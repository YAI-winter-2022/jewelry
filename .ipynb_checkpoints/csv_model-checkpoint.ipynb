{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a83628a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:27.014918Z",
     "start_time": "2022-02-18T19:06:26.246269Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import random_split\n",
    "from ignite.contrib.metrics.regression import R2Score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a6f2fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:27.030876Z",
     "start_time": "2022-02-18T19:06:27.014918Z"
    }
   },
   "outputs": [],
   "source": [
    "root = \"total.csv\"\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7f373c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:27.172448Z",
     "start_time": "2022-02-18T19:06:27.032199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Clarity</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Cut</th>\n",
       "      <th>Polish</th>\n",
       "      <th>Symmetry</th>\n",
       "      <th>Fluorescence</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1638147</td>\n",
       "      <td>CUSHION</td>\n",
       "      <td>0.55</td>\n",
       "      <td>SI2</td>\n",
       "      <td>E</td>\n",
       "      <td>EX</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>N</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1378.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1630155</td>\n",
       "      <td>CUSHION</td>\n",
       "      <td>0.50</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>FANCY</td>\n",
       "      <td>EX</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>F</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.31</td>\n",
       "      <td>2.92</td>\n",
       "      <td>1379.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1612606</td>\n",
       "      <td>CUSHION</td>\n",
       "      <td>0.51</td>\n",
       "      <td>VS2</td>\n",
       "      <td>H</td>\n",
       "      <td>EX</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>N</td>\n",
       "      <td>4.71</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1380.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1638140</td>\n",
       "      <td>CUSHION</td>\n",
       "      <td>0.50</td>\n",
       "      <td>VS2</td>\n",
       "      <td>H</td>\n",
       "      <td>EX</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>N</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.26</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1380.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1536093</td>\n",
       "      <td>CUSHION</td>\n",
       "      <td>0.53</td>\n",
       "      <td>SI1</td>\n",
       "      <td>D</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>VG</td>\n",
       "      <td>N</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1383.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id    Shape  Weight Clarity Colour Cut Polish Symmetry Fluorescence  \\\n",
       "0  1638147  CUSHION    0.55     SI2      E  EX     EX       VG            N   \n",
       "1  1630155  CUSHION    0.50    VVS1  FANCY  EX     EX       VG            F   \n",
       "2  1612606  CUSHION    0.51     VS2      H  EX     EX       VG            N   \n",
       "3  1638140  CUSHION    0.50     VS2      H  EX     EX       VG            N   \n",
       "4  1536093  CUSHION    0.53     SI1      D  EX     VG       VG            N   \n",
       "\n",
       "   Length  Width  Depth    Price  \n",
       "0    5.05   4.35   2.94  1378.65  \n",
       "1    4.60   4.31   2.92  1379.74  \n",
       "2    4.71   4.35   2.94  1380.19  \n",
       "3    4.91   4.26   2.88  1380.61  \n",
       "4    4.70   4.46   3.01  1383.13  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.read_csv(root)\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06878422",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:27.188438Z",
     "start_time": "2022-02-18T19:06:27.173446Z"
    }
   },
   "outputs": [],
   "source": [
    "data_numpy = data_pd.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c82b5d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:27.219356Z",
     "start_time": "2022-02-18T19:06:27.189436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CUSHION': 0, 'EMERALD': 1, 'HEART': 2, 'MARQUISE': 3, 'OVAL': 4, 'PEAR': 5, 'PRINCESS': 6, 'ROUND': 7}\n",
      "{'FL': 0, 'I1': 1, 'I2': 2, 'I3': 3, 'IF': 4, 'SI1': 5, 'SI2': 6, 'VS1': 7, 'VS2': 8, 'VVS1': 9, 'VVS2': 10}\n",
      "{'D': 0, 'E': 1, 'F': 2, 'FANCY': 3, 'G': 4, 'H': 5, 'I': 6, 'J': 7, 'K': 8, 'L': 9, 'M': 10, 'N': 11, 'O': 12, 'O-P': 13, 'Q-R': 14, 'S-T': 15, 'U-V': 16, 'W': 17, 'W-X': 18, 'Y-Z': 19}\n",
      "{'EX': 0, 'F': 1, 'GD': 2, 'VG': 3}\n",
      "{'EX': 0, 'F': 1, 'GD': 2, 'VG': 3}\n",
      "{'EX': 0, 'FR': 1, 'GD': 2, 'VG': 3}\n",
      "{'F': 0, 'M': 1, 'N': 2, 'SL': 3, 'ST': 4, 'VS': 5, 'VSL': 6}\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 3, 4, 5, 6, 7, 8]:\n",
    "    wordset = {word: idx for idx, word in enumerate(np.unique(data_numpy[:,i]))}\n",
    "    print(wordset)\n",
    "    for row in range(len(data_numpy)):\n",
    "        data_numpy[row][i] = wordset[data_numpy[row][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d93a08a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:27.234316Z",
     "start_time": "2022-02-18T19:06:27.220353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0.55 6 1 0 0 3 2 5.05 4.35 2.94 1378.65]\n"
     ]
    }
   ],
   "source": [
    "data_numpy = data_numpy[:,1:]\n",
    "print(data_numpy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b815b6b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:27.250331Z",
     "start_time": "2022-02-18T19:06:27.235313Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,ints, floats, target):\n",
    "        super(Dataset).__init__()\n",
    "        self.ints = ints\n",
    "        self.floats = floats\n",
    "        self.target = target\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return self.ints[idx],self.floats[idx], self.target[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925cf468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:27.266288Z",
     "start_time": "2022-02-18T19:06:27.251329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 6, 1, 0, 0, 3, 2], dtype=torch.int32)\n",
      "tensor([0.5500, 5.0500, 4.3500, 2.9400])\n",
      "tensor([1378.6500])\n"
     ]
    }
   ],
   "source": [
    "data_int = torch.from_numpy(np.array(data_numpy[:,[0,2,3,4,5,6,7]], dtype=\"int\"))\n",
    "data_float = torch.from_numpy(np.array(data_numpy[:,[1,8,9,10]], dtype=\"float\")).float()\n",
    "data_target = torch.from_numpy(np.array(data_numpy[:,[11]], dtype=\"float\")).float()\n",
    "print(data_int[0])\n",
    "print(data_float[0])\n",
    "print(data_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0950ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:27.282245Z",
     "start_time": "2022-02-18T19:06:27.267285Z"
    }
   },
   "outputs": [],
   "source": [
    "train_length = int(len(data_numpy) * 0.6)\n",
    "test_length = int(len(data_numpy) * 0.2)\n",
    "val_length = len(data_numpy) - train_length - test_length\n",
    "\n",
    "train_dataset = Dataset(data_int, data_float, data_target)\n",
    "train_dataset, test_dataset = random_split(train_dataset, [train_length, test_length+val_length])\n",
    "test_dataset, val_dataset = random_split(test_dataset, [test_length, val_length])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a476a743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:27.298203Z",
     "start_time": "2022-02-18T19:06:27.283243Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.emb1 = torch.nn.Embedding(8, 8)\n",
    "        self.emb2 = torch.nn.Embedding(11, 11)\n",
    "        self.emb3 = torch.nn.Embedding(20, 20)\n",
    "        self.emb4 = torch.nn.Embedding(4, 4)\n",
    "        self.emb5 = torch.nn.Embedding(4, 4)\n",
    "        self.emb6 = torch.nn.Embedding(4, 4)\n",
    "        self.emb7 = torch.nn.Embedding(7, 7)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(62, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 840)\n",
    "        self.fc3 = nn.Linear(840, 500)\n",
    "        self.fc4 = nn.Linear(500, 250)\n",
    "        self.fc5 = nn.Linear(250, 1)\n",
    "        self.dropout = nn.Dropout()\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x1 = self.emb1(x[:,0])\n",
    "        x2 = self.emb2(x[:,1])\n",
    "        x3 = self.emb3(x[:,2])\n",
    "        x4 = self.emb4(x[:,3])\n",
    "        x5 = self.emb5(x[:,4])\n",
    "        x6 = self.emb6(x[:,5])\n",
    "        x7 = self.emb7(x[:,6])\n",
    "        x = torch.cat((x1, x2, x3, x4, x5, x6, x7, y), dim=1)\n",
    "        x = self.dropout(self.act(self.fc1(x)))\n",
    "        x = self.dropout(self.act(self.fc2(x)))\n",
    "        x = self.dropout(self.act(self.fc3(x)))\n",
    "        x = self.dropout(self.act(self.fc4(x)))\n",
    "        return self.fc5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57844bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:27.393947Z",
     "start_time": "2022-02-18T19:06:27.299200Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f910f99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:41.331101Z",
     "start_time": "2022-02-18T19:06:27.394944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:  1] Average loss: 20479156.0000, val_loss: 22050858.0000\n",
      "[Epoch:  2] Average loss: 17582150.0000, val_loss: 16556753.0000\n",
      "[Epoch:  3] Average loss: 14758959.0000, val_loss: 15923816.0000\n",
      "[Epoch:  4] Average loss: 14305173.0000, val_loss: 15679588.0000\n",
      "[Epoch:  5] Average loss: 13714279.0000, val_loss: 14975734.0000\n",
      "[Epoch:  6] Average loss: 13193546.0000, val_loss: 14457316.0000\n",
      "[Epoch:  7] Average loss: 13098545.0000, val_loss: 13948106.0000\n",
      "[Epoch:  8] Average loss: 12358193.0000, val_loss: 13406230.0000\n",
      "[Epoch:  9] Average loss: 12247492.0000, val_loss: 12849164.0000\n",
      "[Epoch: 10] Average loss: 11665790.0000, val_loss: 12287973.0000\n",
      "[Epoch: 11] Average loss: 11799627.0000, val_loss: 11957248.0000\n",
      "[Epoch: 12] Average loss: 11220860.0000, val_loss: 11594835.0000\n",
      "[Epoch: 13] Average loss: 10675003.0000, val_loss: 11065933.0000\n",
      "[Epoch: 14] Average loss: 10081547.0000, val_loss: 10408042.0000\n",
      "[Epoch: 15] Average loss: 9657485.0000, val_loss: 9645563.0000\n",
      "[Epoch: 16] Average loss: 8867213.0000, val_loss: 8691170.0000\n",
      "[Epoch: 17] Average loss: 8587198.0000, val_loss: 7425098.0000\n",
      "[Epoch: 18] Average loss: 7067166.5000, val_loss: 6247013.0000\n",
      "[Epoch: 19] Average loss: 6486391.0000, val_loss: 5219956.5000\n",
      "[Epoch: 20] Average loss: 5377627.5000, val_loss: 4257408.5000\n",
      "[Epoch: 21] Average loss: 4573627.0000, val_loss: 3551812.5000\n",
      "[Epoch: 22] Average loss: 3935480.5000, val_loss: 3048577.5000\n",
      "[Epoch: 23] Average loss: 2990575.0000, val_loss: 2525080.0000\n",
      "[Epoch: 24] Average loss: 3162613.7500, val_loss: 2172781.0000\n",
      "[Epoch: 25] Average loss: 2711650.0000, val_loss: 1876337.6250\n",
      "[Epoch: 26] Average loss: 1816645.8750, val_loss: 1811827.2500\n",
      "[Epoch: 27] Average loss: 2169185.5000, val_loss: 1797255.6250\n",
      "[Epoch: 28] Average loss: 2043940.0000, val_loss: 1473841.0000\n",
      "[Epoch: 29] Average loss: 2053160.8750, val_loss: 1459800.5000\n",
      "[Epoch: 30] Average loss: 1555614.0000, val_loss: 1511016.7500\n",
      "[Epoch: 31] Average loss: 1317029.1250, val_loss: 1361415.1250\n",
      "[Epoch: 32] Average loss: 1391560.5000, val_loss: 1340312.5000\n",
      "[Epoch: 33] Average loss: 1545815.2500, val_loss: 1539868.6250\n",
      "[Epoch: 34] Average loss: 1397876.3750, val_loss: 1543424.2500\n",
      "[Epoch: 35] Average loss: 1150894.6250, val_loss: 1698702.0000\n",
      "[Epoch: 36] Average loss: 1062483.2500, val_loss: 1336755.1250\n",
      "[Epoch: 37] Average loss: 1200113.1250, val_loss: 1238619.2500\n",
      "[Epoch: 38] Average loss: 1471226.3750, val_loss: 1267076.8750\n",
      "[Epoch: 39] Average loss: 1163469.0000, val_loss: 1311121.3750\n",
      "[Epoch: 40] Average loss: 1100432.8750, val_loss: 1161116.1250\n",
      "[Epoch: 41] Average loss: 960232.0000, val_loss: 1208775.0000\n",
      "[Epoch: 42] Average loss: 1166329.5000, val_loss: 1237910.5000\n",
      "[Epoch: 43] Average loss: 715834.0000, val_loss: 1276011.7500\n",
      "[Epoch: 44] Average loss: 804240.5000, val_loss: 1287656.5000\n",
      "[Epoch: 45] Average loss: 1073826.5000, val_loss: 1252369.3750\n",
      "[Epoch: 46] Average loss: 727268.3125, val_loss: 1309677.5000\n",
      "[Epoch: 47] Average loss: 1109981.8750, val_loss: 1281530.6250\n",
      "[Epoch: 48] Average loss: 901098.7500, val_loss: 1300791.8750\n",
      "[Epoch: 49] Average loss: 781957.0625, val_loss: 1297142.1250\n",
      "[Epoch: 50] Average loss: 856505.2500, val_loss: 1324673.7500\n",
      "[Epoch: 51] Average loss: 939065.8750, val_loss: 1269515.3750\n",
      "[Epoch: 52] Average loss: 845485.5625, val_loss: 1278810.7500\n",
      "[Epoch: 53] Average loss: 921109.0625, val_loss: 1253664.5000\n",
      "[Epoch: 54] Average loss: 831786.8750, val_loss: 1359590.0000\n",
      "[Epoch: 55] Average loss: 931830.2500, val_loss: 1366963.7500\n",
      "[Epoch: 56] Average loss: 640833.3125, val_loss: 1610558.5000\n",
      "[Epoch: 57] Average loss: 1030353.0000, val_loss: 1472341.6250\n",
      "[Epoch: 58] Average loss: 768634.4375, val_loss: 1364202.3750\n",
      "[Epoch: 59] Average loss: 630503.3125, val_loss: 1320608.7500\n",
      "[Epoch: 60] Average loss: 903089.9375, val_loss: 1161719.6250\n",
      "[Epoch: 61] Average loss: 930190.1250, val_loss: 1157024.0000\n",
      "[Epoch: 62] Average loss: 771560.3750, val_loss: 1374758.5000\n",
      "[Epoch: 63] Average loss: 823348.5625, val_loss: 1119932.7500\n",
      "[Epoch: 64] Average loss: 872803.7500, val_loss: 1283505.2500\n",
      "[Epoch: 65] Average loss: 739360.9375, val_loss: 1339641.6250\n",
      "[Epoch: 66] Average loss: 747611.2500, val_loss: 1103448.7500\n",
      "[Epoch: 67] Average loss: 552059.6875, val_loss: 1003961.8750\n",
      "[Epoch: 68] Average loss: 777150.0000, val_loss: 1495389.0000\n",
      "[Epoch: 69] Average loss: 1000844.2500, val_loss: 1292223.5000\n",
      "[Epoch: 70] Average loss: 567528.1875, val_loss: 1059314.1250\n",
      "[Epoch: 71] Average loss: 591170.3750, val_loss: 1099358.1250\n",
      "[Epoch: 72] Average loss: 765964.8125, val_loss: 1217896.0000\n",
      "[Epoch: 73] Average loss: 752261.5000, val_loss: 1040577.8750\n",
      "[Epoch: 74] Average loss: 751829.6875, val_loss: 1116095.5000\n",
      "[Epoch: 75] Average loss: 667278.1250, val_loss: 1021819.1875\n",
      "[Epoch: 76] Average loss: 824549.0625, val_loss: 1094228.1250\n",
      "[Epoch: 77] Average loss: 626480.6875, val_loss: 1007444.9375\n",
      "[Epoch: 78] Average loss: 520441.4688, val_loss: 1110108.1250\n",
      "[Epoch: 79] Average loss: 577740.0625, val_loss: 1208479.7500\n",
      "[Epoch: 80] Average loss: 737898.8750, val_loss: 1110967.0000\n",
      "[Epoch: 81] Average loss: 510880.6562, val_loss: 1114973.5000\n",
      "[Epoch: 82] Average loss: 815192.0625, val_loss: 1137052.6250\n",
      "[Epoch: 83] Average loss: 603154.7500, val_loss: 1017928.9375\n",
      "[Epoch: 84] Average loss: 576495.8125, val_loss: 1060007.3750\n",
      "[Epoch: 85] Average loss: 590519.8750, val_loss: 1101587.5000\n",
      "[Epoch: 86] Average loss: 653788.8750, val_loss: 994145.1875\n",
      "[Epoch: 87] Average loss: 732010.5625, val_loss: 1137855.7500\n",
      "[Epoch: 88] Average loss: 500595.9375, val_loss: 1454660.5000\n",
      "[Epoch: 89] Average loss: 666936.0625, val_loss: 1218514.7500\n",
      "[Epoch: 90] Average loss: 537016.3750, val_loss: 1107500.6250\n",
      "[Epoch: 91] Average loss: 519269.6875, val_loss: 1504012.3750\n",
      "[Epoch: 92] Average loss: 674907.6875, val_loss: 931126.0000\n",
      "[Epoch: 93] Average loss: 530211.3750, val_loss: 825852.1250\n",
      "[Epoch: 94] Average loss: 542291.1250, val_loss: 1088831.1250\n",
      "[Epoch: 95] Average loss: 575949.5000, val_loss: 1016427.5000\n",
      "[Epoch: 96] Average loss: 421897.5312, val_loss: 1097154.3750\n",
      "[Epoch: 97] Average loss: 566591.1250, val_loss: 1022052.3750\n",
      "[Epoch: 98] Average loss: 669679.8750, val_loss: 1021514.5000\n",
      "[Epoch: 99] Average loss: 597397.1875, val_loss: 1029822.5000\n",
      "[Epoch: 100] Average loss: 472474.8125, val_loss: 1096724.6250\n",
      "[Epoch: 101] Average loss: 567100.0625, val_loss: 985953.6875\n",
      "[Epoch: 102] Average loss: 599395.7500, val_loss: 1314584.6250\n",
      "[Epoch: 103] Average loss: 707084.0000, val_loss: 1003399.5625\n",
      "[Epoch: 104] Average loss: 445194.1875, val_loss: 1309349.2500\n",
      "[Epoch: 105] Average loss: 549929.8750, val_loss: 921443.4375\n",
      "[Epoch: 106] Average loss: 631102.5625, val_loss: 1104948.7500\n",
      "[Epoch: 107] Average loss: 453028.0938, val_loss: 1189664.6250\n",
      "[Epoch: 108] Average loss: 478380.8125, val_loss: 1012499.4375\n",
      "[Epoch: 109] Average loss: 452734.5938, val_loss: 1147408.7500\n",
      "[Epoch: 110] Average loss: 768199.3750, val_loss: 1364450.0000\n",
      "[Epoch: 111] Average loss: 1100800.2500, val_loss: 848431.6875\n",
      "[Epoch: 112] Average loss: 664843.7500, val_loss: 905331.5000\n",
      "[Epoch: 113] Average loss: 531825.2500, val_loss: 924297.3750\n",
      "[Epoch: 114] Average loss: 561576.2500, val_loss: 913672.7500\n",
      "[Epoch: 115] Average loss: 499510.8438, val_loss: 1034687.6250\n",
      "[Epoch: 116] Average loss: 488966.5938, val_loss: 1077463.6250\n",
      "[Epoch: 117] Average loss: 470626.5625, val_loss: 1188446.5000\n",
      "[Epoch: 118] Average loss: 691502.4375, val_loss: 1078432.6250\n",
      "[Epoch: 119] Average loss: 516224.1875, val_loss: 993454.4375\n",
      "[Epoch: 120] Average loss: 660630.9375, val_loss: 917642.8125\n",
      "[Epoch: 121] Average loss: 547758.5000, val_loss: 794175.2500\n",
      "[Epoch: 122] Average loss: 579478.8750, val_loss: 887481.1250\n",
      "[Epoch: 123] Average loss: 511524.2812, val_loss: 896662.4375\n",
      "[Epoch: 124] Average loss: 471144.6250, val_loss: 910468.8125\n",
      "[Epoch: 125] Average loss: 687064.0625, val_loss: 897500.3750\n",
      "[Epoch: 126] Average loss: 505323.7500, val_loss: 1150536.8750\n",
      "[Epoch: 127] Average loss: 542404.6250, val_loss: 998590.3125\n",
      "[Epoch: 128] Average loss: 598893.5000, val_loss: 963031.4375\n",
      "[Epoch: 129] Average loss: 500870.5000, val_loss: 1017331.5000\n",
      "[Epoch: 130] Average loss: 492993.0312, val_loss: 1158172.0000\n",
      "[Epoch: 131] Average loss: 534821.8125, val_loss: 925950.2500\n",
      "[Epoch: 132] Average loss: 443207.1875, val_loss: 892265.4375\n",
      "[Epoch: 133] Average loss: 516314.6250, val_loss: 897080.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 134] Average loss: 879671.1250, val_loss: 975512.0000\n",
      "[Epoch: 135] Average loss: 457908.2188, val_loss: 794204.0000\n",
      "[Epoch: 136] Average loss: 838720.8750, val_loss: 701388.2500\n",
      "[Epoch: 137] Average loss: 502446.1250, val_loss: 1316497.6250\n",
      "[Epoch: 138] Average loss: 529319.1875, val_loss: 905311.5000\n",
      "[Epoch: 139] Average loss: 544680.8750, val_loss: 705183.0000\n",
      "[Epoch: 140] Average loss: 718485.5625, val_loss: 1037150.1250\n",
      "[Epoch: 141] Average loss: 509480.7812, val_loss: 768329.6250\n",
      "[Epoch: 142] Average loss: 459174.1875, val_loss: 1261312.3750\n",
      "[Epoch: 143] Average loss: 656202.7500, val_loss: 999930.6250\n",
      "[Epoch: 144] Average loss: 525957.2500, val_loss: 885948.2500\n",
      "[Epoch: 145] Average loss: 467335.5938, val_loss: 883239.6250\n",
      "[Epoch: 146] Average loss: 619259.5625, val_loss: 1038141.5000\n",
      "[Epoch: 147] Average loss: 555152.3125, val_loss: 943571.0000\n",
      "[Epoch: 148] Average loss: 630229.0000, val_loss: 924642.6875\n",
      "[Epoch: 149] Average loss: 718823.5000, val_loss: 857993.1250\n",
      "[Epoch: 150] Average loss: 525057.1250, val_loss: 752800.0000\n",
      "[Epoch: 151] Average loss: 515850.7500, val_loss: 928187.7500\n",
      "[Epoch: 152] Average loss: 660968.1875, val_loss: 752647.5000\n",
      "[Epoch: 153] Average loss: 569512.2500, val_loss: 806928.8750\n",
      "[Epoch: 154] Average loss: 561919.6875, val_loss: 1077858.6250\n",
      "[Epoch: 155] Average loss: 542325.1875, val_loss: 837811.6250\n",
      "[Epoch: 156] Average loss: 606716.2500, val_loss: 838079.1250\n",
      "[Epoch: 157] Average loss: 674195.5625, val_loss: 962161.1875\n",
      "[Epoch: 158] Average loss: 599138.9375, val_loss: 1029111.6250\n",
      "[Epoch: 159] Average loss: 793472.3125, val_loss: 914457.3125\n",
      "[Epoch: 160] Average loss: 512713.0938, val_loss: 967251.2500\n",
      "[Epoch: 161] Average loss: 491750.1250, val_loss: 921086.3750\n",
      "[Epoch: 162] Average loss: 634649.0625, val_loss: 925690.1250\n",
      "[Epoch: 163] Average loss: 639560.1875, val_loss: 1099006.6250\n",
      "[Epoch: 164] Average loss: 587695.9375, val_loss: 860414.8125\n",
      "[Epoch: 165] Average loss: 568355.5000, val_loss: 930522.8750\n",
      "[Epoch: 166] Average loss: 371123.1875, val_loss: 1247448.6250\n",
      "[Epoch: 167] Average loss: 700738.5000, val_loss: 975975.5000\n",
      "[Epoch: 168] Average loss: 655111.5000, val_loss: 873693.6875\n",
      "[Epoch: 169] Average loss: 556401.1875, val_loss: 840465.0000\n",
      "[Epoch: 170] Average loss: 472617.0938, val_loss: 919990.4375\n",
      "[Epoch: 171] Average loss: 505405.9062, val_loss: 916937.5625\n",
      "[Epoch: 172] Average loss: 419978.9375, val_loss: 838689.7500\n",
      "[Epoch: 173] Average loss: 529303.5625, val_loss: 880993.5000\n",
      "[Epoch: 174] Average loss: 522856.4688, val_loss: 947072.4375\n",
      "[Epoch: 175] Average loss: 417059.0000, val_loss: 846477.5000\n",
      "[Epoch: 176] Average loss: 704282.3125, val_loss: 1016728.0000\n",
      "[Epoch: 177] Average loss: 536237.1875, val_loss: 1069074.1250\n",
      "[Epoch: 178] Average loss: 598763.2500, val_loss: 831532.0000\n",
      "[Epoch: 179] Average loss: 514056.7188, val_loss: 723832.3125\n",
      "[Epoch: 180] Average loss: 503834.3438, val_loss: 812053.9375\n",
      "[Epoch: 181] Average loss: 528668.6250, val_loss: 736099.7500\n",
      "[Epoch: 182] Average loss: 627870.8750, val_loss: 834138.6250\n",
      "[Epoch: 183] Average loss: 698751.4375, val_loss: 1060184.2500\n",
      "[Epoch: 184] Average loss: 405246.4375, val_loss: 745456.1250\n",
      "[Epoch: 185] Average loss: 410056.6562, val_loss: 788755.6250\n",
      "[Epoch: 186] Average loss: 394911.2500, val_loss: 829993.6250\n",
      "[Epoch: 187] Average loss: 471909.6562, val_loss: 802210.3125\n",
      "[Epoch: 188] Average loss: 369654.2500, val_loss: 741818.0625\n",
      "[Epoch: 189] Average loss: 415942.3750, val_loss: 715214.0625\n",
      "[Epoch: 190] Average loss: 427834.0938, val_loss: 640903.8125\n",
      "[Epoch: 191] Average loss: 516720.0312, val_loss: 811616.8750\n",
      "[Epoch: 192] Average loss: 400255.5000, val_loss: 776246.8750\n",
      "[Epoch: 193] Average loss: 528046.8750, val_loss: 979889.1875\n",
      "[Epoch: 194] Average loss: 380159.9375, val_loss: 852356.5000\n",
      "[Epoch: 195] Average loss: 441866.4375, val_loss: 700391.5625\n",
      "[Epoch: 196] Average loss: 433086.6250, val_loss: 693465.6250\n",
      "[Epoch: 197] Average loss: 591431.5000, val_loss: 859412.5625\n",
      "[Epoch: 198] Average loss: 571159.2500, val_loss: 1000548.3750\n",
      "[Epoch: 199] Average loss: 379632.8125, val_loss: 1091431.5000\n",
      "[Epoch: 200] Average loss: 538754.6875, val_loss: 942643.3125\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    avg_loss = 0\n",
    "\n",
    "    for X1, X2, Y in train_loader:\n",
    "        X1 = X1.to(device)\n",
    "        X2 = X2.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        model.zero_grad()  # why we use zero_grad?\n",
    "        prediction = model(X1, X2)\n",
    "        loss = criterion(prediction, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss / len(train_loader)\n",
    "    print(f'[Epoch: {epoch+1:>2}] Average loss: {avg_loss:.4f}, ', end='')\n",
    "    \n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    with torch.no_grad():\n",
    "        val_avg_loss = 0.\n",
    "        for X1_val, X2_val, Y_val in val_loader:\n",
    "            X1_val = X1_val.to(device)\n",
    "            X2_val = X2_val.to(device)\n",
    "            Y_val = Y_val.to(device)\n",
    "            val_prediction = model(X1_val, X2_val)\n",
    "            val_loss = criterion(val_prediction, Y_val)\n",
    "            val_avg_loss += val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"val_loss: {val_avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb590aa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:41.347107Z",
     "start_time": "2022-02-18T19:06:41.332099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.13%\n"
     ]
    }
   ],
   "source": [
    "metric = R2Score(device=device)\n",
    "metric.reset()\n",
    "\n",
    "model.eval()\n",
    "criterion.eval()\n",
    "with torch.no_grad():\n",
    "    test_avg_acc = 0\n",
    "    for X1_test, X2_test, Y_test in test_loader:\n",
    "        X1_test = X1_test.to(device)\n",
    "        X2_test = X2_test.to(device)\n",
    "        Y_test = Y_test.to(device)\n",
    "        \n",
    "        test_prediction = model(X1_test, X2_test)\n",
    "        metric.update([test_prediction, Y_test])\n",
    "    print(f\"Accuracy: {metric.compute()*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python-3-9-7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
