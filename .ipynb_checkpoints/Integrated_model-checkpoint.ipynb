{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7bf85c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T11:45:52.056388Z",
     "start_time": "2022-02-25T11:45:48.422906Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88539da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T11:45:52.072100Z",
     "start_time": "2022-02-25T11:45:52.057385Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_path = \"final.csv\"\n",
    "image_path = \"./images\"\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c5b968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T11:45:52.101989Z",
     "start_time": "2022-02-25T11:45:52.073100Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78410749",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T11:45:52.117947Z",
     "start_time": "2022-02-25T11:45:52.102987Z"
    }
   },
   "outputs": [],
   "source": [
    "class AllDataset(Dataset):\n",
    "    def __init__(self, csv_path, image_path, image_transform=transforms.Compose([transforms.ToTensor()])):\n",
    "        super(AllDataset).__init__()\n",
    "        csv = pd.read_csv(csv_path)\n",
    "        csv_np = csv.to_numpy()\n",
    "        self.image_transform = image_transform\n",
    "        self.ids = list(map(str, csv['id']))\n",
    "        \n",
    "        for i in [1, 3, 4, 5, 6, 7, 8]:\n",
    "            wordset = {word: idx for idx, word in enumerate(np.unique(csv_np[:,i]))}\n",
    "            for row in range(len(csv_np)):\n",
    "                csv_np[row][i] = wordset[csv_np[row][i]]\n",
    "        self.ints = torch.from_numpy(np.array(csv_np[:,[1,3,4,5,6,7,8]], dtype=\"int\"))\n",
    "        self.floats = torch.from_numpy(np.array(csv_np[:,[2,9,10,11]], dtype=\"float\")).float()\n",
    "        self.target = torch.from_numpy(np.array(csv_np[:,[12]], dtype=\"float\")).float()\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.image_transform(Image.open(self.image_path+'/'+self.Id[idx]+'jpg')), self.ints[idx],self.floats[idx], self.target[idx]\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8af2023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T11:46:02.052415Z",
     "start_time": "2022-02-25T11:45:52.118943Z"
    }
   },
   "outputs": [],
   "source": [
    "data_length = len(pd.read_csv(csv_path))\n",
    "train_length = int(data_length * 0.6)\n",
    "test_length = int(data_length * 0.2)\n",
    "val_length = data_length - train_length - test_length\n",
    "\n",
    "image_transform = transforms.Compose([transforms.ToTensor()\n",
    "                                     ])\n",
    "\n",
    "all_dataset = AllDataset(csv_path, image_path, image_transform)\n",
    "train_dataset, test_dataset = random_split(all_dataset, [train_length, test_length+val_length])\n",
    "test_dataset, val_dataset = random_split(test_dataset, [test_length, val_length])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a46f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T11:46:02.068373Z",
     "start_time": "2022-02-25T11:46:02.053414Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "        self.resnet18.fc = nn.Sequential(nn.Linear(512, 4096),\n",
    "                                         nn.BatchNorm1d(4096),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout()\n",
    "                                        )\n",
    "        self.resenet18 = self.resnet18.to(device)\n",
    "        \n",
    "        self.emb1 = torch.nn.Embedding(8, 20)\n",
    "        self.emb2 = torch.nn.Embedding(11, 20)\n",
    "        self.emb3 = torch.nn.Embedding(20, 20)\n",
    "        self.emb4 = torch.nn.Embedding(4, 20)\n",
    "        self.emb5 = torch.nn.Embedding(4, 20)\n",
    "        self.emb6 = torch.nn.Embedding(4, 20)\n",
    "        self.emb7 = torch.nn.Embedding(7, 20)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc = nn.Linear(4, 80)\n",
    "        self.csvbn = nn.BatchNorm1d(80)\n",
    "        self.csvfc1 = nn.Linear(220, 8192)\n",
    "        self.csvfc2 = nn.Linear(8192, 8192)\n",
    "        self.csvfc3 = nn.Linear(8192, 4096)\n",
    "        self.csvbn1 = nn.BatchNorm1d(8192)\n",
    "        self.csvbn2 = nn.BatchNorm1d(8192)\n",
    "        self.csvbn3 = nn.BatchNorm1d(4096)\n",
    "        \n",
    "        self.fc1 = nn.Linear(8192, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(4096)\n",
    "        self.dropout = nn.Dropout()\n",
    "    \n",
    "    def forward(self, image, x, y):\n",
    "        image = self.resnet18(image)\n",
    "        \n",
    "        x1 = self.emb1(x[:,0])\n",
    "        x2 = self.emb2(x[:,1])\n",
    "        x3 = self.emb3(x[:,2])\n",
    "        x4 = self.emb4(x[:,3])\n",
    "        x5 = self.emb5(x[:,4])\n",
    "        x6 = self.emb6(x[:,5])\n",
    "        x7 = self.emb7(x[:,6])\n",
    "        y = self.csvbn(self.fc(y))\n",
    "        x = torch.cat((x1, x2, x3, x4, x5, x6, x7, y), dim=1)\n",
    "        \n",
    "        x = self.dropout(self.act(self.csvbn1(self.csvfc1(x))))\n",
    "        x = self.dropout(self.act(self.csvbn2(self.csvfc2(x))))\n",
    "        x = self.dropout(self.act(self.csvbn3(self.csvfc3(x))))\n",
    "        x = torch.cat((x, image), dim=1)\n",
    "        \n",
    "        x = self.dropout(self.act(self.bn1(self.fc1(x))))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3749f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T11:46:04.819966Z",
     "start_time": "2022-02-25T11:46:02.069370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "52.5%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad748bfb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-25T11:45:48.409Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:  1] Average loss: 5837.4082, val_loss: 4831.2959\n",
      "[Epoch:  2] Average loss: 4644.8345, val_loss: 4605.3135\n",
      "[Epoch:  3] Average loss: 4506.5938, val_loss: 4763.9248\n",
      "[Epoch:  4] Average loss: 4523.3716, val_loss: 4618.1274\n",
      "[Epoch:  5] Average loss: 4378.6816, val_loss: 3690.2083\n",
      "[Epoch:  6] Average loss: 4217.6035, val_loss: 4649.6680\n",
      "[Epoch:  7] Average loss: 4181.8940, val_loss: 4479.1821\n",
      "[Epoch:  8] Average loss: 4128.0591, val_loss: 3739.5688\n",
      "[Epoch:  9] Average loss: 4137.7817, val_loss: 4308.7485\n",
      "[Epoch: 10] Average loss: 4038.1733, val_loss: 4068.2632\n",
      "[Epoch: 11] Average loss: 4374.7261, val_loss: 4273.9951\n",
      "[Epoch: 12] Average loss: 3999.0034, val_loss: 3994.0151\n",
      "[Epoch: 13] Average loss: 3976.6306, val_loss: 7926.8457\n",
      "[Epoch: 14] Average loss: 3851.5366, val_loss: 3911.3679\n",
      "[Epoch: 15] Average loss: 3749.6560, val_loss: 4062.5054\n",
      "[Epoch: 16] Average loss: 3837.5535, val_loss: 3830.5122\n",
      "[Epoch: 17] Average loss: 3746.0723, val_loss: 3426.4839\n",
      "[Epoch: 18] Average loss: 3715.8950, val_loss: 3720.9199\n",
      "[Epoch: 19] Average loss: 3567.2695, val_loss: 3336.3455\n",
      "[Epoch: 20] Average loss: 4088.3901, val_loss: 3552.0342\n",
      "[Epoch: 21] Average loss: 3335.7007, val_loss: 3327.7478\n",
      "[Epoch: 22] Average loss: 3322.1794, val_loss: 3169.8125\n",
      "[Epoch: 23] Average loss: 3251.8062, val_loss: 2445.9705\n",
      "[Epoch: 24] Average loss: 3143.0281, val_loss: 2680.5200\n",
      "[Epoch: 25] Average loss: 3108.0029, val_loss: 3153.3770\n",
      "[Epoch: 26] Average loss: 2993.7317, val_loss: 2688.1882\n",
      "[Epoch: 27] Average loss: 2835.7134, val_loss: 2739.5952\n",
      "[Epoch: 28] Average loss: 2782.5088, val_loss: 2505.6653\n",
      "[Epoch: 29] Average loss: 2744.2607, val_loss: 1967.2312\n",
      "[Epoch: 30] Average loss: 2753.9636, val_loss: 1712.7997\n",
      "[Epoch: 31] Average loss: 2653.5793, val_loss: 1885.9808\n",
      "[Epoch: 32] Average loss: 2566.9526, val_loss: 2043.6375\n",
      "[Epoch: 33] Average loss: 2467.3772, val_loss: 2081.8711\n",
      "[Epoch: 34] Average loss: 2443.7837, val_loss: 1765.0032\n",
      "[Epoch: 35] Average loss: 2332.7341, val_loss: 1790.3079\n",
      "[Epoch: 36] Average loss: 2367.2832, val_loss: 2049.8364\n",
      "[Epoch: 37] Average loss: 2213.6753, val_loss: 1683.0812\n",
      "[Epoch: 38] Average loss: 2104.6980, val_loss: 1848.8315\n",
      "[Epoch: 39] Average loss: 2109.6580, val_loss: 1655.8842\n",
      "[Epoch: 40] Average loss: 1958.2017, val_loss: 1952.0889\n",
      "[Epoch: 41] Average loss: 2004.0630, val_loss: 1679.2501\n",
      "[Epoch: 42] Average loss: 3850.9053, val_loss: 2149.3169\n",
      "[Epoch: 43] Average loss: 1840.3345, val_loss: 2128.7029\n",
      "[Epoch: 44] Average loss: 2540.6606, val_loss: 2342.6682\n",
      "[Epoch: 45] Average loss: 1710.7743, val_loss: 1539.5884\n",
      "[Epoch: 46] Average loss: 1892.2599, val_loss: 1550.7339\n",
      "[Epoch: 47] Average loss: 1783.8405, val_loss: 1373.0083\n",
      "[Epoch: 48] Average loss: 1753.5828, val_loss: 1396.5143\n",
      "[Epoch: 49] Average loss: 1666.2764, val_loss: 1562.9093\n",
      "[Epoch: 50] Average loss: 3072.0981, val_loss: 1871.2876\n",
      "[Epoch: 51] Average loss: 1365.7542, val_loss: 1281.3904\n",
      "[Epoch: 52] Average loss: 1547.9326, val_loss: 1339.3459\n",
      "[Epoch: 53] Average loss: 1557.5864, val_loss: 1332.4520\n",
      "[Epoch: 54] Average loss: 1446.8827, val_loss: 1323.4966\n",
      "[Epoch: 55] Average loss: 1665.3883, val_loss: 1117.4869\n",
      "[Epoch: 56] Average loss: 1563.5358, val_loss: 1263.2679\n",
      "[Epoch: 57] Average loss: 1499.9529, val_loss: 1361.3533\n",
      "[Epoch: 58] Average loss: 1457.5653, val_loss: 1605.6382\n",
      "[Epoch: 59] Average loss: 1573.4937, val_loss: 1123.3955\n",
      "[Epoch: 60] Average loss: 1374.8463, val_loss: 1103.7449\n",
      "[Epoch: 61] Average loss: 1433.2772, val_loss: 1304.2172\n",
      "[Epoch: 62] Average loss: 1443.7262, val_loss: 1139.4883\n",
      "[Epoch: 63] Average loss: 1383.3335, val_loss: 2698.4561\n",
      "[Epoch: 64] Average loss: 1828.4332, val_loss: 1341.5702\n",
      "[Epoch: 65] Average loss: 1284.7996, val_loss: 1079.0979\n",
      "[Epoch: 66] Average loss: 1304.4908, val_loss: 1163.4973\n",
      "[Epoch: 67] Average loss: 1536.2144, val_loss: 1205.3783\n",
      "[Epoch: 68] Average loss: 1404.5331, val_loss: 1136.8503\n",
      "[Epoch: 69] Average loss: 1457.3274, val_loss: 1225.9170\n",
      "[Epoch: 70] Average loss: 1150.0751, val_loss: 1148.9974\n",
      "[Epoch: 71] Average loss: 1357.4180, val_loss: 1253.0496\n",
      "[Epoch: 72] Average loss: 1138.2906, val_loss: 1091.3036\n",
      "[Epoch: 73] Average loss: 1296.3535, val_loss: 1752.5728\n",
      "[Epoch: 74] Average loss: 1206.7076, val_loss: 1237.2498\n",
      "[Epoch: 75] Average loss: 1460.2626, val_loss: 1241.2522\n",
      "[Epoch: 76] Average loss: 1292.7858, val_loss: 1687.0757\n",
      "[Epoch: 77] Average loss: 1198.6965, val_loss: 1456.0629\n",
      "[Epoch: 78] Average loss: 1099.7690, val_loss: 1906.4994\n",
      "[Epoch: 79] Average loss: 1604.3286, val_loss: 1932.4700\n",
      "[Epoch: 80] Average loss: 1318.1759, val_loss: 1544.7850\n",
      "[Epoch: 81] Average loss: 1314.0563, val_loss: 1457.2275\n",
      "[Epoch: 82] Average loss: 1541.2124, val_loss: 1296.0657\n",
      "[Epoch: 83] Average loss: 1297.7837, val_loss: 1521.9415\n",
      "[Epoch: 84] Average loss: 1115.8544, val_loss: 1289.3262\n",
      "[Epoch: 85] Average loss: 1296.1805, val_loss: 1122.5287\n",
      "[Epoch: 86] Average loss: 1201.5660, val_loss: 1284.5553\n",
      "[Epoch: 87] Average loss: 1160.6904, val_loss: 1017.6526\n",
      "[Epoch: 88] Average loss: 1156.1630, val_loss: 1203.9825\n",
      "[Epoch: 89] Average loss: 1172.1648, val_loss: 1140.7871\n",
      "[Epoch: 90] Average loss: 1168.5588, val_loss: 1186.7031\n",
      "[Epoch: 91] Average loss: 1115.5104, val_loss: 1155.8495\n",
      "[Epoch: 92] Average loss: 1044.6238, val_loss: 1054.2517\n",
      "[Epoch: 93] Average loss: 1000.0008, val_loss: 1204.7595\n",
      "[Epoch: 94] Average loss: 1114.7899, val_loss: 1366.2979\n",
      "[Epoch: 95] Average loss: 1227.2318, val_loss: 1202.6178\n",
      "[Epoch: 96] Average loss: 1147.9401, val_loss: 1145.2089\n",
      "[Epoch: 97] Average loss: 1090.1012, val_loss: 1317.1489\n",
      "[Epoch: 98] Average loss: 1257.1650, val_loss: 1645.3779\n",
      "[Epoch: 99] Average loss: 1200.4761, val_loss: 1993.9108\n",
      "[Epoch: 100] Average loss: 1202.0569, val_loss: 1180.5216\n",
      "[Epoch: 101] Average loss: 1304.2207, val_loss: 1178.5745\n",
      "[Epoch: 102] Average loss: 1291.8733, val_loss: 1031.2599\n",
      "[Epoch: 103] Average loss: 986.2285, val_loss: 1113.7355\n",
      "[Epoch: 104] Average loss: 1058.9423, val_loss: 1165.7645\n",
      "[Epoch: 105] Average loss: 1111.9133, val_loss: 1206.8068\n",
      "[Epoch: 106] Average loss: 1227.5752, val_loss: 1756.3411\n",
      "[Epoch: 107] Average loss: 1192.3693, val_loss: 1009.2083\n",
      "[Epoch: 108] Average loss: 1293.1586, val_loss: 1135.1766\n",
      "[Epoch: 109] Average loss: 1275.3818, val_loss: 1220.7283\n",
      "[Epoch: 110] Average loss: 1120.4146, val_loss: 3715.8960\n",
      "[Epoch: 111] Average loss: 1149.0288, val_loss: 1357.8716\n",
      "[Epoch: 112] Average loss: 1167.9257, val_loss: 1221.1639\n",
      "[Epoch: 113] Average loss: 916.8330, val_loss: 1119.5160\n",
      "[Epoch: 114] Average loss: 1021.2589, val_loss: 1223.0775\n",
      "[Epoch: 115] Average loss: 1131.8885, val_loss: 1135.1030\n",
      "[Epoch: 116] Average loss: 980.3210, val_loss: 1543.2146\n",
      "[Epoch: 117] Average loss: 1225.1875, val_loss: 1389.7080\n",
      "[Epoch: 118] Average loss: 987.3401, val_loss: 1188.7529\n",
      "[Epoch: 119] Average loss: 1038.6681, val_loss: 1106.6558\n",
      "[Epoch: 120] Average loss: 943.9944, val_loss: 1105.5656\n",
      "[Epoch: 121] Average loss: 1251.2893, val_loss: 954.8426\n",
      "[Epoch: 122] Average loss: 1122.1367, val_loss: 999.3841\n",
      "[Epoch: 123] Average loss: 1144.1681, val_loss: 1103.2595\n",
      "[Epoch: 124] Average loss: 1116.2664, val_loss: 1142.0543\n",
      "[Epoch: 125] Average loss: 897.0217, val_loss: 1227.0511\n",
      "[Epoch: 126] Average loss: 1065.8596, val_loss: 1165.5681\n",
      "[Epoch: 127] Average loss: 1004.2946, val_loss: 1142.1755\n",
      "[Epoch: 128] Average loss: 1088.4867, val_loss: 1096.8508\n",
      "[Epoch: 129] Average loss: 876.6118, val_loss: 1172.4209\n",
      "[Epoch: 130] Average loss: 1004.9678, val_loss: 1021.6887\n",
      "[Epoch: 131] Average loss: 1020.7967, val_loss: 1083.0452\n",
      "[Epoch: 132] Average loss: 2282.6885, val_loss: 1669.4282\n",
      "[Epoch: 133] Average loss: 990.6227, val_loss: 966.9620\n",
      "[Epoch: 134] Average loss: 1054.6979, val_loss: 1194.0916\n",
      "[Epoch: 135] Average loss: 1004.5624, val_loss: 1127.9746\n",
      "[Epoch: 136] Average loss: 864.8516, val_loss: 1330.7495\n",
      "[Epoch: 137] Average loss: 1062.1837, val_loss: 1043.7760\n",
      "[Epoch: 138] Average loss: 1015.5804, val_loss: 1034.7863\n",
      "[Epoch: 139] Average loss: 1352.5554, val_loss: 1204.0131\n",
      "[Epoch: 140] Average loss: 1280.5216, val_loss: 1183.9761\n",
      "[Epoch: 141] Average loss: 902.9941, val_loss: 1219.0320\n",
      "[Epoch: 142] Average loss: 928.9954, val_loss: 1284.5782\n",
      "[Epoch: 143] Average loss: 1232.8256, val_loss: 1160.9661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 144] Average loss: 1049.0756, val_loss: 1152.4504\n",
      "[Epoch: 145] Average loss: 2683.9854, val_loss: 1509.7109\n",
      "[Epoch: 146] Average loss: 1160.0051, val_loss: 1167.3109\n",
      "[Epoch: 147] Average loss: 914.3068, val_loss: 1234.5750\n",
      "[Epoch: 148] Average loss: 844.8141, val_loss: 1206.8271\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    avg_loss = 0\n",
    "\n",
    "    for Image, X1, X2, Y in train_loader:\n",
    "        Image = Image.to(device)\n",
    "        X1 = X1.to(device)\n",
    "        X2 = X2.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        prediction = model(Image, X1, X2)\n",
    "        loss = torch.sqrt(criterion(prediction, Y)).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss / len(train_loader)\n",
    "    print(f'[Epoch: {epoch+1:>2}] Average loss: {avg_loss:.4f}, ', end='')\n",
    "    \n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    with torch.no_grad():\n",
    "        val_avg_loss = 0.\n",
    "        for Image_val, X1_val, X2_val, Y_val in val_loader:\n",
    "            Image_val = Image_val.to(device)\n",
    "            X1_val = X1_val.to(device)\n",
    "            X2_val = X2_val.to(device)\n",
    "            Y_val = Y_val.to(device)\n",
    "            val_prediction = model(Image_val, X1_val, X2_val)\n",
    "            val_loss = torch.sqrt(criterion(val_prediction, Y_val)).to(device)\n",
    "            val_avg_loss += val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"val_loss: {val_avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a531a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-25T11:45:48.409Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "criterion.eval()\n",
    "ss_tot = 0\n",
    "ss_res = 0\n",
    "with torch.no_grad():\n",
    "    for Image_test, X1_test, X2_test, Y_test in test_loader:\n",
    "        Image_test =Image_test.to(device)\n",
    "        X1_test = X1_test.to(device)\n",
    "        X2_test = X2_test.to(device)\n",
    "        Y_test = Y_test.to(device)\n",
    "        prediction = model(Image_test, X1_test, X2_test)\n",
    "        mean = torch.mean(Y_test)\n",
    "        ss_tot += torch.sum((Y_test - mean) ** 2)\n",
    "        ss_res += torch.sum((Y_test - prediction) ** 2)\n",
    "    \n",
    "    accuracy = 1 - ss_res/ss_tot\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python-3-9-7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
