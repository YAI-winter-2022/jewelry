{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7bf85c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T18:38:42.553401Z",
     "start_time": "2022-02-24T18:38:41.811159Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88539da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T18:38:42.569358Z",
     "start_time": "2022-02-24T18:38:42.553401Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_path = \"final.csv\"\n",
    "image_path = \"./images\"\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c5b968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T18:38:42.692972Z",
     "start_time": "2022-02-24T18:38:42.570356Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78410749",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T18:38:42.708929Z",
     "start_time": "2022-02-24T18:38:42.693975Z"
    }
   },
   "outputs": [],
   "source": [
    "class AllDataset(Dataset):\n",
    "    def __init__(self, csv_path, image_path, image_transform=transforms.Compose([transforms.ToTensor()])):\n",
    "        super(AllDataset).__init__()\n",
    "        csv = pd.read_csv(csv_path)\n",
    "        csv_np = csv.to_numpy()\n",
    "        self.images = []\n",
    "        for Id in csv['Id']:\n",
    "            Id = str(Id)\n",
    "            image = Image.open(image_path+'/'+Id+'.jpg')\n",
    "            self.images.append(image_transform(image))\n",
    "            image.close()\n",
    "        \n",
    "        for i in [1, 3, 4, 5, 6, 7, 8]:\n",
    "            wordset = {word: idx for idx, word in enumerate(np.unique(csv_np[:,i]))}\n",
    "            for row in range(len(csv_np)):\n",
    "                csv_np[row][i] = wordset[csv_np[row][i]]\n",
    "        self.ints = torch.from_numpy(np.array(csv_np[:,[1,3,4,5,6,7,8]], dtype=\"int\"))\n",
    "        self.floats = torch.from_numpy(np.array(csv_np[:,[2,9,10,11]], dtype=\"float\")).float()\n",
    "        self.target = torch.from_numpy(np.array(csv_np[:,[12]], dtype=\"float\")).float()\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.images[idx], self.ints[idx],self.floats[idx], self.target[idx]\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8af2023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T18:38:49.789011Z",
     "start_time": "2022-02-24T18:38:42.708929Z"
    }
   },
   "outputs": [],
   "source": [
    "data_length = len(pd.read_csv(csv_path))\n",
    "train_length = int(data_length * 0.6)\n",
    "test_length = int(data_length * 0.2)\n",
    "val_length = data_length - train_length - test_length\n",
    "\n",
    "image_transform = transforms.Compose([transforms.ToTensor()\n",
    "                                     ])\n",
    "\n",
    "train_dataset = AllDataset(csv_path, image_path, image_transform)\n",
    "train_dataset, test_dataset = random_split(train_dataset, [train_length, test_length+val_length])\n",
    "test_dataset, val_dataset = random_split(test_dataset, [test_length, val_length])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a46f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T18:38:49.804968Z",
     "start_time": "2022-02-24T18:38:49.790008Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.resnet18 = torchvision.models.resnet18(pretrained=False)\n",
    "        self.resnet18.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet18.fc = nn.Sequential(nn.Linear(512, 4096),\n",
    "                                         nn.BatchNorm1d(4096),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout()\n",
    "                                        )\n",
    "        self.resenet18 = self.resnet18.to(device)\n",
    "        \n",
    "        self.emb1 = torch.nn.Embedding(8, 20)\n",
    "        self.emb2 = torch.nn.Embedding(11, 20)\n",
    "        self.emb3 = torch.nn.Embedding(20, 20)\n",
    "        self.emb4 = torch.nn.Embedding(4, 20)\n",
    "        self.emb5 = torch.nn.Embedding(4, 20)\n",
    "        self.emb6 = torch.nn.Embedding(4, 20)\n",
    "        self.emb7 = torch.nn.Embedding(7, 20)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc = nn.Linear(4, 80)\n",
    "        self.csvbn = nn.BatchNorm1d(80)\n",
    "        self.csvfc1 = nn.Linear(220, 8192)\n",
    "        self.csvfc2 = nn.Linear(8192, 8192)\n",
    "        self.csvfc3 = nn.Linear(8192, 4096)\n",
    "        self.csvbn1 = nn.BatchNorm1d(8192)\n",
    "        self.csvbn2 = nn.BatchNorm1d(8192)\n",
    "        self.csvbn3 = nn.BatchNorm1d(4096)\n",
    "        \n",
    "        self.fc1 = nn.Linear(8192, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(4096)\n",
    "        self.dropout = nn.Dropout()\n",
    "    \n",
    "    def forward(self, image, x, y):\n",
    "        image = self.resnet18(image)\n",
    "        \n",
    "        x1 = self.emb1(x[:,0])\n",
    "        x2 = self.emb2(x[:,1])\n",
    "        x3 = self.emb3(x[:,2])\n",
    "        x4 = self.emb4(x[:,3])\n",
    "        x5 = self.emb5(x[:,4])\n",
    "        x6 = self.emb6(x[:,5])\n",
    "        x7 = self.emb7(x[:,6])\n",
    "        y = self.csvbn(self.fc(y))\n",
    "        x = torch.cat((x1, x2, x3, x4, x5, x6, x7, y), dim=1)\n",
    "        \n",
    "        x = self.dropout(self.act(self.csvbn1(self.csvfc1(x))))\n",
    "        x = self.dropout(self.act(self.csvbn2(self.csvfc2(x))))\n",
    "        x = self.dropout(self.act(self.csvbn3(self.csvfc3(x))))\n",
    "        x = torch.cat((x, image), dim=1)\n",
    "        \n",
    "        x = self.dropout(self.act(self.bn1(self.fc1(x))))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3749f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T18:38:50.619520Z",
     "start_time": "2022-02-24T18:38:49.804968Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad748bfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T18:58:27.204393Z",
     "start_time": "2022-02-24T18:38:50.620490Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:  1] Average loss: 4596.6143, val_loss: 4781.8906\n",
      "[Epoch:  2] Average loss: 4494.8154, val_loss: 4299.6875\n",
      "[Epoch:  3] Average loss: 4406.4683, val_loss: 4405.1904\n",
      "[Epoch:  4] Average loss: 4606.4419, val_loss: 4331.0952\n",
      "[Epoch:  5] Average loss: 4301.9302, val_loss: 4082.8333\n",
      "[Epoch:  6] Average loss: 4247.0342, val_loss: 4456.7246\n",
      "[Epoch:  7] Average loss: 4269.2734, val_loss: 4402.0703\n",
      "[Epoch:  8] Average loss: 4556.2451, val_loss: 4638.7290\n",
      "[Epoch:  9] Average loss: 4172.8154, val_loss: 4034.5176\n",
      "[Epoch: 10] Average loss: 3995.3066, val_loss: 4052.1890\n",
      "[Epoch: 11] Average loss: 4785.1392, val_loss: 4070.7100\n",
      "[Epoch: 12] Average loss: 3900.6819, val_loss: 3995.6794\n",
      "[Epoch: 13] Average loss: 3980.2500, val_loss: 3961.5649\n",
      "[Epoch: 14] Average loss: 3913.4407, val_loss: 3960.2341\n",
      "[Epoch: 15] Average loss: 3730.7915, val_loss: 3823.4019\n",
      "[Epoch: 16] Average loss: 5204.5674, val_loss: 3739.1116\n",
      "[Epoch: 17] Average loss: 3622.3970, val_loss: 3542.1091\n",
      "[Epoch: 18] Average loss: 3538.0669, val_loss: 3200.8386\n",
      "[Epoch: 19] Average loss: 3623.7546, val_loss: 3344.4917\n",
      "[Epoch: 20] Average loss: 3380.1882, val_loss: 3165.2515\n",
      "[Epoch: 21] Average loss: 3399.4534, val_loss: 3327.2808\n",
      "[Epoch: 22] Average loss: 3257.9648, val_loss: 2768.3296\n",
      "[Epoch: 23] Average loss: 3229.9990, val_loss: 2730.5732\n",
      "[Epoch: 24] Average loss: 3106.9460, val_loss: 2894.3013\n",
      "[Epoch: 25] Average loss: 3006.3843, val_loss: 2949.9082\n",
      "[Epoch: 26] Average loss: 2886.7324, val_loss: 2377.7749\n",
      "[Epoch: 27] Average loss: 3106.2524, val_loss: 2732.8555\n",
      "[Epoch: 28] Average loss: 2874.1387, val_loss: 2864.5752\n",
      "[Epoch: 29] Average loss: 2731.2095, val_loss: 2620.7288\n",
      "[Epoch: 30] Average loss: 2939.2239, val_loss: 2243.6606\n",
      "[Epoch: 31] Average loss: 4542.1543, val_loss: 3056.3176\n",
      "[Epoch: 32] Average loss: 2614.0432, val_loss: 2149.4387\n",
      "[Epoch: 33] Average loss: 2562.0251, val_loss: 2403.8691\n",
      "[Epoch: 34] Average loss: 2301.8223, val_loss: 2385.4067\n",
      "[Epoch: 35] Average loss: 2227.0327, val_loss: 1941.0574\n",
      "[Epoch: 36] Average loss: 2215.1047, val_loss: 1849.4889\n",
      "[Epoch: 37] Average loss: 2385.0588, val_loss: 1755.7449\n",
      "[Epoch: 38] Average loss: 2092.1816, val_loss: 1682.9623\n",
      "[Epoch: 39] Average loss: 2105.4329, val_loss: 1433.1353\n",
      "[Epoch: 40] Average loss: 2056.3462, val_loss: 1506.5554\n",
      "[Epoch: 41] Average loss: 2000.9242, val_loss: 1679.9531\n",
      "[Epoch: 42] Average loss: 1986.9196, val_loss: 1456.6843\n",
      "[Epoch: 43] Average loss: 1806.9749, val_loss: 1381.4574\n",
      "[Epoch: 44] Average loss: 1753.5204, val_loss: 1386.3419\n",
      "[Epoch: 45] Average loss: 1912.1005, val_loss: 1645.8314\n",
      "[Epoch: 46] Average loss: 1698.6871, val_loss: 1385.0939\n",
      "[Epoch: 47] Average loss: 1684.7510, val_loss: 1181.8904\n",
      "[Epoch: 48] Average loss: 1704.2781, val_loss: 1741.8159\n",
      "[Epoch: 49] Average loss: 1951.5042, val_loss: 1389.5601\n",
      "[Epoch: 50] Average loss: 1672.2556, val_loss: 1499.4786\n",
      "[Epoch: 51] Average loss: 1690.3127, val_loss: 1222.2350\n",
      "[Epoch: 52] Average loss: 1626.4193, val_loss: 1298.6676\n",
      "[Epoch: 53] Average loss: 1544.8601, val_loss: 1335.8997\n",
      "[Epoch: 54] Average loss: 1485.8209, val_loss: 1219.7495\n",
      "[Epoch: 55] Average loss: 1274.0793, val_loss: 1293.3885\n",
      "[Epoch: 56] Average loss: 1629.7672, val_loss: 1407.6951\n",
      "[Epoch: 57] Average loss: 1559.2261, val_loss: 1452.0731\n",
      "[Epoch: 58] Average loss: 1446.4377, val_loss: 1170.7666\n",
      "[Epoch: 59] Average loss: 1389.6818, val_loss: 1453.4542\n",
      "[Epoch: 60] Average loss: 1627.7131, val_loss: 1557.2375\n",
      "[Epoch: 61] Average loss: 1367.9326, val_loss: 1371.5930\n",
      "[Epoch: 62] Average loss: 1228.4341, val_loss: 1261.3152\n",
      "[Epoch: 63] Average loss: 1327.8628, val_loss: 1316.7390\n",
      "[Epoch: 64] Average loss: 1329.0739, val_loss: 1404.3740\n",
      "[Epoch: 65] Average loss: 1292.1643, val_loss: 1175.2404\n",
      "[Epoch: 66] Average loss: 1345.6652, val_loss: 1176.2413\n",
      "[Epoch: 67] Average loss: 1157.5250, val_loss: 1260.8599\n",
      "[Epoch: 68] Average loss: 2538.5171, val_loss: 1611.8379\n",
      "[Epoch: 69] Average loss: 1114.9956, val_loss: 1350.0502\n",
      "[Epoch: 70] Average loss: 1273.9469, val_loss: 1339.8137\n",
      "[Epoch: 71] Average loss: 1198.6718, val_loss: 1283.5626\n",
      "[Epoch: 72] Average loss: 1200.5988, val_loss: 1209.1086\n",
      "[Epoch: 73] Average loss: 2353.2520, val_loss: 1217.4917\n",
      "[Epoch: 74] Average loss: 1279.8068, val_loss: 1306.6450\n",
      "[Epoch: 75] Average loss: 1281.2871, val_loss: 1168.9534\n",
      "[Epoch: 76] Average loss: 1241.4197, val_loss: 1093.1361\n",
      "[Epoch: 77] Average loss: 1299.8005, val_loss: 1432.7949\n",
      "[Epoch: 78] Average loss: 1165.8527, val_loss: 1370.6929\n",
      "[Epoch: 79] Average loss: 1044.6956, val_loss: 1655.6112\n",
      "[Epoch: 80] Average loss: 1061.6116, val_loss: 1664.0524\n",
      "[Epoch: 81] Average loss: 1429.1522, val_loss: 1453.3674\n",
      "[Epoch: 82] Average loss: 2965.6821, val_loss: 1566.1765\n",
      "[Epoch: 83] Average loss: 1089.1168, val_loss: 1215.5262\n",
      "[Epoch: 84] Average loss: 1148.5594, val_loss: 1312.5200\n",
      "[Epoch: 85] Average loss: 1531.3713, val_loss: 1388.8191\n",
      "[Epoch: 86] Average loss: 1259.8757, val_loss: 1195.3790\n",
      "[Epoch: 87] Average loss: 1047.0165, val_loss: 1310.6848\n",
      "[Epoch: 88] Average loss: 1038.8878, val_loss: 1243.6387\n",
      "[Epoch: 89] Average loss: 987.4346, val_loss: 1144.9537\n",
      "[Epoch: 90] Average loss: 1162.1002, val_loss: 1214.3204\n",
      "[Epoch: 91] Average loss: 1075.8926, val_loss: 1154.4902\n",
      "[Epoch: 92] Average loss: 1168.0767, val_loss: 1340.1304\n",
      "[Epoch: 93] Average loss: 1253.5461, val_loss: 1205.6055\n",
      "[Epoch: 94] Average loss: 1034.1544, val_loss: 1135.6067\n",
      "[Epoch: 95] Average loss: 959.8814, val_loss: 1195.3057\n",
      "[Epoch: 96] Average loss: 1188.2651, val_loss: 1610.8170\n",
      "[Epoch: 97] Average loss: 1173.6824, val_loss: 1097.3771\n",
      "[Epoch: 98] Average loss: 1742.2450, val_loss: 1161.0338\n",
      "[Epoch: 99] Average loss: 1098.9628, val_loss: 1230.6221\n",
      "[Epoch: 100] Average loss: 1262.1147, val_loss: 1218.2617\n",
      "[Epoch: 101] Average loss: 1249.8572, val_loss: 1624.3993\n",
      "[Epoch: 102] Average loss: 1343.0735, val_loss: 1412.2974\n",
      "[Epoch: 103] Average loss: 990.3375, val_loss: 1245.9717\n",
      "[Epoch: 104] Average loss: 1190.5952, val_loss: 1183.6940\n",
      "[Epoch: 105] Average loss: 919.7414, val_loss: 1423.7026\n",
      "[Epoch: 106] Average loss: 2221.7083, val_loss: 1457.6180\n",
      "[Epoch: 107] Average loss: 1043.1362, val_loss: 1191.4567\n",
      "[Epoch: 108] Average loss: 1040.9301, val_loss: 1120.5669\n",
      "[Epoch: 109] Average loss: 1213.1179, val_loss: 1479.7200\n",
      "[Epoch: 110] Average loss: 992.7593, val_loss: 1313.2948\n",
      "[Epoch: 111] Average loss: 1065.4431, val_loss: 1244.5603\n",
      "[Epoch: 112] Average loss: 1092.6169, val_loss: 1035.2672\n",
      "[Epoch: 113] Average loss: 1001.8552, val_loss: 1174.8430\n",
      "[Epoch: 114] Average loss: 1636.7355, val_loss: 1501.3260\n",
      "[Epoch: 115] Average loss: 1036.1547, val_loss: 1136.3787\n",
      "[Epoch: 116] Average loss: 2110.4319, val_loss: 1531.4486\n",
      "[Epoch: 117] Average loss: 1161.9945, val_loss: 1184.5573\n",
      "[Epoch: 118] Average loss: 1062.8420, val_loss: 1066.8098\n",
      "[Epoch: 119] Average loss: 1001.9921, val_loss: 1152.0327\n",
      "[Epoch: 120] Average loss: 909.5225, val_loss: 1075.5502\n",
      "[Epoch: 121] Average loss: 1478.1284, val_loss: 1234.4146\n",
      "[Epoch: 122] Average loss: 1288.1177, val_loss: 1226.9993\n",
      "[Epoch: 123] Average loss: 955.1484, val_loss: 1389.3502\n",
      "[Epoch: 124] Average loss: 929.7291, val_loss: 1044.3639\n",
      "[Epoch: 125] Average loss: 794.2891, val_loss: 1211.5933\n",
      "[Epoch: 126] Average loss: 898.4917, val_loss: 1054.5321\n",
      "[Epoch: 127] Average loss: 912.3570, val_loss: 1011.8746\n",
      "[Epoch: 128] Average loss: 987.9824, val_loss: 1648.9203\n",
      "[Epoch: 129] Average loss: 852.8420, val_loss: 1040.1154\n",
      "[Epoch: 130] Average loss: 1156.1057, val_loss: 1072.2393\n",
      "[Epoch: 131] Average loss: 1146.8210, val_loss: 1152.4978\n",
      "[Epoch: 132] Average loss: 933.9056, val_loss: 1281.7466\n",
      "[Epoch: 133] Average loss: 910.1888, val_loss: 1184.3174\n",
      "[Epoch: 134] Average loss: 907.4397, val_loss: 1237.4504\n",
      "[Epoch: 135] Average loss: 1077.6664, val_loss: 1190.7346\n",
      "[Epoch: 136] Average loss: 1075.0142, val_loss: 1226.5870\n",
      "[Epoch: 137] Average loss: 861.1502, val_loss: 1626.5502\n",
      "[Epoch: 138] Average loss: 1149.9121, val_loss: 1185.0895\n",
      "[Epoch: 139] Average loss: 1040.9292, val_loss: 1215.9744\n",
      "[Epoch: 140] Average loss: 1036.4949, val_loss: 1242.1333\n",
      "[Epoch: 141] Average loss: 1079.2659, val_loss: 1145.7161\n",
      "[Epoch: 142] Average loss: 765.4210, val_loss: 1242.7133\n",
      "[Epoch: 143] Average loss: 1023.1677, val_loss: 1259.5237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 144] Average loss: 906.2473, val_loss: 1169.9846\n",
      "[Epoch: 145] Average loss: 2132.9141, val_loss: 1272.2814\n",
      "[Epoch: 146] Average loss: 1148.2400, val_loss: 1409.9351\n",
      "[Epoch: 147] Average loss: 930.1148, val_loss: 1192.2170\n",
      "[Epoch: 148] Average loss: 746.7089, val_loss: 1177.4508\n",
      "[Epoch: 149] Average loss: 918.8292, val_loss: 1301.2992\n",
      "[Epoch: 150] Average loss: 1017.2535, val_loss: 1322.0310\n",
      "[Epoch: 151] Average loss: 1066.6678, val_loss: 1273.9910\n",
      "[Epoch: 152] Average loss: 785.9244, val_loss: 1405.8866\n",
      "[Epoch: 153] Average loss: 1091.7393, val_loss: 1301.1069\n",
      "[Epoch: 154] Average loss: 1073.1073, val_loss: 1086.3059\n",
      "[Epoch: 155] Average loss: 835.4859, val_loss: 1449.1801\n",
      "[Epoch: 156] Average loss: 1037.3973, val_loss: 1211.5059\n",
      "[Epoch: 157] Average loss: 893.1290, val_loss: 1169.8937\n",
      "[Epoch: 158] Average loss: 1244.6959, val_loss: 1244.3960\n",
      "[Epoch: 159] Average loss: 962.2257, val_loss: 1148.4696\n",
      "[Epoch: 160] Average loss: 918.2781, val_loss: 1135.2908\n",
      "[Epoch: 161] Average loss: 857.6619, val_loss: 1136.7500\n",
      "[Epoch: 162] Average loss: 826.7157, val_loss: 1250.4044\n",
      "[Epoch: 163] Average loss: 794.9833, val_loss: 1227.6196\n",
      "[Epoch: 164] Average loss: 940.6963, val_loss: 1379.0530\n",
      "[Epoch: 165] Average loss: 863.3803, val_loss: 964.7218\n",
      "[Epoch: 166] Average loss: 1064.8090, val_loss: 1322.8203\n",
      "[Epoch: 167] Average loss: 1087.2744, val_loss: 1118.8735\n",
      "[Epoch: 168] Average loss: 842.5048, val_loss: 1033.8798\n",
      "[Epoch: 169] Average loss: 884.4050, val_loss: 1197.0778\n",
      "[Epoch: 170] Average loss: 1539.2352, val_loss: 1385.7656\n",
      "[Epoch: 171] Average loss: 806.4846, val_loss: 1241.2937\n",
      "[Epoch: 172] Average loss: 1066.8247, val_loss: 1155.5609\n",
      "[Epoch: 173] Average loss: 900.3679, val_loss: 1157.5487\n",
      "[Epoch: 174] Average loss: 961.1597, val_loss: 1178.5775\n",
      "[Epoch: 175] Average loss: 877.4755, val_loss: 1296.2087\n",
      "[Epoch: 176] Average loss: 1084.0219, val_loss: 1382.9247\n",
      "[Epoch: 177] Average loss: 840.4668, val_loss: 1166.1171\n",
      "[Epoch: 178] Average loss: 786.1100, val_loss: 1377.2866\n",
      "[Epoch: 179] Average loss: 995.5322, val_loss: 1496.3757\n",
      "[Epoch: 180] Average loss: 911.7463, val_loss: 1258.5167\n",
      "[Epoch: 181] Average loss: 762.4614, val_loss: 1157.6096\n",
      "[Epoch: 182] Average loss: 911.7521, val_loss: 1229.2008\n",
      "[Epoch: 183] Average loss: 1081.3490, val_loss: 1054.2297\n",
      "[Epoch: 184] Average loss: 786.3404, val_loss: 1093.8036\n",
      "[Epoch: 185] Average loss: 1184.7760, val_loss: 1077.6538\n",
      "[Epoch: 186] Average loss: 1026.7565, val_loss: 1211.5569\n",
      "[Epoch: 187] Average loss: 963.0833, val_loss: 1164.3367\n",
      "[Epoch: 188] Average loss: 1041.5891, val_loss: 1269.3898\n",
      "[Epoch: 189] Average loss: 1156.8224, val_loss: 1269.8218\n",
      "[Epoch: 190] Average loss: 1083.4318, val_loss: 1243.7384\n",
      "[Epoch: 191] Average loss: 767.7780, val_loss: 1253.6456\n",
      "[Epoch: 192] Average loss: 941.1210, val_loss: 1207.3999\n",
      "[Epoch: 193] Average loss: 909.9651, val_loss: 1205.5981\n",
      "[Epoch: 194] Average loss: 987.8707, val_loss: 1083.7988\n",
      "[Epoch: 195] Average loss: 895.5728, val_loss: 1099.3325\n",
      "[Epoch: 196] Average loss: 868.1249, val_loss: 1334.9984\n",
      "[Epoch: 197] Average loss: 856.1047, val_loss: 1211.0254\n",
      "[Epoch: 198] Average loss: 810.5581, val_loss: 1120.9117\n",
      "[Epoch: 199] Average loss: 998.4445, val_loss: 1156.8036\n",
      "[Epoch: 200] Average loss: 967.5942, val_loss: 1173.4133\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    avg_loss = 0\n",
    "\n",
    "    for Image, X1, X2, Y in train_loader:\n",
    "        Image = Image.to(device)\n",
    "        X1 = X1.to(device)\n",
    "        X2 = X2.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        prediction = model(Image, X1, X2)\n",
    "        loss = torch.sqrt(criterion(prediction, Y)).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss / len(train_loader)\n",
    "    print(f'[Epoch: {epoch+1:>2}] Average loss: {avg_loss:.4f}, ', end='')\n",
    "    \n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    with torch.no_grad():\n",
    "        val_avg_loss = 0.\n",
    "        for Image_val, X1_val, X2_val, Y_val in val_loader:\n",
    "            Image_val = Image_val.to(device)\n",
    "            X1_val = X1_val.to(device)\n",
    "            X2_val = X2_val.to(device)\n",
    "            Y_val = Y_val.to(device)\n",
    "            val_prediction = model(Image_val, X1_val, X2_val)\n",
    "            val_loss = torch.sqrt(criterion(val_prediction, Y_val)).to(device)\n",
    "            val_avg_loss += val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"val_loss: {val_avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "434a531a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T18:58:27.831068Z",
     "start_time": "2022-02-24T18:58:27.205392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.93%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "criterion.eval()\n",
    "ss_tot = 0\n",
    "ss_res = 0\n",
    "with torch.no_grad():\n",
    "    for Image_test, X1_test, X2_test, Y_test in test_loader:\n",
    "        Image_test =Image_test.to(device)\n",
    "        X1_test = X1_test.to(device)\n",
    "        X2_test = X2_test.to(device)\n",
    "        Y_test = Y_test.to(device)\n",
    "        prediction = model(Image_test, X1_test, X2_test)\n",
    "        mean = torch.mean(Y_test)\n",
    "        ss_tot += torch.sum((Y_test - mean) ** 2)\n",
    "        ss_res += torch.sum((Y_test - prediction) ** 2)\n",
    "    \n",
    "    accuracy = 1 - ss_res/ss_tot\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python-3-9-7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
