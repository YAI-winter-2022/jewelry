{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:23:46.456521Z",
     "start_time": "2022-02-24T13:23:45.723300Z"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1645248583756,
     "user": {
      "displayName": "석진혁(공과대학 기계공학)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04829476984882153292"
     },
     "user_tz": -540
    },
    "id": "gala7GMLTriy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:23:46.472366Z",
     "start_time": "2022-02-24T13:23:46.457519Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_path = \"final.csv\"\n",
    "image_path = \"./images\"\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:23:46.596228Z",
     "start_time": "2022-02-24T13:23:46.473363Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:23:46.612233Z",
     "start_time": "2022-02-24T13:23:46.596228Z"
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1645248727632,
     "user": {
      "displayName": "석진혁(공과대학 기계공학)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04829476984882153292"
     },
     "user_tz": -540
    },
    "id": "S2aoNXxHSGUw"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_path, image_path, image_transform=transforms.Compose([transforms.ToTensor()])):\n",
    "        super(ImageDataset).__init__()\n",
    "        csv = pd.read_csv(csv_path)\n",
    "        csv_np = csv.to_numpy()\n",
    "        self.images = []\n",
    "        for Id in csv['Id']:\n",
    "            Id = str(Id)\n",
    "            image = Image.open(image_path+'/'+Id+'.jpg')\n",
    "            self.images.append(image_transform(image))\n",
    "            image.close()\n",
    "        \n",
    "        self.target = torch.from_numpy(np.array(csv_np[:,[12]], dtype=\"float\")).float()\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.images[idx], self.target[idx]\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:23:53.835533Z",
     "start_time": "2022-02-24T13:23:46.613230Z"
    }
   },
   "outputs": [],
   "source": [
    "data_length = len(pd.read_csv(csv_path))\n",
    "train_length = int(data_length * 0.6)\n",
    "test_length = int(data_length * 0.2)\n",
    "val_length = data_length - train_length - test_length\n",
    "\n",
    "image_transform = transforms.Compose([transforms.ToTensor()\n",
    "                                     ])\n",
    "\n",
    "train_dataset = ImageDataset(csv_path, image_path, image_transform)\n",
    "train_dataset, test_dataset = random_split(train_dataset, [train_length, test_length+val_length])\n",
    "test_dataset, val_dataset = random_split(test_dataset, [test_length, val_length])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:23:53.851535Z",
     "start_time": "2022-02-24T13:23:53.836531Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageNet, self).__init__()\n",
    "        self.resnet18 = torchvision.models.resnet18(pretrained=False)\n",
    "        self.resnet18.fc = nn.Sequential(\n",
    "        nn.Linear(512, 4096),\n",
    "        nn.BatchNorm1d(4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 2048),\n",
    "        nn.BatchNorm1d(2048),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(2048, 1024),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(1024, 1)\n",
    "        )\n",
    "        self.resnet18.to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:23:54.209000Z",
     "start_time": "2022-02-24T13:23:53.852532Z"
    },
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1645249328264,
     "user": {
      "displayName": "석진혁(공과대학 기계공학)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04829476984882153292"
     },
     "user_tz": -540
    },
    "id": "l9xfqkslLx40"
   },
   "outputs": [],
   "source": [
    "model = ImageNet().to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:44:07.218934Z",
     "start_time": "2022-02-24T13:23:54.209000Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 786494,
     "status": "ok",
     "timestamp": 1645250118255,
     "user": {
      "displayName": "석진혁(공과대학 기계공학)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04829476984882153292"
     },
     "user_tz": -540
    },
    "id": "HTmDcy0gVAoM",
    "outputId": "355d74c4-e47f-45a7-b321-6aa19d66ac02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:  1] Average loss: 4572.0889, val_loss: 4863.4121\n",
      "[Epoch:  2] Average loss: 4566.9805, val_loss: 4890.8384\n",
      "[Epoch:  3] Average loss: 4503.0176, val_loss: 4823.6953\n",
      "[Epoch:  4] Average loss: 4574.6846, val_loss: 5000.8096\n",
      "[Epoch:  5] Average loss: 4517.0200, val_loss: 4512.5684\n",
      "[Epoch:  6] Average loss: 4319.8184, val_loss: 4100.5010\n",
      "[Epoch:  7] Average loss: 4435.8877, val_loss: 4912.2930\n",
      "[Epoch:  8] Average loss: 4724.2705, val_loss: 4817.5645\n",
      "[Epoch:  9] Average loss: 6200.4189, val_loss: 4711.5063\n",
      "[Epoch: 10] Average loss: 4397.5781, val_loss: 4624.6470\n",
      "[Epoch: 11] Average loss: 4538.6699, val_loss: 4875.1357\n",
      "[Epoch: 12] Average loss: 4549.2339, val_loss: 4466.2437\n",
      "[Epoch: 13] Average loss: 4505.3730, val_loss: 4603.8525\n",
      "[Epoch: 14] Average loss: 4466.6616, val_loss: 4061.5317\n",
      "[Epoch: 15] Average loss: 4573.0615, val_loss: 4203.7974\n",
      "[Epoch: 16] Average loss: 4420.8696, val_loss: 4396.5713\n",
      "[Epoch: 17] Average loss: 4286.6011, val_loss: 4777.4912\n",
      "[Epoch: 18] Average loss: 4336.1182, val_loss: 4774.7803\n",
      "[Epoch: 19] Average loss: 4249.6680, val_loss: 4580.3193\n",
      "[Epoch: 20] Average loss: 4542.2632, val_loss: 4750.3569\n",
      "[Epoch: 21] Average loss: 5562.7490, val_loss: 4965.4507\n",
      "[Epoch: 22] Average loss: 4197.6304, val_loss: 4642.9419\n",
      "[Epoch: 23] Average loss: 4248.5332, val_loss: 4809.9248\n",
      "[Epoch: 24] Average loss: 4047.8918, val_loss: 4864.1240\n",
      "[Epoch: 25] Average loss: 4084.1736, val_loss: 4828.9229\n",
      "[Epoch: 26] Average loss: 4134.9072, val_loss: 4748.9507\n",
      "[Epoch: 27] Average loss: 4151.1113, val_loss: 4441.5273\n",
      "[Epoch: 28] Average loss: 4154.3779, val_loss: 5647.6562\n",
      "[Epoch: 29] Average loss: 4077.4961, val_loss: 4302.4072\n",
      "[Epoch: 30] Average loss: 4000.3188, val_loss: 4767.3672\n",
      "[Epoch: 31] Average loss: 3900.2629, val_loss: 4930.8291\n",
      "[Epoch: 32] Average loss: 4128.4907, val_loss: 4376.8179\n",
      "[Epoch: 33] Average loss: 3905.7166, val_loss: 4534.1099\n",
      "[Epoch: 34] Average loss: 3949.5398, val_loss: 4833.6157\n",
      "[Epoch: 35] Average loss: 3872.6108, val_loss: 4562.9478\n",
      "[Epoch: 36] Average loss: 3930.8589, val_loss: 4709.3706\n",
      "[Epoch: 37] Average loss: 3910.0269, val_loss: 4185.5977\n",
      "[Epoch: 38] Average loss: 3825.3347, val_loss: 4600.1982\n",
      "[Epoch: 39] Average loss: 3786.4653, val_loss: 4599.4653\n",
      "[Epoch: 40] Average loss: 3832.8025, val_loss: 4772.3745\n",
      "[Epoch: 41] Average loss: 3791.3135, val_loss: 4327.1821\n",
      "[Epoch: 42] Average loss: 3695.1726, val_loss: 4712.3281\n",
      "[Epoch: 43] Average loss: 3581.6057, val_loss: 4758.9287\n",
      "[Epoch: 44] Average loss: 3717.9033, val_loss: 4515.0840\n",
      "[Epoch: 45] Average loss: 3610.5500, val_loss: 4696.2998\n",
      "[Epoch: 46] Average loss: 3885.7417, val_loss: 4830.7285\n",
      "[Epoch: 47] Average loss: 3503.7441, val_loss: 4524.5181\n",
      "[Epoch: 48] Average loss: 3442.1711, val_loss: 4622.0732\n",
      "[Epoch: 49] Average loss: 3431.5547, val_loss: 4646.9995\n",
      "[Epoch: 50] Average loss: 3418.7754, val_loss: 4275.2314\n",
      "[Epoch: 51] Average loss: 3423.7910, val_loss: 4235.6514\n",
      "[Epoch: 52] Average loss: 3288.7258, val_loss: 4454.6738\n",
      "[Epoch: 53] Average loss: 3196.0146, val_loss: 3927.0149\n",
      "[Epoch: 54] Average loss: 3538.2607, val_loss: 4681.0068\n",
      "[Epoch: 55] Average loss: 3144.3381, val_loss: 4458.4814\n",
      "[Epoch: 56] Average loss: 3327.6697, val_loss: 4097.8726\n",
      "[Epoch: 57] Average loss: 3223.1980, val_loss: 4408.9873\n",
      "[Epoch: 58] Average loss: 2996.9551, val_loss: 4151.3735\n",
      "[Epoch: 59] Average loss: 3996.1196, val_loss: 4341.1323\n",
      "[Epoch: 60] Average loss: 3301.6855, val_loss: 4444.8193\n",
      "[Epoch: 61] Average loss: 2907.2332, val_loss: 4117.2197\n",
      "[Epoch: 62] Average loss: 2792.7202, val_loss: 3898.0613\n",
      "[Epoch: 63] Average loss: 2934.0159, val_loss: 4289.4858\n",
      "[Epoch: 64] Average loss: 3042.6907, val_loss: 5584.1426\n",
      "[Epoch: 65] Average loss: 2853.0669, val_loss: 4256.4468\n",
      "[Epoch: 66] Average loss: 3102.7271, val_loss: 4311.9155\n",
      "[Epoch: 67] Average loss: 2675.8765, val_loss: 5626.2461\n",
      "[Epoch: 68] Average loss: 2679.3877, val_loss: 5525.6235\n",
      "[Epoch: 69] Average loss: 2529.1248, val_loss: 4282.1235\n",
      "[Epoch: 70] Average loss: 2535.0063, val_loss: 4342.7817\n",
      "[Epoch: 71] Average loss: 2627.2375, val_loss: 4417.8818\n",
      "[Epoch: 72] Average loss: 2770.4219, val_loss: 4013.1462\n",
      "[Epoch: 73] Average loss: 2388.2288, val_loss: 5306.8716\n",
      "[Epoch: 74] Average loss: 2501.2944, val_loss: 8760.6289\n",
      "[Epoch: 75] Average loss: 4139.8516, val_loss: 4350.9907\n",
      "[Epoch: 76] Average loss: 2507.8594, val_loss: 4471.1353\n",
      "[Epoch: 77] Average loss: 2353.1677, val_loss: 4368.8994\n",
      "[Epoch: 78] Average loss: 2461.7263, val_loss: 5910.1777\n",
      "[Epoch: 79] Average loss: 2380.5383, val_loss: 5677.7451\n",
      "[Epoch: 80] Average loss: 2331.2224, val_loss: 4382.0195\n",
      "[Epoch: 81] Average loss: 2247.8835, val_loss: 4495.8730\n",
      "[Epoch: 82] Average loss: 2319.7214, val_loss: 4352.1748\n",
      "[Epoch: 83] Average loss: 2154.4827, val_loss: 3966.6448\n",
      "[Epoch: 84] Average loss: 2192.5178, val_loss: 3839.0037\n",
      "[Epoch: 85] Average loss: 2243.6118, val_loss: 4408.7163\n",
      "[Epoch: 86] Average loss: 2335.1924, val_loss: 4527.0508\n",
      "[Epoch: 87] Average loss: 2069.9561, val_loss: 3695.7678\n",
      "[Epoch: 88] Average loss: 1881.6694, val_loss: 4364.7505\n",
      "[Epoch: 89] Average loss: 2039.7200, val_loss: 4279.3716\n",
      "[Epoch: 90] Average loss: 2085.9082, val_loss: 4531.4585\n",
      "[Epoch: 91] Average loss: 1945.2489, val_loss: 4247.2700\n",
      "[Epoch: 92] Average loss: 1992.1055, val_loss: 5947.4624\n",
      "[Epoch: 93] Average loss: 2020.6489, val_loss: 6177.8115\n",
      "[Epoch: 94] Average loss: 2017.7894, val_loss: 5063.5942\n",
      "[Epoch: 95] Average loss: 1885.2203, val_loss: 4141.4438\n",
      "[Epoch: 96] Average loss: 1914.4094, val_loss: 4038.4614\n",
      "[Epoch: 97] Average loss: 1866.4934, val_loss: 6686.6758\n",
      "[Epoch: 98] Average loss: 1879.6379, val_loss: 4251.8984\n",
      "[Epoch: 99] Average loss: 2227.6008, val_loss: 4336.3145\n",
      "[Epoch: 100] Average loss: 1862.4720, val_loss: 4009.0535\n",
      "[Epoch: 101] Average loss: 1865.7019, val_loss: 4262.6772\n",
      "[Epoch: 102] Average loss: 1852.0393, val_loss: 4186.3159\n",
      "[Epoch: 103] Average loss: 1658.9188, val_loss: 3873.4348\n",
      "[Epoch: 104] Average loss: 2836.0293, val_loss: 3760.2659\n",
      "[Epoch: 105] Average loss: 1662.2068, val_loss: 3956.5449\n",
      "[Epoch: 106] Average loss: 1573.5038, val_loss: 4253.8706\n",
      "[Epoch: 107] Average loss: 1603.8916, val_loss: 4316.0127\n",
      "[Epoch: 108] Average loss: 1644.4349, val_loss: 4165.5776\n",
      "[Epoch: 109] Average loss: 1806.9351, val_loss: 4296.5889\n",
      "[Epoch: 110] Average loss: 1577.6466, val_loss: 4086.1096\n",
      "[Epoch: 111] Average loss: 1556.2380, val_loss: 4252.0205\n",
      "[Epoch: 112] Average loss: 1525.6503, val_loss: 4312.1030\n",
      "[Epoch: 113] Average loss: 3118.4521, val_loss: 3854.0261\n",
      "[Epoch: 114] Average loss: 1397.9446, val_loss: 3933.2373\n",
      "[Epoch: 115] Average loss: 1351.5261, val_loss: 3906.5520\n",
      "[Epoch: 116] Average loss: 1371.7397, val_loss: 3602.6204\n",
      "[Epoch: 117] Average loss: 1436.6422, val_loss: 3645.1431\n",
      "[Epoch: 118] Average loss: 1455.8127, val_loss: 4154.9741\n",
      "[Epoch: 119] Average loss: 1489.9501, val_loss: 3597.8599\n",
      "[Epoch: 120] Average loss: 1591.4727, val_loss: 3740.9910\n",
      "[Epoch: 121] Average loss: 1474.2385, val_loss: 4081.2734\n",
      "[Epoch: 122] Average loss: 1381.1902, val_loss: 4336.7861\n",
      "[Epoch: 123] Average loss: 1576.3263, val_loss: 3551.9058\n",
      "[Epoch: 124] Average loss: 1614.4158, val_loss: 3874.8750\n",
      "[Epoch: 125] Average loss: 1672.7014, val_loss: 4261.4312\n",
      "[Epoch: 126] Average loss: 1355.4785, val_loss: 4016.7107\n",
      "[Epoch: 127] Average loss: 1647.1077, val_loss: 4185.1353\n",
      "[Epoch: 128] Average loss: 1360.5366, val_loss: 3583.4736\n",
      "[Epoch: 129] Average loss: 1548.9697, val_loss: 3788.0132\n",
      "[Epoch: 130] Average loss: 1494.8643, val_loss: 4005.6562\n",
      "[Epoch: 131] Average loss: 1575.4315, val_loss: 3964.2993\n",
      "[Epoch: 132] Average loss: 1367.3977, val_loss: 4310.8726\n",
      "[Epoch: 133] Average loss: 1447.8411, val_loss: 4544.8184\n",
      "[Epoch: 134] Average loss: 1485.1531, val_loss: 3645.7192\n",
      "[Epoch: 135] Average loss: 3171.8818, val_loss: 3742.0613\n",
      "[Epoch: 136] Average loss: 1437.4517, val_loss: 3801.0771\n",
      "[Epoch: 137] Average loss: 1282.5746, val_loss: 3820.3398\n",
      "[Epoch: 138] Average loss: 1250.8983, val_loss: 4293.9092\n",
      "[Epoch: 139] Average loss: 1506.2283, val_loss: 4240.9507\n",
      "[Epoch: 140] Average loss: 1362.1599, val_loss: 3709.3901\n",
      "[Epoch: 141] Average loss: 1393.0981, val_loss: 3856.7739\n",
      "[Epoch: 142] Average loss: 1256.8022, val_loss: 3527.3867\n",
      "[Epoch: 143] Average loss: 1519.5635, val_loss: 4010.3503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 144] Average loss: 1345.7349, val_loss: 3559.2500\n",
      "[Epoch: 145] Average loss: 1333.1497, val_loss: 6081.1035\n",
      "[Epoch: 146] Average loss: 1463.0696, val_loss: 5338.1206\n",
      "[Epoch: 147] Average loss: 1549.3533, val_loss: 4041.2915\n",
      "[Epoch: 148] Average loss: 1225.0027, val_loss: 4245.7891\n",
      "[Epoch: 149] Average loss: 1520.1891, val_loss: 3856.6831\n",
      "[Epoch: 150] Average loss: 1234.0702, val_loss: 3592.2451\n",
      "[Epoch: 151] Average loss: 1235.5819, val_loss: 3750.9272\n",
      "[Epoch: 152] Average loss: 1386.1284, val_loss: 4006.7271\n",
      "[Epoch: 153] Average loss: 1150.5261, val_loss: 3615.2449\n",
      "[Epoch: 154] Average loss: 2169.3391, val_loss: 4234.1323\n",
      "[Epoch: 155] Average loss: 1096.9482, val_loss: 3972.5884\n",
      "[Epoch: 156] Average loss: 1156.2188, val_loss: 4248.6133\n",
      "[Epoch: 157] Average loss: 1183.9086, val_loss: 3609.0383\n",
      "[Epoch: 158] Average loss: 1215.7528, val_loss: 4089.7185\n",
      "[Epoch: 159] Average loss: 1358.9457, val_loss: 4142.6758\n",
      "[Epoch: 160] Average loss: 1252.9128, val_loss: 3450.8843\n",
      "[Epoch: 161] Average loss: 1489.7212, val_loss: 4202.5303\n",
      "[Epoch: 162] Average loss: 1084.1122, val_loss: 4302.2563\n",
      "[Epoch: 163] Average loss: 1287.7798, val_loss: 3629.7998\n",
      "[Epoch: 164] Average loss: 1438.3209, val_loss: 3620.6838\n",
      "[Epoch: 165] Average loss: 1146.4607, val_loss: 3916.2815\n",
      "[Epoch: 166] Average loss: 2192.0381, val_loss: 3676.3113\n",
      "[Epoch: 167] Average loss: 1356.1559, val_loss: 4065.1223\n",
      "[Epoch: 168] Average loss: 1093.9618, val_loss: 4294.2588\n",
      "[Epoch: 169] Average loss: 1310.1218, val_loss: 4285.8164\n",
      "[Epoch: 170] Average loss: 1287.6584, val_loss: 4235.9639\n",
      "[Epoch: 171] Average loss: 1000.6910, val_loss: 4253.5459\n",
      "[Epoch: 172] Average loss: 1358.4650, val_loss: 3927.0454\n",
      "[Epoch: 173] Average loss: 1221.1896, val_loss: 3520.8599\n",
      "[Epoch: 174] Average loss: 1288.2046, val_loss: 4223.3242\n",
      "[Epoch: 175] Average loss: 1374.9102, val_loss: 3931.2563\n",
      "[Epoch: 176] Average loss: 1159.7948, val_loss: 4292.2295\n",
      "[Epoch: 177] Average loss: 1260.0544, val_loss: 4085.5874\n",
      "[Epoch: 178] Average loss: 1199.2253, val_loss: 3945.7651\n",
      "[Epoch: 179] Average loss: 1060.2627, val_loss: 4223.7510\n",
      "[Epoch: 180] Average loss: 1273.3741, val_loss: 3971.1287\n",
      "[Epoch: 181] Average loss: 1100.5072, val_loss: 3805.7559\n",
      "[Epoch: 182] Average loss: 1002.3062, val_loss: 4173.2515\n",
      "[Epoch: 183] Average loss: 1391.5022, val_loss: 3963.1909\n",
      "[Epoch: 184] Average loss: 1288.8663, val_loss: 4061.4209\n",
      "[Epoch: 185] Average loss: 1106.8439, val_loss: 3994.0046\n",
      "[Epoch: 186] Average loss: 1261.6890, val_loss: 3937.6541\n",
      "[Epoch: 187] Average loss: 1002.0456, val_loss: 4050.3123\n",
      "[Epoch: 188] Average loss: 1047.8579, val_loss: 4129.6982\n",
      "[Epoch: 189] Average loss: 2367.0459, val_loss: 3853.9756\n",
      "[Epoch: 190] Average loss: 1195.4943, val_loss: 4167.7642\n",
      "[Epoch: 191] Average loss: 1093.9021, val_loss: 4074.3525\n",
      "[Epoch: 192] Average loss: 1082.6115, val_loss: 3831.3926\n",
      "[Epoch: 193] Average loss: 1083.5195, val_loss: 4005.6841\n",
      "[Epoch: 194] Average loss: 957.6028, val_loss: 3743.9502\n",
      "[Epoch: 195] Average loss: 1062.9034, val_loss: 4025.8755\n",
      "[Epoch: 196] Average loss: 1116.0391, val_loss: 3930.6816\n",
      "[Epoch: 197] Average loss: 1078.4913, val_loss: 3915.4873\n",
      "[Epoch: 198] Average loss: 2061.0259, val_loss: 3878.7192\n",
      "[Epoch: 199] Average loss: 1182.6042, val_loss: 4182.9629\n",
      "[Epoch: 200] Average loss: 1252.8381, val_loss: 4036.5806\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    avg_loss = 0\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        prediction = model(X)\n",
    "        loss = torch.sqrt(criterion(prediction, Y)).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss / len(train_loader)\n",
    "    print(f'[Epoch: {epoch+1:>2}] Average loss: {avg_loss:.4f}, ', end='')\n",
    "    \n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    with torch.no_grad():\n",
    "        val_avg_loss = 0.\n",
    "        for X_val, Y_val in val_loader:\n",
    "            X_val = X_val.to(device)\n",
    "            Y_val = Y_val.to(device)\n",
    "            val_prediction = model(X_val)\n",
    "            val_loss = torch.sqrt(criterion(val_prediction, Y_val)).to(device)\n",
    "            val_avg_loss += val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"val_loss: {val_avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:44:07.959301Z",
     "start_time": "2022-02-24T13:44:07.219931Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8090,
     "status": "ok",
     "timestamp": 1645251018146,
     "user": {
      "displayName": "석진혁(공과대학 기계공학)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04829476984882153292"
     },
     "user_tz": -540
    },
    "id": "bNWcnr4RR9wP",
    "outputId": "d1174ff1-ea8b-49a9-9ce4-294874569f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 17.74%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "criterion.eval()\n",
    "ss_tot = 0\n",
    "ss_res = 0\n",
    "with torch.no_grad():\n",
    "    for X_test, Y_test in test_loader:\n",
    "        X_test = X_test.to(device)\n",
    "        Y_test = Y_test.to(device)\n",
    "        prediction = model(X_test)\n",
    "        mean = torch.mean(Y_test)\n",
    "        ss_tot += torch.sum((Y_test - mean) ** 2)\n",
    "        ss_res += torch.sum((Y_test - prediction) ** 2)\n",
    "    \n",
    "    accuracy = 1 - ss_res/ss_tot\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPfB93W6gSzubm+xCLPEP0L",
   "collapsed_sections": [],
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
