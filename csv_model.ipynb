{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a83628a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:20:22.159821Z",
     "start_time": "2022-02-24T13:20:21.418245Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a6f2fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:20:22.175779Z",
     "start_time": "2022-02-24T13:20:22.160820Z"
    }
   },
   "outputs": [],
   "source": [
    "root = \"final.csv\"\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee64c02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:20:22.282345Z",
     "start_time": "2022-02-24T13:20:22.176776Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b815b6b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:20:22.297313Z",
     "start_time": "2022-02-24T13:20:22.283333Z"
    }
   },
   "outputs": [],
   "source": [
    "class CsvDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super(CsvDataset).__init__()\n",
    "        csv = pd.read_csv(path)\n",
    "        csv_np = csv.to_numpy()\n",
    "        for i in [1, 3, 4, 5, 6, 7, 8]:\n",
    "            wordset = {word: idx for idx, word in enumerate(np.unique(csv_np[:,i]))}\n",
    "            for row in range(len(csv_np)):\n",
    "                csv_np[row][i] = wordset[csv_np[row][i]]\n",
    "        self.ints = torch.from_numpy(np.array(csv_np[:,[1,3,4,5,6,7,8]], dtype=\"int\"))\n",
    "        self.floats = torch.from_numpy(np.array(csv_np[:,[2,9,10,11]], dtype=\"float\")).float()\n",
    "        self.target = torch.from_numpy(np.array(csv_np[:,[12]], dtype=\"float\")).float()\n",
    "        \n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return self.ints[idx],self.floats[idx], self.target[idx]\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0950ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:20:22.329226Z",
     "start_time": "2022-02-24T13:20:22.298310Z"
    }
   },
   "outputs": [],
   "source": [
    "data_length = len(pd.read_csv(root))\n",
    "train_length = int(data_length * 0.6)\n",
    "test_length = int(data_length * 0.2)\n",
    "val_length = data_length - train_length - test_length\n",
    "\n",
    "train_dataset = CsvDataset(root)\n",
    "train_dataset, test_dataset = random_split(train_dataset, [train_length, test_length+val_length])\n",
    "test_dataset, val_dataset = random_split(test_dataset, [test_length, val_length])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a476a743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:20:22.345205Z",
     "start_time": "2022-02-24T13:20:22.330224Z"
    }
   },
   "outputs": [],
   "source": [
    "class CsvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CsvNet, self).__init__()\n",
    "        self.emb1 = torch.nn.Embedding(8, 20)\n",
    "        self.emb2 = torch.nn.Embedding(11, 20)\n",
    "        self.emb3 = torch.nn.Embedding(20, 20)\n",
    "        self.emb4 = torch.nn.Embedding(4, 20)\n",
    "        self.emb5 = torch.nn.Embedding(4, 20)\n",
    "        self.emb6 = torch.nn.Embedding(4, 20)\n",
    "        self.emb7 = torch.nn.Embedding(7, 20)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc = nn.Linear(4, 80)\n",
    "        self.bn = nn.BatchNorm1d(80)\n",
    "        self.fc1 = nn.Linear(220, 8192)\n",
    "        self.fc2 = nn.Linear(8192, 8192)\n",
    "        self.fc3 = nn.Linear(8192, 4096)\n",
    "        self.fc4 = nn.Linear(4096, 2048)\n",
    "        self.fc5 = nn.Linear(2048, 1024)\n",
    "        self.fc6 = nn.Linear(1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(8192)\n",
    "        self.bn2 = nn.BatchNorm1d(8192)\n",
    "        self.bn3 = nn.BatchNorm1d(4096)\n",
    "        self.bn4 = nn.BatchNorm1d(2048)\n",
    "        self.bn5 = nn.BatchNorm1d(1024)\n",
    "        self.dropout = nn.Dropout()\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x1 = self.emb1(x[:,0])\n",
    "        x2 = self.emb2(x[:,1])\n",
    "        x3 = self.emb3(x[:,2])\n",
    "        x4 = self.emb4(x[:,3])\n",
    "        x5 = self.emb5(x[:,4])\n",
    "        x6 = self.emb6(x[:,5])\n",
    "        x7 = self.emb7(x[:,6])\n",
    "        y = self.bn(self.fc(y))\n",
    "        x = torch.cat((x1, x2, x3, x4, x5, x6, x7, y), dim=1)\n",
    "        x = self.dropout(self.act(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout(self.act(self.bn2(self.fc2(x))))\n",
    "        x = self.dropout(self.act(self.bn3(self.fc3(x))))\n",
    "        x = self.dropout(self.act(self.bn4(self.fc4(x))))\n",
    "        x = self.dropout(self.act(self.bn5(self.fc5(x))))\n",
    "        return self.fc6(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57844bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:20:22.841685Z",
     "start_time": "2022-02-24T13:20:22.346203Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CsvNet().to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f910f99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:21:19.977662Z",
     "start_time": "2022-02-24T13:20:22.842671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:  1] Average loss: 4519.5762, val_loss: 4559.9575\n",
      "[Epoch:  2] Average loss: 4533.3750, val_loss: 4797.3760\n",
      "[Epoch:  3] Average loss: 4581.8599, val_loss: 5060.5278\n",
      "[Epoch:  4] Average loss: 4457.4434, val_loss: 5000.6460\n",
      "[Epoch:  5] Average loss: 4464.5142, val_loss: 4442.4307\n",
      "[Epoch:  6] Average loss: 4421.5005, val_loss: 4526.6196\n",
      "[Epoch:  7] Average loss: 4505.9775, val_loss: 4913.3276\n",
      "[Epoch:  8] Average loss: 4425.6211, val_loss: 4611.4053\n",
      "[Epoch:  9] Average loss: 4365.6475, val_loss: 4826.8535\n",
      "[Epoch: 10] Average loss: 4508.2744, val_loss: 4631.7588\n",
      "[Epoch: 11] Average loss: 4360.5522, val_loss: 4894.0371\n",
      "[Epoch: 12] Average loss: 4473.0420, val_loss: 4708.0571\n",
      "[Epoch: 13] Average loss: 4661.7061, val_loss: 4432.7959\n",
      "[Epoch: 14] Average loss: 4464.1636, val_loss: 4710.3647\n",
      "[Epoch: 15] Average loss: 4347.0547, val_loss: 4440.3643\n",
      "[Epoch: 16] Average loss: 4374.8901, val_loss: 4371.7251\n",
      "[Epoch: 17] Average loss: 4155.9185, val_loss: 4577.7129\n",
      "[Epoch: 18] Average loss: 4411.7153, val_loss: 4184.1484\n",
      "[Epoch: 19] Average loss: 4380.7583, val_loss: 4454.0571\n",
      "[Epoch: 20] Average loss: 4284.6514, val_loss: 4209.1128\n",
      "[Epoch: 21] Average loss: 4230.8687, val_loss: 4049.9106\n",
      "[Epoch: 22] Average loss: 4233.5610, val_loss: 4397.0132\n",
      "[Epoch: 23] Average loss: 4101.3145, val_loss: 4077.3425\n",
      "[Epoch: 24] Average loss: 4169.2139, val_loss: 4403.5576\n",
      "[Epoch: 25] Average loss: 4085.8682, val_loss: 4256.5542\n",
      "[Epoch: 26] Average loss: 4104.2095, val_loss: 4253.8257\n",
      "[Epoch: 27] Average loss: 4145.6934, val_loss: 4105.3003\n",
      "[Epoch: 28] Average loss: 3884.9116, val_loss: 4172.1167\n",
      "[Epoch: 29] Average loss: 4005.2266, val_loss: 4048.4902\n",
      "[Epoch: 30] Average loss: 4104.6406, val_loss: 3874.8430\n",
      "[Epoch: 31] Average loss: 3983.6138, val_loss: 4002.1421\n",
      "[Epoch: 32] Average loss: 3908.2244, val_loss: 4164.4204\n",
      "[Epoch: 33] Average loss: 4012.4131, val_loss: 3900.9053\n",
      "[Epoch: 34] Average loss: 3893.8994, val_loss: 4272.5352\n",
      "[Epoch: 35] Average loss: 3968.7446, val_loss: 4094.4114\n",
      "[Epoch: 36] Average loss: 3640.4104, val_loss: 3952.7495\n",
      "[Epoch: 37] Average loss: 3762.2114, val_loss: 3593.8242\n",
      "[Epoch: 38] Average loss: 3763.3862, val_loss: 3852.5620\n",
      "[Epoch: 39] Average loss: 3744.5393, val_loss: 3729.0105\n",
      "[Epoch: 40] Average loss: 3696.1433, val_loss: 3626.1497\n",
      "[Epoch: 41] Average loss: 3666.2571, val_loss: 3828.4800\n",
      "[Epoch: 42] Average loss: 3541.9282, val_loss: 3624.0071\n",
      "[Epoch: 43] Average loss: 4301.7803, val_loss: 4070.4785\n",
      "[Epoch: 44] Average loss: 4032.4819, val_loss: 3704.8923\n",
      "[Epoch: 45] Average loss: 3508.9802, val_loss: 3608.0862\n",
      "[Epoch: 46] Average loss: 3498.9858, val_loss: 3594.8167\n",
      "[Epoch: 47] Average loss: 3366.4836, val_loss: 3363.5942\n",
      "[Epoch: 48] Average loss: 3432.4292, val_loss: 3367.4385\n",
      "[Epoch: 49] Average loss: 3259.0691, val_loss: 3007.4468\n",
      "[Epoch: 50] Average loss: 3643.9331, val_loss: 3552.7905\n",
      "[Epoch: 51] Average loss: 3309.1809, val_loss: 3149.9199\n",
      "[Epoch: 52] Average loss: 3431.5952, val_loss: 3232.0688\n",
      "[Epoch: 53] Average loss: 3121.6826, val_loss: 3178.3501\n",
      "[Epoch: 54] Average loss: 3095.0337, val_loss: 3264.2227\n",
      "[Epoch: 55] Average loss: 3036.9822, val_loss: 3141.3254\n",
      "[Epoch: 56] Average loss: 3084.3389, val_loss: 3165.7078\n",
      "[Epoch: 57] Average loss: 3291.6465, val_loss: 2885.9597\n",
      "[Epoch: 58] Average loss: 3173.9155, val_loss: 2769.1299\n",
      "[Epoch: 59] Average loss: 2875.9175, val_loss: 2980.6431\n",
      "[Epoch: 60] Average loss: 2838.3477, val_loss: 2853.5156\n",
      "[Epoch: 61] Average loss: 2835.9575, val_loss: 2532.0276\n",
      "[Epoch: 62] Average loss: 2826.2771, val_loss: 2753.8264\n",
      "[Epoch: 63] Average loss: 2747.8850, val_loss: 2809.2683\n",
      "[Epoch: 64] Average loss: 3614.7600, val_loss: 2785.3452\n",
      "[Epoch: 65] Average loss: 2669.1829, val_loss: 2595.2358\n",
      "[Epoch: 66] Average loss: 2698.8608, val_loss: 2621.9526\n",
      "[Epoch: 67] Average loss: 2603.5520, val_loss: 2221.0532\n",
      "[Epoch: 68] Average loss: 2767.0410, val_loss: 2784.9675\n",
      "[Epoch: 69] Average loss: 2522.4263, val_loss: 1722.1204\n",
      "[Epoch: 70] Average loss: 2479.7900, val_loss: 2604.1880\n",
      "[Epoch: 71] Average loss: 2441.2686, val_loss: 2129.9021\n",
      "[Epoch: 72] Average loss: 2677.2241, val_loss: 2497.8755\n",
      "[Epoch: 73] Average loss: 2334.3936, val_loss: 2177.4004\n",
      "[Epoch: 74] Average loss: 2297.9834, val_loss: 1909.8325\n",
      "[Epoch: 75] Average loss: 2279.2456, val_loss: 1712.5935\n",
      "[Epoch: 76] Average loss: 2195.0598, val_loss: 1836.3810\n",
      "[Epoch: 77] Average loss: 2264.9744, val_loss: 1609.0986\n",
      "[Epoch: 78] Average loss: 2195.7996, val_loss: 2070.9209\n",
      "[Epoch: 79] Average loss: 2792.2856, val_loss: 1874.4698\n",
      "[Epoch: 80] Average loss: 2026.3947, val_loss: 2070.6787\n",
      "[Epoch: 81] Average loss: 1986.2279, val_loss: 1596.6687\n",
      "[Epoch: 82] Average loss: 1980.3699, val_loss: 1553.1526\n",
      "[Epoch: 83] Average loss: 1962.9531, val_loss: 1568.7662\n",
      "[Epoch: 84] Average loss: 1974.4078, val_loss: 2030.1185\n",
      "[Epoch: 85] Average loss: 2025.2104, val_loss: 1717.8636\n",
      "[Epoch: 86] Average loss: 1893.8488, val_loss: 1929.2506\n",
      "[Epoch: 87] Average loss: 1976.0723, val_loss: 1099.9174\n",
      "[Epoch: 88] Average loss: 2183.5239, val_loss: 1716.6027\n",
      "[Epoch: 89] Average loss: 1918.4180, val_loss: 1911.7200\n",
      "[Epoch: 90] Average loss: 1897.8904, val_loss: 1539.4622\n",
      "[Epoch: 91] Average loss: 1813.7207, val_loss: 1300.1760\n",
      "[Epoch: 92] Average loss: 1923.5428, val_loss: 1236.6147\n",
      "[Epoch: 93] Average loss: 1772.4301, val_loss: 1865.8752\n",
      "[Epoch: 94] Average loss: 1730.1191, val_loss: 1334.2362\n",
      "[Epoch: 95] Average loss: 2045.3921, val_loss: 1880.2231\n",
      "[Epoch: 96] Average loss: 1658.1226, val_loss: 1188.4075\n",
      "[Epoch: 97] Average loss: 1662.4784, val_loss: 1630.4072\n",
      "[Epoch: 98] Average loss: 1639.7683, val_loss: 1138.3224\n",
      "[Epoch: 99] Average loss: 1696.6818, val_loss: 1687.1033\n",
      "[Epoch: 100] Average loss: 2463.8926, val_loss: 2182.4636\n",
      "[Epoch: 101] Average loss: 1759.8781, val_loss: 1506.1348\n",
      "[Epoch: 102] Average loss: 1709.9019, val_loss: 1477.4116\n",
      "[Epoch: 103] Average loss: 1607.5659, val_loss: 1483.4946\n",
      "[Epoch: 104] Average loss: 1567.9193, val_loss: 1374.8915\n",
      "[Epoch: 105] Average loss: 1550.5282, val_loss: 1894.3104\n",
      "[Epoch: 106] Average loss: 1551.2117, val_loss: 1244.7827\n",
      "[Epoch: 107] Average loss: 1646.8104, val_loss: 2014.0793\n",
      "[Epoch: 108] Average loss: 1679.3407, val_loss: 1086.0842\n",
      "[Epoch: 109] Average loss: 1682.3802, val_loss: 1202.2285\n",
      "[Epoch: 110] Average loss: 1740.6958, val_loss: 1470.7407\n",
      "[Epoch: 111] Average loss: 1455.8209, val_loss: 1512.0072\n",
      "[Epoch: 112] Average loss: 1393.2345, val_loss: 1420.6886\n",
      "[Epoch: 113] Average loss: 1270.4614, val_loss: 1477.2690\n",
      "[Epoch: 114] Average loss: 1592.7296, val_loss: 1770.8477\n",
      "[Epoch: 115] Average loss: 1534.8676, val_loss: 1542.8331\n",
      "[Epoch: 116] Average loss: 1299.4352, val_loss: 1409.5450\n",
      "[Epoch: 117] Average loss: 1350.9226, val_loss: 1442.1862\n",
      "[Epoch: 118] Average loss: 1363.0200, val_loss: 1159.4838\n",
      "[Epoch: 119] Average loss: 1634.2896, val_loss: 1367.0450\n",
      "[Epoch: 120] Average loss: 1868.9443, val_loss: 1939.8522\n",
      "[Epoch: 121] Average loss: 1398.2922, val_loss: 1046.4998\n",
      "[Epoch: 122] Average loss: 1399.5291, val_loss: 1329.9581\n",
      "[Epoch: 123] Average loss: 1253.1986, val_loss: 1286.3662\n",
      "[Epoch: 124] Average loss: 1452.1426, val_loss: 1247.3618\n",
      "[Epoch: 125] Average loss: 1617.7573, val_loss: 1245.4568\n",
      "[Epoch: 126] Average loss: 1306.6436, val_loss: 1055.2002\n",
      "[Epoch: 127] Average loss: 1261.8254, val_loss: 1289.0199\n",
      "[Epoch: 128] Average loss: 1204.1866, val_loss: 1292.8153\n",
      "[Epoch: 129] Average loss: 1115.5435, val_loss: 1438.8269\n",
      "[Epoch: 130] Average loss: 1200.1324, val_loss: 1165.5259\n",
      "[Epoch: 131] Average loss: 1212.0552, val_loss: 1604.2064\n",
      "[Epoch: 132] Average loss: 1289.3057, val_loss: 1275.0167\n",
      "[Epoch: 133] Average loss: 1392.8086, val_loss: 1116.6870\n",
      "[Epoch: 134] Average loss: 1122.2838, val_loss: 993.1021\n",
      "[Epoch: 135] Average loss: 1183.3418, val_loss: 1592.2728\n",
      "[Epoch: 136] Average loss: 1319.8983, val_loss: 1005.2835\n",
      "[Epoch: 137] Average loss: 1144.1423, val_loss: 1537.6271\n",
      "[Epoch: 138] Average loss: 1614.2516, val_loss: 1314.8540\n",
      "[Epoch: 139] Average loss: 1524.7079, val_loss: 1801.8451\n",
      "[Epoch: 140] Average loss: 1196.8123, val_loss: 1127.2864\n",
      "[Epoch: 141] Average loss: 1249.4327, val_loss: 1208.2373\n",
      "[Epoch: 142] Average loss: 1173.2144, val_loss: 1186.0381\n",
      "[Epoch: 143] Average loss: 1929.1343, val_loss: 1576.9019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 144] Average loss: 1178.8431, val_loss: 1144.0959\n",
      "[Epoch: 145] Average loss: 1305.5814, val_loss: 1607.1671\n",
      "[Epoch: 146] Average loss: 1039.2130, val_loss: 1204.0282\n",
      "[Epoch: 147] Average loss: 1125.1207, val_loss: 1237.5701\n",
      "[Epoch: 148] Average loss: 1125.2358, val_loss: 1091.0691\n",
      "[Epoch: 149] Average loss: 1261.6077, val_loss: 1243.1740\n",
      "[Epoch: 150] Average loss: 1274.4833, val_loss: 1242.8267\n",
      "[Epoch: 151] Average loss: 1123.8521, val_loss: 1213.3269\n",
      "[Epoch: 152] Average loss: 1402.2902, val_loss: 1582.1960\n",
      "[Epoch: 153] Average loss: 1265.3231, val_loss: 1293.2488\n",
      "[Epoch: 154] Average loss: 1301.5834, val_loss: 999.6271\n",
      "[Epoch: 155] Average loss: 1126.7878, val_loss: 1504.4102\n",
      "[Epoch: 156] Average loss: 1296.0389, val_loss: 1120.7988\n",
      "[Epoch: 157] Average loss: 1438.3850, val_loss: 1321.7009\n",
      "[Epoch: 158] Average loss: 1236.9622, val_loss: 1147.7062\n",
      "[Epoch: 159] Average loss: 1112.3372, val_loss: 1014.3842\n",
      "[Epoch: 160] Average loss: 1026.1965, val_loss: 1064.2285\n",
      "[Epoch: 161] Average loss: 1144.7809, val_loss: 1637.7523\n",
      "[Epoch: 162] Average loss: 1255.9225, val_loss: 1109.2061\n",
      "[Epoch: 163] Average loss: 998.0854, val_loss: 1053.0046\n",
      "[Epoch: 164] Average loss: 1183.9128, val_loss: 1267.9293\n",
      "[Epoch: 165] Average loss: 2398.0969, val_loss: 1770.9484\n",
      "[Epoch: 166] Average loss: 1195.5659, val_loss: 1753.2020\n",
      "[Epoch: 167] Average loss: 1264.8712, val_loss: 1119.7079\n",
      "[Epoch: 168] Average loss: 1297.4978, val_loss: 1056.2729\n",
      "[Epoch: 169] Average loss: 980.8395, val_loss: 1269.5845\n",
      "[Epoch: 170] Average loss: 1147.4684, val_loss: 1274.6023\n",
      "[Epoch: 171] Average loss: 1157.6941, val_loss: 1288.0957\n",
      "[Epoch: 172] Average loss: 1176.7893, val_loss: 1433.2606\n",
      "[Epoch: 173] Average loss: 1221.4954, val_loss: 1278.2616\n",
      "[Epoch: 174] Average loss: 1303.4570, val_loss: 1596.2737\n",
      "[Epoch: 175] Average loss: 1042.6764, val_loss: 1140.0161\n",
      "[Epoch: 176] Average loss: 1025.0284, val_loss: 1149.5859\n",
      "[Epoch: 177] Average loss: 1182.3906, val_loss: 1299.2159\n",
      "[Epoch: 178] Average loss: 1106.5618, val_loss: 1178.6814\n",
      "[Epoch: 179] Average loss: 914.3778, val_loss: 1007.3372\n",
      "[Epoch: 180] Average loss: 1024.7731, val_loss: 1287.6572\n",
      "[Epoch: 181] Average loss: 1129.2946, val_loss: 1067.7522\n",
      "[Epoch: 182] Average loss: 905.4076, val_loss: 1207.8663\n",
      "[Epoch: 183] Average loss: 1032.6676, val_loss: 1558.2806\n",
      "[Epoch: 184] Average loss: 1191.5889, val_loss: 1177.9043\n",
      "[Epoch: 185] Average loss: 1149.3302, val_loss: 1443.2523\n",
      "[Epoch: 186] Average loss: 1128.2814, val_loss: 1159.2419\n",
      "[Epoch: 187] Average loss: 1037.6418, val_loss: 1330.1748\n",
      "[Epoch: 188] Average loss: 1035.1310, val_loss: 1254.9111\n",
      "[Epoch: 189] Average loss: 1042.2380, val_loss: 1440.3604\n",
      "[Epoch: 190] Average loss: 1137.6547, val_loss: 989.3807\n",
      "[Epoch: 191] Average loss: 1136.6803, val_loss: 1215.9669\n",
      "[Epoch: 192] Average loss: 1160.0115, val_loss: 1156.0624\n",
      "[Epoch: 193] Average loss: 932.5045, val_loss: 1238.2101\n",
      "[Epoch: 194] Average loss: 1096.0551, val_loss: 1496.0469\n",
      "[Epoch: 195] Average loss: 1066.9512, val_loss: 1429.7600\n",
      "[Epoch: 196] Average loss: 1134.7712, val_loss: 1247.2499\n",
      "[Epoch: 197] Average loss: 1153.6880, val_loss: 1252.3269\n",
      "[Epoch: 198] Average loss: 999.3606, val_loss: 1188.2651\n",
      "[Epoch: 199] Average loss: 1245.6863, val_loss: 1191.0951\n",
      "[Epoch: 200] Average loss: 1145.1471, val_loss: 1096.5911\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    avg_loss = 0\n",
    "\n",
    "    for X1, X2, Y in train_loader:\n",
    "        X1 = X1.to(device)\n",
    "        X2 = X2.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        prediction = model(X1, X2)\n",
    "        loss = torch.sqrt(criterion(prediction, Y)).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss / len(train_loader)\n",
    "    print(f'[Epoch: {epoch+1:>2}] Average loss: {avg_loss:.4f}, ', end='')\n",
    "    \n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    with torch.no_grad():\n",
    "        val_avg_loss = 0.\n",
    "        for X1_val, X2_val, Y_val in val_loader:\n",
    "            X1_val = X1_val.to(device)\n",
    "            X2_val = X2_val.to(device)\n",
    "            Y_val = Y_val.to(device)\n",
    "            val_prediction = model(X1_val, X2_val)\n",
    "            val_loss = torch.sqrt(criterion(val_prediction, Y_val)).to(device)\n",
    "            val_avg_loss += val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"val_loss: {val_avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "783b56f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T13:21:20.007597Z",
     "start_time": "2022-02-24T13:21:19.978661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.28%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "criterion.eval()\n",
    "ss_tot = 0\n",
    "ss_res = 0\n",
    "with torch.no_grad():\n",
    "    for X1_test, X2_test, Y_test in test_loader:\n",
    "        X1_test = X1_test.to(device)\n",
    "        X2_test = X2_test.to(device)\n",
    "        Y_test = Y_test.to(device)\n",
    "        prediction = model(X1_test, X2_test)\n",
    "        mean = torch.mean(Y_test)\n",
    "        ss_tot += torch.sum((Y_test - mean) ** 2)\n",
    "        ss_res += torch.sum((Y_test - prediction) ** 2)\n",
    "    \n",
    "    accuracy = 1 - ss_res/ss_tot\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python-3-9-7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
