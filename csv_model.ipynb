{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a83628a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:34:26.017025Z",
     "start_time": "2022-02-21T11:34:25.240698Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import random_split\n",
    "from ignite.contrib.metrics.regression import R2Score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a6f2fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:34:26.032998Z",
     "start_time": "2022-02-21T11:34:26.018024Z"
    }
   },
   "outputs": [],
   "source": [
    "root = \"final.csv\"\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7f373c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:34:26.175132Z",
     "start_time": "2022-02-21T11:34:26.033995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Clarity</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Cut</th>\n",
       "      <th>Polish</th>\n",
       "      <th>Symmetry</th>\n",
       "      <th>Fluorescence</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111000-5962</td>\n",
       "      <td>CUSHION</td>\n",
       "      <td>1.01</td>\n",
       "      <td>I2</td>\n",
       "      <td>FANCY</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>VG</td>\n",
       "      <td>N</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.63</td>\n",
       "      <td>3.53</td>\n",
       "      <td>1155.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111000-6281</td>\n",
       "      <td>CUSHION</td>\n",
       "      <td>1.19</td>\n",
       "      <td>I2</td>\n",
       "      <td>FANCY</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>GD</td>\n",
       "      <td>M</td>\n",
       "      <td>5.97</td>\n",
       "      <td>5.59</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3638.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111000-6305</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>1.00</td>\n",
       "      <td>SI2</td>\n",
       "      <td>U-V</td>\n",
       "      <td>EX</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>M</td>\n",
       "      <td>8.47</td>\n",
       "      <td>5.39</td>\n",
       "      <td>3.42</td>\n",
       "      <td>2237.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111000-6320</td>\n",
       "      <td>PEAR</td>\n",
       "      <td>1.01</td>\n",
       "      <td>SI2</td>\n",
       "      <td>E</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>VG</td>\n",
       "      <td>N</td>\n",
       "      <td>9.39</td>\n",
       "      <td>5.52</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2953.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111000-6368</td>\n",
       "      <td>CUSHION</td>\n",
       "      <td>1.01</td>\n",
       "      <td>SI2</td>\n",
       "      <td>FANCY</td>\n",
       "      <td>VG</td>\n",
       "      <td>VG</td>\n",
       "      <td>GD</td>\n",
       "      <td>ST</td>\n",
       "      <td>6.10</td>\n",
       "      <td>5.36</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2241.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id    Shape  Weight Clarity Colour Cut Polish Symmetry  \\\n",
       "0  111000-5962  CUSHION    1.01      I2  FANCY  EX     VG       VG   \n",
       "1  111000-6281  CUSHION    1.19      I2  FANCY  EX     VG       GD   \n",
       "2  111000-6305     OVAL    1.00     SI2    U-V  EX     EX       VG   \n",
       "3  111000-6320     PEAR    1.01     SI2      E  EX     VG       VG   \n",
       "4  111000-6368  CUSHION    1.01     SI2  FANCY  VG     VG       GD   \n",
       "\n",
       "  Fluorescence  Length  Width  Depth    Price  \n",
       "0            N    5.89   5.63   3.53  1155.27  \n",
       "1            M    5.97   5.59   3.80  3638.36  \n",
       "2            M    8.47   5.39   3.42  2237.73  \n",
       "3            N    9.39   5.52   3.24  2953.85  \n",
       "4           ST    6.10   5.36   3.48  2241.67  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.read_csv(root)\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06878422",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:34:26.190092Z",
     "start_time": "2022-02-21T11:34:26.176130Z"
    }
   },
   "outputs": [],
   "source": [
    "data_numpy = data_pd.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c82b5d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:34:26.221009Z",
     "start_time": "2022-02-21T11:34:26.191089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CUSHION': 0, 'EMERALD': 1, 'HEART': 2, 'MARQUISE': 3, 'OVAL': 4, 'PEAR': 5, 'PRINCESS': 6, 'ROUND': 7}\n",
      "{'FL': 0, 'I1': 1, 'I2': 2, 'I3': 3, 'IF': 4, 'SI1': 5, 'SI2': 6, 'VS1': 7, 'VS2': 8, 'VVS1': 9, 'VVS2': 10}\n",
      "{'D': 0, 'E': 1, 'F': 2, 'FANCY': 3, 'G': 4, 'H': 5, 'I': 6, 'J': 7, 'K': 8, 'L': 9, 'M': 10, 'N': 11, 'O': 12, 'O-P': 13, 'Q-R': 14, 'S-T': 15, 'U-V': 16, 'W': 17, 'W-X': 18, 'Y-Z': 19}\n",
      "{'EX': 0, 'F': 1, 'GD': 2, 'VG': 3}\n",
      "{'EX': 0, 'F': 1, 'GD': 2, 'VG': 3}\n",
      "{'EX': 0, 'FR': 1, 'GD': 2, 'VG': 3}\n",
      "{'F': 0, 'M': 1, 'N': 2, 'SL': 3, 'ST': 4, 'VS': 5, 'VSL': 6}\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 3, 4, 5, 6, 7, 8]:\n",
    "    wordset = {word: idx for idx, word in enumerate(np.unique(data_numpy[:,i]))}\n",
    "    print(wordset)\n",
    "    for row in range(len(data_numpy)):\n",
    "        data_numpy[row][i] = wordset[data_numpy[row][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b815b6b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:34:26.235969Z",
     "start_time": "2022-02-21T11:34:26.222008Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,ints, floats, target):\n",
    "        super(Dataset).__init__()\n",
    "        self.ints = ints\n",
    "        self.floats = floats\n",
    "        self.target = target\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return self.ints[idx],self.floats[idx], self.target[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "925cf468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:34:26.250930Z",
     "start_time": "2022-02-21T11:34:26.236967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 3, 0, 3, 3, 2], dtype=torch.int32)\n",
      "tensor([1.0100, 5.8900, 5.6300, 3.5300])\n",
      "tensor([1155.2700])\n"
     ]
    }
   ],
   "source": [
    "data_int = torch.from_numpy(np.array(data_numpy[:,[1,3,4,5,6,7,8]], dtype=\"int\"))\n",
    "data_float = torch.from_numpy(np.array(data_numpy[:,[2,9,10,11]], dtype=\"float\")).float()\n",
    "data_target = torch.from_numpy(np.array(data_numpy[:,[12]], dtype=\"float\")).float()\n",
    "print(data_int[0])\n",
    "print(data_float[0])\n",
    "print(data_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff0950ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:34:26.265890Z",
     "start_time": "2022-02-21T11:34:26.251927Z"
    }
   },
   "outputs": [],
   "source": [
    "train_length = int(len(data_numpy) * 0.6)\n",
    "test_length = int(len(data_numpy) * 0.2)\n",
    "val_length = len(data_numpy) - train_length - test_length\n",
    "\n",
    "train_dataset = Dataset(data_int, data_float, data_target)\n",
    "train_dataset, test_dataset = random_split(train_dataset, [train_length, test_length+val_length])\n",
    "test_dataset, val_dataset = random_split(test_dataset, [test_length, val_length])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31add96f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:34:26.280849Z",
     "start_time": "2022-02-21T11:34:26.266886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2826 942 943\n"
     ]
    }
   ],
   "source": [
    "print(train_length, test_length, val_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a476a743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:34:26.296807Z",
     "start_time": "2022-02-21T11:34:26.281847Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.emb1 = torch.nn.Embedding(8, 20)\n",
    "        self.emb2 = torch.nn.Embedding(11, 20)\n",
    "        self.emb3 = torch.nn.Embedding(20, 20)\n",
    "        self.emb4 = torch.nn.Embedding(4, 20)\n",
    "        self.emb5 = torch.nn.Embedding(4, 20)\n",
    "        self.emb6 = torch.nn.Embedding(4, 20)\n",
    "        self.emb7 = torch.nn.Embedding(7, 20)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc = nn.Linear(4, 80)\n",
    "        self.fc1 = nn.Linear(220, 8192)\n",
    "        self.fc2 = nn.Linear(8192, 8192)\n",
    "        self.fc3 = nn.Linear(8192, 4096)\n",
    "        self.fc4 = nn.Linear(4096, 2048)\n",
    "        self.fc5 = nn.Linear(2048, 1)\n",
    "        self.dropout = nn.Dropout()\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x1 = self.emb1(x[:,0])\n",
    "        x2 = self.emb2(x[:,1])\n",
    "        x3 = self.emb3(x[:,2])\n",
    "        x4 = self.emb4(x[:,3])\n",
    "        x5 = self.emb5(x[:,4])\n",
    "        x6 = self.emb6(x[:,5])\n",
    "        x7 = self.emb7(x[:,6])\n",
    "        y = self.fc(y)\n",
    "        x = torch.cat((x1, x2, x3, x4, x5, x6, x7, y), dim=1)\n",
    "        x = self.dropout(self.act(self.fc1(x)))\n",
    "        x = self.dropout(self.act(self.fc2(x)))\n",
    "        x = self.dropout(self.act(self.fc3(x)))\n",
    "        x = self.dropout(self.act(self.fc4(x)))\n",
    "        return self.fc5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57844bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:34:26.821031Z",
     "start_time": "2022-02-21T11:34:26.297805Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f910f99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:35:20.372161Z",
     "start_time": "2022-02-21T11:34:26.822028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:  1] Average loss: 4425.7754, val_loss: 4846.7339\n",
      "[Epoch:  2] Average loss: 4676.3511, val_loss: 4546.4194\n",
      "[Epoch:  3] Average loss: 3929.9219, val_loss: 3925.0225\n",
      "[Epoch:  4] Average loss: 3363.8142, val_loss: 3404.8367\n",
      "[Epoch:  5] Average loss: 2994.1753, val_loss: 3205.7554\n",
      "[Epoch:  6] Average loss: 2967.6206, val_loss: 3039.3894\n",
      "[Epoch:  7] Average loss: 2532.3508, val_loss: 2394.8315\n",
      "[Epoch:  8] Average loss: 2139.6274, val_loss: 1844.6324\n",
      "[Epoch:  9] Average loss: 1919.9109, val_loss: 1627.4802\n",
      "[Epoch: 10] Average loss: 1758.2539, val_loss: 1476.5518\n",
      "[Epoch: 11] Average loss: 1560.1492, val_loss: 1386.4557\n",
      "[Epoch: 12] Average loss: 1603.3612, val_loss: 1159.2008\n",
      "[Epoch: 13] Average loss: 1443.2219, val_loss: 1502.7002\n",
      "[Epoch: 14] Average loss: 2018.4463, val_loss: 1807.8419\n",
      "[Epoch: 15] Average loss: 2032.9700, val_loss: 1153.7285\n",
      "[Epoch: 16] Average loss: 1701.3096, val_loss: 1454.3053\n",
      "[Epoch: 17] Average loss: 1607.0767, val_loss: 962.9247\n",
      "[Epoch: 18] Average loss: 1418.0045, val_loss: 1310.8054\n",
      "[Epoch: 19] Average loss: 1347.0903, val_loss: 1095.3982\n",
      "[Epoch: 20] Average loss: 1245.4232, val_loss: 1241.8357\n",
      "[Epoch: 21] Average loss: 1431.9452, val_loss: 1577.5315\n",
      "[Epoch: 22] Average loss: 1501.5964, val_loss: 1138.4382\n",
      "[Epoch: 23] Average loss: 1450.8875, val_loss: 1177.1782\n",
      "[Epoch: 24] Average loss: 1339.1348, val_loss: 936.6669\n",
      "[Epoch: 25] Average loss: 1277.1556, val_loss: 865.0369\n",
      "[Epoch: 26] Average loss: 1215.4424, val_loss: 832.2915\n",
      "[Epoch: 27] Average loss: 1108.4681, val_loss: 1062.6809\n",
      "[Epoch: 28] Average loss: 1344.0040, val_loss: 1008.9292\n",
      "[Epoch: 29] Average loss: 1300.9360, val_loss: 988.8831\n",
      "[Epoch: 30] Average loss: 1335.1010, val_loss: 1174.2966\n",
      "[Epoch: 31] Average loss: 1139.9514, val_loss: 1467.2588\n",
      "[Epoch: 32] Average loss: 1198.5715, val_loss: 982.0029\n",
      "[Epoch: 33] Average loss: 1191.1354, val_loss: 907.6970\n",
      "[Epoch: 34] Average loss: 1280.6257, val_loss: 1212.1860\n",
      "[Epoch: 35] Average loss: 1234.3933, val_loss: 971.4253\n",
      "[Epoch: 36] Average loss: 1071.1428, val_loss: 1023.5495\n",
      "[Epoch: 37] Average loss: 1444.1218, val_loss: 1343.7515\n",
      "[Epoch: 38] Average loss: 1230.7378, val_loss: 1716.9664\n",
      "[Epoch: 39] Average loss: 1369.2482, val_loss: 1093.8655\n",
      "[Epoch: 40] Average loss: 1046.0640, val_loss: 2175.1714\n",
      "[Epoch: 41] Average loss: 1868.2313, val_loss: 1164.2994\n",
      "[Epoch: 42] Average loss: 1642.3291, val_loss: 1938.6370\n",
      "[Epoch: 43] Average loss: 1574.1512, val_loss: 1489.1460\n",
      "[Epoch: 44] Average loss: 1231.8508, val_loss: 1223.8892\n",
      "[Epoch: 45] Average loss: 1124.3038, val_loss: 980.7378\n",
      "[Epoch: 46] Average loss: 1227.4358, val_loss: 1176.0979\n",
      "[Epoch: 47] Average loss: 1118.2111, val_loss: 901.4487\n",
      "[Epoch: 48] Average loss: 1086.9285, val_loss: 916.1107\n",
      "[Epoch: 49] Average loss: 989.5267, val_loss: 898.7299\n",
      "[Epoch: 50] Average loss: 974.0360, val_loss: 907.3201\n",
      "[Epoch: 51] Average loss: 1000.1796, val_loss: 1022.9415\n",
      "[Epoch: 52] Average loss: 1117.6401, val_loss: 1051.3148\n",
      "[Epoch: 53] Average loss: 1073.0552, val_loss: 1123.0925\n",
      "[Epoch: 54] Average loss: 1121.8853, val_loss: 890.3816\n",
      "[Epoch: 55] Average loss: 979.1957, val_loss: 881.0685\n",
      "[Epoch: 56] Average loss: 892.1549, val_loss: 1019.2857\n",
      "[Epoch: 57] Average loss: 1024.5746, val_loss: 921.6679\n",
      "[Epoch: 58] Average loss: 1318.0454, val_loss: 954.3510\n",
      "[Epoch: 59] Average loss: 1142.1322, val_loss: 981.7379\n",
      "[Epoch: 60] Average loss: 1060.4044, val_loss: 1030.9226\n",
      "[Epoch: 61] Average loss: 950.8541, val_loss: 1231.7554\n",
      "[Epoch: 62] Average loss: 975.6303, val_loss: 949.1921\n",
      "[Epoch: 63] Average loss: 1403.8430, val_loss: 899.6304\n",
      "[Epoch: 64] Average loss: 1210.6947, val_loss: 934.2863\n",
      "[Epoch: 65] Average loss: 1028.3843, val_loss: 1167.2289\n",
      "[Epoch: 66] Average loss: 1072.7131, val_loss: 1016.5669\n",
      "[Epoch: 67] Average loss: 1204.3811, val_loss: 1445.7040\n",
      "[Epoch: 68] Average loss: 1157.3851, val_loss: 1156.6647\n",
      "[Epoch: 69] Average loss: 1197.4811, val_loss: 1205.3927\n",
      "[Epoch: 70] Average loss: 1162.4984, val_loss: 890.0707\n",
      "[Epoch: 71] Average loss: 1106.8151, val_loss: 1005.3342\n",
      "[Epoch: 72] Average loss: 878.9183, val_loss: 908.1923\n",
      "[Epoch: 73] Average loss: 969.4145, val_loss: 1025.3055\n",
      "[Epoch: 74] Average loss: 1033.4598, val_loss: 1010.4875\n",
      "[Epoch: 75] Average loss: 944.0102, val_loss: 897.5065\n",
      "[Epoch: 76] Average loss: 884.0843, val_loss: 980.3597\n",
      "[Epoch: 77] Average loss: 1025.5076, val_loss: 1278.5573\n",
      "[Epoch: 78] Average loss: 976.9244, val_loss: 979.7574\n",
      "[Epoch: 79] Average loss: 992.7449, val_loss: 927.9409\n",
      "[Epoch: 80] Average loss: 953.2706, val_loss: 886.6664\n",
      "[Epoch: 81] Average loss: 1078.3435, val_loss: 923.9991\n",
      "[Epoch: 82] Average loss: 827.7806, val_loss: 983.2782\n",
      "[Epoch: 83] Average loss: 956.8774, val_loss: 1016.8741\n",
      "[Epoch: 84] Average loss: 834.9772, val_loss: 1018.8986\n",
      "[Epoch: 85] Average loss: 1115.5105, val_loss: 1133.0312\n",
      "[Epoch: 86] Average loss: 1138.3954, val_loss: 995.2277\n",
      "[Epoch: 87] Average loss: 1158.3167, val_loss: 941.3812\n",
      "[Epoch: 88] Average loss: 880.3209, val_loss: 899.6755\n",
      "[Epoch: 89] Average loss: 869.3826, val_loss: 1031.3903\n",
      "[Epoch: 90] Average loss: 939.5891, val_loss: 901.9289\n",
      "[Epoch: 91] Average loss: 944.0239, val_loss: 942.4433\n",
      "[Epoch: 92] Average loss: 977.8582, val_loss: 970.5864\n",
      "[Epoch: 93] Average loss: 912.8114, val_loss: 1046.5536\n",
      "[Epoch: 94] Average loss: 1278.9248, val_loss: 1396.0181\n",
      "[Epoch: 95] Average loss: 939.7678, val_loss: 1312.6525\n",
      "[Epoch: 96] Average loss: 1085.6603, val_loss: 1135.1819\n",
      "[Epoch: 97] Average loss: 964.2250, val_loss: 951.9150\n",
      "[Epoch: 98] Average loss: 747.5219, val_loss: 940.2234\n",
      "[Epoch: 99] Average loss: 805.6844, val_loss: 1017.0828\n",
      "[Epoch: 100] Average loss: 1001.9259, val_loss: 1016.6798\n",
      "[Epoch: 101] Average loss: 914.8726, val_loss: 935.7757\n",
      "[Epoch: 102] Average loss: 1192.3391, val_loss: 1422.6702\n",
      "[Epoch: 103] Average loss: 1200.6130, val_loss: 1072.5466\n",
      "[Epoch: 104] Average loss: 939.4803, val_loss: 1004.6482\n",
      "[Epoch: 105] Average loss: 787.4094, val_loss: 819.8102\n",
      "[Epoch: 106] Average loss: 915.5776, val_loss: 987.3300\n",
      "[Epoch: 107] Average loss: 800.9271, val_loss: 888.3903\n",
      "[Epoch: 108] Average loss: 1046.9355, val_loss: 844.3616\n",
      "[Epoch: 109] Average loss: 858.4845, val_loss: 949.5462\n",
      "[Epoch: 110] Average loss: 892.9267, val_loss: 1040.9763\n",
      "[Epoch: 111] Average loss: 830.1296, val_loss: 1112.9575\n",
      "[Epoch: 112] Average loss: 981.2418, val_loss: 1137.0505\n",
      "[Epoch: 113] Average loss: 1044.1611, val_loss: 1191.2344\n",
      "[Epoch: 114] Average loss: 1076.3400, val_loss: 1108.9183\n",
      "[Epoch: 115] Average loss: 891.3964, val_loss: 1222.1846\n",
      "[Epoch: 116] Average loss: 901.4892, val_loss: 1101.6799\n",
      "[Epoch: 117] Average loss: 846.7192, val_loss: 1264.2998\n",
      "[Epoch: 118] Average loss: 1012.9622, val_loss: 1103.3987\n",
      "[Epoch: 119] Average loss: 975.5541, val_loss: 1125.5045\n",
      "[Epoch: 120] Average loss: 931.5298, val_loss: 1082.5266\n",
      "[Epoch: 121] Average loss: 789.3142, val_loss: 945.0690\n",
      "[Epoch: 122] Average loss: 800.7540, val_loss: 986.3510\n",
      "[Epoch: 123] Average loss: 850.6434, val_loss: 1092.0046\n",
      "[Epoch: 124] Average loss: 885.5690, val_loss: 1027.5922\n",
      "[Epoch: 125] Average loss: 1004.5746, val_loss: 893.0488\n",
      "[Epoch: 126] Average loss: 920.0244, val_loss: 1006.7766\n",
      "[Epoch: 127] Average loss: 960.2833, val_loss: 1019.1185\n",
      "[Epoch: 128] Average loss: 883.6419, val_loss: 956.4098\n",
      "[Epoch: 129] Average loss: 782.6307, val_loss: 958.6679\n",
      "[Epoch: 130] Average loss: 932.7692, val_loss: 1106.3290\n",
      "[Epoch: 131] Average loss: 826.4526, val_loss: 1039.7849\n",
      "[Epoch: 132] Average loss: 762.7615, val_loss: 1059.6165\n",
      "[Epoch: 133] Average loss: 836.5243, val_loss: 1089.8262\n",
      "[Epoch: 134] Average loss: 952.8799, val_loss: 1018.0709\n",
      "[Epoch: 135] Average loss: 855.4587, val_loss: 992.9843\n",
      "[Epoch: 136] Average loss: 864.4821, val_loss: 1020.2242\n",
      "[Epoch: 137] Average loss: 770.0762, val_loss: 929.2313\n",
      "[Epoch: 138] Average loss: 911.2323, val_loss: 1136.4728\n",
      "[Epoch: 139] Average loss: 915.8916, val_loss: 1248.0039\n",
      "[Epoch: 140] Average loss: 1056.0873, val_loss: 1357.6682\n",
      "[Epoch: 141] Average loss: 1024.8578, val_loss: 1005.3118\n",
      "[Epoch: 142] Average loss: 860.7953, val_loss: 866.2924\n",
      "[Epoch: 143] Average loss: 1059.2377, val_loss: 1122.0181\n",
      "[Epoch: 144] Average loss: 825.3028, val_loss: 998.1586\n",
      "[Epoch: 145] Average loss: 774.8551, val_loss: 1063.8149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 146] Average loss: 895.7075, val_loss: 959.0568\n",
      "[Epoch: 147] Average loss: 1182.7999, val_loss: 973.4172\n",
      "[Epoch: 148] Average loss: 878.5492, val_loss: 1029.2778\n",
      "[Epoch: 149] Average loss: 732.7737, val_loss: 1051.3925\n",
      "[Epoch: 150] Average loss: 774.3350, val_loss: 1076.4945\n",
      "[Epoch: 151] Average loss: 831.4259, val_loss: 1079.2463\n",
      "[Epoch: 152] Average loss: 1157.5493, val_loss: 1490.5980\n",
      "[Epoch: 153] Average loss: 1325.6605, val_loss: 1287.8823\n",
      "[Epoch: 154] Average loss: 1167.0648, val_loss: 1063.2471\n",
      "[Epoch: 155] Average loss: 963.4194, val_loss: 1052.8905\n",
      "[Epoch: 156] Average loss: 899.2847, val_loss: 888.8813\n",
      "[Epoch: 157] Average loss: 749.9509, val_loss: 958.7319\n",
      "[Epoch: 158] Average loss: 724.9723, val_loss: 1179.4446\n",
      "[Epoch: 159] Average loss: 870.6068, val_loss: 992.6862\n",
      "[Epoch: 160] Average loss: 832.1213, val_loss: 1090.7991\n",
      "[Epoch: 161] Average loss: 767.8268, val_loss: 978.7211\n",
      "[Epoch: 162] Average loss: 791.0344, val_loss: 942.2130\n",
      "[Epoch: 163] Average loss: 865.9964, val_loss: 1048.2216\n",
      "[Epoch: 164] Average loss: 968.1710, val_loss: 1099.2246\n",
      "[Epoch: 165] Average loss: 759.4481, val_loss: 1211.1383\n",
      "[Epoch: 166] Average loss: 786.1226, val_loss: 1079.3829\n",
      "[Epoch: 167] Average loss: 802.6575, val_loss: 1152.0050\n",
      "[Epoch: 168] Average loss: 1186.3673, val_loss: 1065.5791\n",
      "[Epoch: 169] Average loss: 892.4930, val_loss: 1180.7041\n",
      "[Epoch: 170] Average loss: 908.2105, val_loss: 1042.2517\n",
      "[Epoch: 171] Average loss: 735.5990, val_loss: 950.7830\n",
      "[Epoch: 172] Average loss: 877.0303, val_loss: 1043.1130\n",
      "[Epoch: 173] Average loss: 796.0540, val_loss: 1104.7935\n",
      "[Epoch: 174] Average loss: 808.4214, val_loss: 1217.7175\n",
      "[Epoch: 175] Average loss: 822.4747, val_loss: 902.0723\n",
      "[Epoch: 176] Average loss: 835.8378, val_loss: 1010.5947\n",
      "[Epoch: 177] Average loss: 791.2936, val_loss: 944.3273\n",
      "[Epoch: 178] Average loss: 796.3882, val_loss: 936.4888\n",
      "[Epoch: 179] Average loss: 769.7625, val_loss: 1052.2368\n",
      "[Epoch: 180] Average loss: 787.7086, val_loss: 952.2439\n",
      "[Epoch: 181] Average loss: 797.8815, val_loss: 1084.0571\n",
      "[Epoch: 182] Average loss: 892.0902, val_loss: 994.5504\n",
      "[Epoch: 183] Average loss: 846.7363, val_loss: 867.5239\n",
      "[Epoch: 184] Average loss: 738.9432, val_loss: 897.9045\n",
      "[Epoch: 185] Average loss: 1131.7081, val_loss: 1014.9750\n",
      "[Epoch: 186] Average loss: 830.7969, val_loss: 995.0458\n",
      "[Epoch: 187] Average loss: 828.4336, val_loss: 1118.8878\n",
      "[Epoch: 188] Average loss: 857.1019, val_loss: 999.1033\n",
      "[Epoch: 189] Average loss: 788.1549, val_loss: 1018.8196\n",
      "[Epoch: 190] Average loss: 842.6729, val_loss: 1221.4424\n",
      "[Epoch: 191] Average loss: 819.8240, val_loss: 980.8303\n",
      "[Epoch: 192] Average loss: 841.7768, val_loss: 1060.5184\n",
      "[Epoch: 193] Average loss: 840.8491, val_loss: 1036.0989\n",
      "[Epoch: 194] Average loss: 740.2158, val_loss: 1027.6224\n",
      "[Epoch: 195] Average loss: 985.3315, val_loss: 1138.2625\n",
      "[Epoch: 196] Average loss: 852.2129, val_loss: 1020.9456\n",
      "[Epoch: 197] Average loss: 981.3918, val_loss: 1055.7070\n",
      "[Epoch: 198] Average loss: 905.0552, val_loss: 1234.5531\n",
      "[Epoch: 199] Average loss: 922.4979, val_loss: 1143.7135\n",
      "[Epoch: 200] Average loss: 842.2643, val_loss: 996.7160\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    avg_loss = 0\n",
    "\n",
    "    for X1, X2, Y in train_loader:\n",
    "        X1 = X1.to(device)\n",
    "        X2 = X2.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        model.zero_grad()  # why we use zero_grad?\n",
    "        prediction = model(X1, X2)\n",
    "        loss = torch.sqrt(criterion(prediction, Y)).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss / len(train_loader)\n",
    "    print(f'[Epoch: {epoch+1:>2}] Average loss: {avg_loss:.4f}, ', end='')\n",
    "    \n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    with torch.no_grad():\n",
    "        val_avg_loss = 0.\n",
    "        for X1_val, X2_val, Y_val in val_loader:\n",
    "            X1_val = X1_val.to(device)\n",
    "            X2_val = X2_val.to(device)\n",
    "            Y_val = Y_val.to(device)\n",
    "            val_prediction = model(X1_val, X2_val)\n",
    "            val_loss = torch.sqrt(criterion(val_prediction, Y_val)).to(device)\n",
    "            val_avg_loss += val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"val_loss: {val_avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb590aa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:35:20.404171Z",
     "start_time": "2022-02-21T11:35:20.373190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.97%\n"
     ]
    }
   ],
   "source": [
    "metric = R2Score(device=device)\n",
    "metric.reset()\n",
    "\n",
    "model.eval()\n",
    "criterion.eval()\n",
    "with torch.no_grad():\n",
    "    test_avg_acc = 0\n",
    "    for X1_test, X2_test, Y_test in test_loader:\n",
    "        X1_test = X1_test.to(device)\n",
    "        X2_test = X2_test.to(device)\n",
    "        Y_test = Y_test.to(device)\n",
    "        \n",
    "        test_prediction = model(X1_test, X2_test)\n",
    "        metric.update([test_prediction, Y_test])\n",
    "    print(f\"Accuracy: {metric.compute()*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python-3-9-7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
