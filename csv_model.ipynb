{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a83628a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:00.209198Z",
     "start_time": "2022-02-23T14:20:59.263069Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a6f2fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:00.224225Z",
     "start_time": "2022-02-23T14:21:00.210194Z"
    }
   },
   "outputs": [],
   "source": [
    "root = \"final.csv\"\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7f373c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:00.255178Z",
     "start_time": "2022-02-23T14:21:00.225223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Clarity</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Cut</th>\n",
       "      <th>Polish</th>\n",
       "      <th>Symmetry</th>\n",
       "      <th>Fluorescence</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111000-5962</td>\n",
       "      <td>CUSHION</td>\n",
       "      <td>1.01</td>\n",
       "      <td>I2</td>\n",
       "      <td>FANCY</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>VG</td>\n",
       "      <td>N</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.63</td>\n",
       "      <td>3.53</td>\n",
       "      <td>1155.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111000-6281</td>\n",
       "      <td>CUSHION</td>\n",
       "      <td>1.19</td>\n",
       "      <td>I2</td>\n",
       "      <td>FANCY</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>GD</td>\n",
       "      <td>M</td>\n",
       "      <td>5.97</td>\n",
       "      <td>5.59</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3638.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111000-6305</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>1.00</td>\n",
       "      <td>SI2</td>\n",
       "      <td>U-V</td>\n",
       "      <td>EX</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>M</td>\n",
       "      <td>8.47</td>\n",
       "      <td>5.39</td>\n",
       "      <td>3.42</td>\n",
       "      <td>2237.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111000-6320</td>\n",
       "      <td>PEAR</td>\n",
       "      <td>1.01</td>\n",
       "      <td>SI2</td>\n",
       "      <td>E</td>\n",
       "      <td>EX</td>\n",
       "      <td>VG</td>\n",
       "      <td>VG</td>\n",
       "      <td>N</td>\n",
       "      <td>9.39</td>\n",
       "      <td>5.52</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2953.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111000-6368</td>\n",
       "      <td>CUSHION</td>\n",
       "      <td>1.01</td>\n",
       "      <td>SI2</td>\n",
       "      <td>FANCY</td>\n",
       "      <td>VG</td>\n",
       "      <td>VG</td>\n",
       "      <td>GD</td>\n",
       "      <td>ST</td>\n",
       "      <td>6.10</td>\n",
       "      <td>5.36</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2241.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id    Shape  Weight Clarity Colour Cut Polish Symmetry  \\\n",
       "0  111000-5962  CUSHION    1.01      I2  FANCY  EX     VG       VG   \n",
       "1  111000-6281  CUSHION    1.19      I2  FANCY  EX     VG       GD   \n",
       "2  111000-6305     OVAL    1.00     SI2    U-V  EX     EX       VG   \n",
       "3  111000-6320     PEAR    1.01     SI2      E  EX     VG       VG   \n",
       "4  111000-6368  CUSHION    1.01     SI2  FANCY  VG     VG       GD   \n",
       "\n",
       "  Fluorescence  Length  Width  Depth    Price  \n",
       "0            N    5.89   5.63   3.53  1155.27  \n",
       "1            M    5.97   5.59   3.80  3638.36  \n",
       "2            M    8.47   5.39   3.42  2237.73  \n",
       "3            N    9.39   5.52   3.24  2953.85  \n",
       "4           ST    6.10   5.36   3.48  2241.67  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.read_csv(root)\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06878422",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:00.270137Z",
     "start_time": "2022-02-23T14:21:00.256175Z"
    }
   },
   "outputs": [],
   "source": [
    "data_numpy = data_pd.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c82b5d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:00.301058Z",
     "start_time": "2022-02-23T14:21:00.271135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CUSHION': 0, 'EMERALD': 1, 'HEART': 2, 'MARQUISE': 3, 'OVAL': 4, 'PEAR': 5, 'PRINCESS': 6, 'ROUND': 7}\n",
      "{'FL': 0, 'I1': 1, 'I2': 2, 'I3': 3, 'IF': 4, 'SI1': 5, 'SI2': 6, 'VS1': 7, 'VS2': 8, 'VVS1': 9, 'VVS2': 10}\n",
      "{'D': 0, 'E': 1, 'F': 2, 'FANCY': 3, 'G': 4, 'H': 5, 'I': 6, 'J': 7, 'K': 8, 'L': 9, 'M': 10, 'N': 11, 'O': 12, 'O-P': 13, 'Q-R': 14, 'S-T': 15, 'U-V': 16, 'W': 17, 'W-X': 18, 'Y-Z': 19}\n",
      "{'EX': 0, 'F': 1, 'GD': 2, 'VG': 3}\n",
      "{'EX': 0, 'F': 1, 'GD': 2, 'VG': 3}\n",
      "{'EX': 0, 'FR': 1, 'GD': 2, 'VG': 3}\n",
      "{'F': 0, 'M': 1, 'N': 2, 'SL': 3, 'ST': 4, 'VS': 5, 'VSL': 6}\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 3, 4, 5, 6, 7, 8]:\n",
    "    wordset = {word: idx for idx, word in enumerate(np.unique(data_numpy[:,i]))}\n",
    "    print(wordset)\n",
    "    for row in range(len(data_numpy)):\n",
    "        data_numpy[row][i] = wordset[data_numpy[row][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b815b6b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:00.316931Z",
     "start_time": "2022-02-23T14:21:00.302057Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,ints, floats, target):\n",
    "        super(Dataset).__init__()\n",
    "        self.ints = ints\n",
    "        self.floats = floats\n",
    "        self.target = target\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return self.ints[idx],self.floats[idx], self.target[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "925cf468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:00.362833Z",
     "start_time": "2022-02-23T14:21:00.317928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 3, 0, 3, 3, 2], dtype=torch.int32)\n",
      "tensor([1.0100, 5.8900, 5.6300, 3.5300])\n",
      "tensor([1155.2700])\n"
     ]
    }
   ],
   "source": [
    "data_int = torch.from_numpy(np.array(data_numpy[:,[1,3,4,5,6,7,8]], dtype=\"int\"))\n",
    "data_float = torch.from_numpy(np.array(data_numpy[:,[2,9,10,11]], dtype=\"float\")).float()\n",
    "data_target = torch.from_numpy(np.array(data_numpy[:,[12]], dtype=\"float\")).float()\n",
    "print(data_int[0])\n",
    "print(data_float[0])\n",
    "print(data_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff0950ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:00.378790Z",
     "start_time": "2022-02-23T14:21:00.363830Z"
    }
   },
   "outputs": [],
   "source": [
    "train_length = int(len(data_numpy) * 0.6)\n",
    "test_length = int(len(data_numpy) * 0.2)\n",
    "val_length = len(data_numpy) - train_length - test_length\n",
    "\n",
    "train_dataset = Dataset(data_int, data_float, data_target)\n",
    "train_dataset, test_dataset = random_split(train_dataset, [train_length, test_length+val_length])\n",
    "test_dataset, val_dataset = random_split(test_dataset, [test_length, val_length])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31add96f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:00.394747Z",
     "start_time": "2022-02-23T14:21:00.379789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823 941 942\n"
     ]
    }
   ],
   "source": [
    "print(train_length, test_length, val_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a476a743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:00.409708Z",
     "start_time": "2022-02-23T14:21:00.395746Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.emb1 = torch.nn.Embedding(8, 20)\n",
    "        self.emb2 = torch.nn.Embedding(11, 20)\n",
    "        self.emb3 = torch.nn.Embedding(20, 20)\n",
    "        self.emb4 = torch.nn.Embedding(4, 20)\n",
    "        self.emb5 = torch.nn.Embedding(4, 20)\n",
    "        self.emb6 = torch.nn.Embedding(4, 20)\n",
    "        self.emb7 = torch.nn.Embedding(7, 20)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc = nn.Linear(4, 80)\n",
    "        self.fc1 = nn.Linear(220, 8192)\n",
    "        self.fc2 = nn.Linear(8192, 8192)\n",
    "        self.fc3 = nn.Linear(8192, 4096)\n",
    "        self.fc4 = nn.Linear(4096, 2048)\n",
    "        self.fc5 = nn.Linear(2048, 1)\n",
    "        self.dropout = nn.Dropout()\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x1 = self.emb1(x[:,0])\n",
    "        x2 = self.emb2(x[:,1])\n",
    "        x3 = self.emb3(x[:,2])\n",
    "        x4 = self.emb4(x[:,3])\n",
    "        x5 = self.emb5(x[:,4])\n",
    "        x6 = self.emb6(x[:,5])\n",
    "        x7 = self.emb7(x[:,6])\n",
    "        y = self.fc(y)\n",
    "        x = torch.cat((x1, x2, x3, x4, x5, x6, x7, y), dim=1)\n",
    "        x = self.dropout(self.act(self.fc1(x)))\n",
    "        x = self.dropout(self.act(self.fc2(x)))\n",
    "        x = self.dropout(self.act(self.fc3(x)))\n",
    "        x = self.dropout(self.act(self.fc4(x)))\n",
    "        return self.fc5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57844bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:00.940804Z",
     "start_time": "2022-02-23T14:21:00.410705Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f910f99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:21:54.212532Z",
     "start_time": "2022-02-23T14:21:00.941801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:  1] Average loss: 4499.2910, val_loss: 3936.0359\n",
      "[Epoch:  2] Average loss: 4075.3438, val_loss: 2781.2327\n",
      "[Epoch:  3] Average loss: 3587.3677, val_loss: 2510.3118\n",
      "[Epoch:  4] Average loss: 3054.9487, val_loss: 2544.4656\n",
      "[Epoch:  5] Average loss: 2444.0068, val_loss: 1622.6880\n",
      "[Epoch:  6] Average loss: 1913.0565, val_loss: 1399.6243\n",
      "[Epoch:  7] Average loss: 2369.5996, val_loss: 2470.9812\n",
      "[Epoch:  8] Average loss: 2059.4697, val_loss: 1363.5911\n",
      "[Epoch:  9] Average loss: 1770.1033, val_loss: 1183.0544\n",
      "[Epoch: 10] Average loss: 1634.8228, val_loss: 964.7881\n",
      "[Epoch: 11] Average loss: 1741.6593, val_loss: 1025.1941\n",
      "[Epoch: 12] Average loss: 1486.2272, val_loss: 1699.4443\n",
      "[Epoch: 13] Average loss: 1830.7837, val_loss: 1188.8289\n",
      "[Epoch: 14] Average loss: 1495.6873, val_loss: 1119.8545\n",
      "[Epoch: 15] Average loss: 1450.7186, val_loss: 972.4531\n",
      "[Epoch: 16] Average loss: 1592.2949, val_loss: 2023.9189\n",
      "[Epoch: 17] Average loss: 2172.3059, val_loss: 1174.6162\n",
      "[Epoch: 18] Average loss: 1631.0342, val_loss: 903.9666\n",
      "[Epoch: 19] Average loss: 1512.5494, val_loss: 931.9521\n",
      "[Epoch: 20] Average loss: 1438.2010, val_loss: 1430.9783\n",
      "[Epoch: 21] Average loss: 1337.4380, val_loss: 776.5287\n",
      "[Epoch: 22] Average loss: 1290.3422, val_loss: 1287.9393\n",
      "[Epoch: 23] Average loss: 1253.0312, val_loss: 1041.0476\n",
      "[Epoch: 24] Average loss: 1356.5707, val_loss: 866.0892\n",
      "[Epoch: 25] Average loss: 1509.1937, val_loss: 1807.2476\n",
      "[Epoch: 26] Average loss: 2884.1489, val_loss: 2499.4819\n",
      "[Epoch: 27] Average loss: 1908.3079, val_loss: 1122.0468\n",
      "[Epoch: 28] Average loss: 1535.9626, val_loss: 1442.9011\n",
      "[Epoch: 29] Average loss: 1349.2983, val_loss: 1136.4133\n",
      "[Epoch: 30] Average loss: 1368.3442, val_loss: 899.0412\n",
      "[Epoch: 31] Average loss: 1311.8760, val_loss: 927.3195\n",
      "[Epoch: 32] Average loss: 1855.5928, val_loss: 1217.1538\n",
      "[Epoch: 33] Average loss: 1558.3628, val_loss: 1828.5308\n",
      "[Epoch: 34] Average loss: 1417.6042, val_loss: 1359.3893\n",
      "[Epoch: 35] Average loss: 1320.4310, val_loss: 948.7177\n",
      "[Epoch: 36] Average loss: 1112.6777, val_loss: 749.8804\n",
      "[Epoch: 37] Average loss: 1109.8334, val_loss: 858.9851\n",
      "[Epoch: 38] Average loss: 1338.3750, val_loss: 1080.8750\n",
      "[Epoch: 39] Average loss: 1283.4774, val_loss: 1250.4021\n",
      "[Epoch: 40] Average loss: 1251.8778, val_loss: 995.6620\n",
      "[Epoch: 41] Average loss: 1199.6594, val_loss: 822.8577\n",
      "[Epoch: 42] Average loss: 1179.9039, val_loss: 844.0262\n",
      "[Epoch: 43] Average loss: 1339.7411, val_loss: 935.7701\n",
      "[Epoch: 44] Average loss: 1234.8295, val_loss: 1210.9265\n",
      "[Epoch: 45] Average loss: 1397.9840, val_loss: 818.0237\n",
      "[Epoch: 46] Average loss: 1330.6117, val_loss: 804.6013\n",
      "[Epoch: 47] Average loss: 1103.4292, val_loss: 954.8312\n",
      "[Epoch: 48] Average loss: 1160.0132, val_loss: 853.7748\n",
      "[Epoch: 49] Average loss: 1205.7096, val_loss: 824.2055\n",
      "[Epoch: 50] Average loss: 1143.9912, val_loss: 813.5367\n",
      "[Epoch: 51] Average loss: 1094.4489, val_loss: 906.4943\n",
      "[Epoch: 52] Average loss: 1126.1658, val_loss: 1340.8774\n",
      "[Epoch: 53] Average loss: 1351.5469, val_loss: 734.0745\n",
      "[Epoch: 54] Average loss: 1199.4712, val_loss: 651.5501\n",
      "[Epoch: 55] Average loss: 973.2399, val_loss: 778.0186\n",
      "[Epoch: 56] Average loss: 1088.9606, val_loss: 722.0161\n",
      "[Epoch: 57] Average loss: 1005.1486, val_loss: 839.6116\n",
      "[Epoch: 58] Average loss: 1095.9840, val_loss: 623.6627\n",
      "[Epoch: 59] Average loss: 1138.1879, val_loss: 892.2598\n",
      "[Epoch: 60] Average loss: 1098.4861, val_loss: 693.1731\n",
      "[Epoch: 61] Average loss: 1271.7700, val_loss: 757.7705\n",
      "[Epoch: 62] Average loss: 970.2487, val_loss: 606.3657\n",
      "[Epoch: 63] Average loss: 1031.9314, val_loss: 716.8044\n",
      "[Epoch: 64] Average loss: 1330.4834, val_loss: 997.3196\n",
      "[Epoch: 65] Average loss: 1715.0396, val_loss: 986.9729\n",
      "[Epoch: 66] Average loss: 1504.4344, val_loss: 1031.9146\n",
      "[Epoch: 67] Average loss: 1063.1945, val_loss: 689.2797\n",
      "[Epoch: 68] Average loss: 1010.2098, val_loss: 1117.1046\n",
      "[Epoch: 69] Average loss: 1319.4055, val_loss: 979.4415\n",
      "[Epoch: 70] Average loss: 1332.2355, val_loss: 1205.9320\n",
      "[Epoch: 71] Average loss: 1230.8801, val_loss: 792.5240\n",
      "[Epoch: 72] Average loss: 1073.4231, val_loss: 772.5610\n",
      "[Epoch: 73] Average loss: 1131.4807, val_loss: 694.2154\n",
      "[Epoch: 74] Average loss: 974.2077, val_loss: 701.0437\n",
      "[Epoch: 75] Average loss: 1100.1736, val_loss: 731.2211\n",
      "[Epoch: 76] Average loss: 1355.0648, val_loss: 973.1495\n",
      "[Epoch: 77] Average loss: 1105.0166, val_loss: 831.0482\n",
      "[Epoch: 78] Average loss: 901.7659, val_loss: 943.9264\n",
      "[Epoch: 79] Average loss: 836.8896, val_loss: 1110.3831\n",
      "[Epoch: 80] Average loss: 1030.9905, val_loss: 881.7097\n",
      "[Epoch: 81] Average loss: 982.2401, val_loss: 1042.9039\n",
      "[Epoch: 82] Average loss: 941.2888, val_loss: 846.1780\n",
      "[Epoch: 83] Average loss: 1169.0551, val_loss: 1010.8810\n",
      "[Epoch: 84] Average loss: 881.9247, val_loss: 644.1930\n",
      "[Epoch: 85] Average loss: 875.7177, val_loss: 718.7816\n",
      "[Epoch: 86] Average loss: 1028.5834, val_loss: 831.9147\n",
      "[Epoch: 87] Average loss: 979.5335, val_loss: 703.3737\n",
      "[Epoch: 88] Average loss: 980.4138, val_loss: 736.6625\n",
      "[Epoch: 89] Average loss: 1142.9532, val_loss: 722.1998\n",
      "[Epoch: 90] Average loss: 1103.3463, val_loss: 1282.7939\n",
      "[Epoch: 91] Average loss: 1232.0953, val_loss: 714.9534\n",
      "[Epoch: 92] Average loss: 1117.4753, val_loss: 626.8138\n",
      "[Epoch: 93] Average loss: 882.3768, val_loss: 680.3011\n",
      "[Epoch: 94] Average loss: 907.2642, val_loss: 838.0917\n",
      "[Epoch: 95] Average loss: 1540.7330, val_loss: 918.7134\n",
      "[Epoch: 96] Average loss: 1479.1995, val_loss: 1525.5334\n",
      "[Epoch: 97] Average loss: 1171.1924, val_loss: 1029.9061\n",
      "[Epoch: 98] Average loss: 976.0431, val_loss: 891.3955\n",
      "[Epoch: 99] Average loss: 961.0856, val_loss: 795.0535\n",
      "[Epoch: 100] Average loss: 779.1124, val_loss: 816.8335\n",
      "[Epoch: 101] Average loss: 916.7562, val_loss: 717.3093\n",
      "[Epoch: 102] Average loss: 924.0497, val_loss: 729.1928\n",
      "[Epoch: 103] Average loss: 904.1191, val_loss: 843.8507\n",
      "[Epoch: 104] Average loss: 856.2307, val_loss: 638.2243\n",
      "[Epoch: 105] Average loss: 912.3845, val_loss: 899.5349\n",
      "[Epoch: 106] Average loss: 894.7852, val_loss: 853.7805\n",
      "[Epoch: 107] Average loss: 972.9334, val_loss: 904.8538\n",
      "[Epoch: 108] Average loss: 958.5506, val_loss: 961.9921\n",
      "[Epoch: 109] Average loss: 1178.3242, val_loss: 711.4799\n",
      "[Epoch: 110] Average loss: 1396.4109, val_loss: 919.2450\n",
      "[Epoch: 111] Average loss: 1339.0829, val_loss: 1734.8824\n",
      "[Epoch: 112] Average loss: 1417.3320, val_loss: 1068.5524\n",
      "[Epoch: 113] Average loss: 912.2617, val_loss: 776.9392\n",
      "[Epoch: 114] Average loss: 992.2491, val_loss: 749.5627\n",
      "[Epoch: 115] Average loss: 935.2017, val_loss: 737.3336\n",
      "[Epoch: 116] Average loss: 815.4678, val_loss: 661.6292\n",
      "[Epoch: 117] Average loss: 911.1509, val_loss: 635.3376\n",
      "[Epoch: 118] Average loss: 1003.9236, val_loss: 806.1032\n",
      "[Epoch: 119] Average loss: 1057.6255, val_loss: 1028.7094\n",
      "[Epoch: 120] Average loss: 991.0804, val_loss: 675.9833\n",
      "[Epoch: 121] Average loss: 836.9061, val_loss: 846.0463\n",
      "[Epoch: 122] Average loss: 1035.9354, val_loss: 1057.7126\n",
      "[Epoch: 123] Average loss: 1009.9240, val_loss: 975.8487\n",
      "[Epoch: 124] Average loss: 1011.5302, val_loss: 765.8111\n",
      "[Epoch: 125] Average loss: 925.3698, val_loss: 877.8124\n",
      "[Epoch: 126] Average loss: 991.6783, val_loss: 804.8959\n",
      "[Epoch: 127] Average loss: 838.5334, val_loss: 709.1992\n",
      "[Epoch: 128] Average loss: 899.7974, val_loss: 696.2856\n",
      "[Epoch: 129] Average loss: 908.4352, val_loss: 707.5493\n",
      "[Epoch: 130] Average loss: 891.2433, val_loss: 716.5186\n",
      "[Epoch: 131] Average loss: 878.3643, val_loss: 627.8687\n",
      "[Epoch: 132] Average loss: 930.1127, val_loss: 619.0009\n",
      "[Epoch: 133] Average loss: 832.5458, val_loss: 627.6302\n",
      "[Epoch: 134] Average loss: 894.7888, val_loss: 651.3903\n",
      "[Epoch: 135] Average loss: 943.3760, val_loss: 946.9479\n",
      "[Epoch: 136] Average loss: 1131.9313, val_loss: 864.4114\n",
      "[Epoch: 137] Average loss: 983.2705, val_loss: 661.4741\n",
      "[Epoch: 138] Average loss: 1260.2837, val_loss: 1228.8357\n",
      "[Epoch: 139] Average loss: 1176.8574, val_loss: 707.1155\n",
      "[Epoch: 140] Average loss: 937.0371, val_loss: 805.2151\n",
      "[Epoch: 141] Average loss: 939.7308, val_loss: 733.4070\n",
      "[Epoch: 142] Average loss: 1142.3359, val_loss: 706.8230\n",
      "[Epoch: 143] Average loss: 1008.4522, val_loss: 773.9009\n",
      "[Epoch: 144] Average loss: 911.7523, val_loss: 754.6086\n",
      "[Epoch: 145] Average loss: 838.5458, val_loss: 714.6667\n",
      "[Epoch: 146] Average loss: 907.9579, val_loss: 767.8726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 147] Average loss: 862.0826, val_loss: 1018.4038\n",
      "[Epoch: 148] Average loss: 867.0449, val_loss: 587.1291\n",
      "[Epoch: 149] Average loss: 777.7991, val_loss: 643.0063\n",
      "[Epoch: 150] Average loss: 820.5073, val_loss: 677.5059\n",
      "[Epoch: 151] Average loss: 1280.9557, val_loss: 857.8763\n",
      "[Epoch: 152] Average loss: 978.0987, val_loss: 690.2148\n",
      "[Epoch: 153] Average loss: 847.6796, val_loss: 733.9296\n",
      "[Epoch: 154] Average loss: 878.9752, val_loss: 754.2997\n",
      "[Epoch: 155] Average loss: 806.6649, val_loss: 620.6897\n",
      "[Epoch: 156] Average loss: 706.4814, val_loss: 689.5688\n",
      "[Epoch: 157] Average loss: 870.4234, val_loss: 840.2589\n",
      "[Epoch: 158] Average loss: 841.9087, val_loss: 659.7205\n",
      "[Epoch: 159] Average loss: 908.7751, val_loss: 739.4746\n",
      "[Epoch: 160] Average loss: 822.1196, val_loss: 809.2917\n",
      "[Epoch: 161] Average loss: 914.5387, val_loss: 931.6133\n",
      "[Epoch: 162] Average loss: 963.8137, val_loss: 780.8416\n",
      "[Epoch: 163] Average loss: 1030.1266, val_loss: 912.0414\n",
      "[Epoch: 164] Average loss: 839.0438, val_loss: 794.6194\n",
      "[Epoch: 165] Average loss: 784.9363, val_loss: 683.7090\n",
      "[Epoch: 166] Average loss: 771.3580, val_loss: 893.2850\n",
      "[Epoch: 167] Average loss: 887.9665, val_loss: 625.3702\n",
      "[Epoch: 168] Average loss: 924.7520, val_loss: 808.7806\n",
      "[Epoch: 169] Average loss: 887.1850, val_loss: 819.5342\n",
      "[Epoch: 170] Average loss: 795.7556, val_loss: 625.9200\n",
      "[Epoch: 171] Average loss: 1164.2600, val_loss: 789.1349\n",
      "[Epoch: 172] Average loss: 1048.1934, val_loss: 1432.9595\n",
      "[Epoch: 173] Average loss: 1202.0677, val_loss: 797.2557\n",
      "[Epoch: 174] Average loss: 1088.4236, val_loss: 745.9979\n",
      "[Epoch: 175] Average loss: 954.1284, val_loss: 836.2045\n",
      "[Epoch: 176] Average loss: 985.5760, val_loss: 701.6436\n",
      "[Epoch: 177] Average loss: 966.9951, val_loss: 663.0550\n",
      "[Epoch: 178] Average loss: 861.6683, val_loss: 739.9226\n",
      "[Epoch: 179] Average loss: 968.7577, val_loss: 705.4111\n",
      "[Epoch: 180] Average loss: 768.5976, val_loss: 704.3528\n",
      "[Epoch: 181] Average loss: 833.1189, val_loss: 836.7607\n",
      "[Epoch: 182] Average loss: 813.8607, val_loss: 867.5197\n",
      "[Epoch: 183] Average loss: 957.7211, val_loss: 718.8264\n",
      "[Epoch: 184] Average loss: 915.2443, val_loss: 666.4700\n",
      "[Epoch: 185] Average loss: 863.2713, val_loss: 666.5365\n",
      "[Epoch: 186] Average loss: 971.5249, val_loss: 906.6844\n",
      "[Epoch: 187] Average loss: 865.8956, val_loss: 740.5166\n",
      "[Epoch: 188] Average loss: 998.5454, val_loss: 698.9806\n",
      "[Epoch: 189] Average loss: 907.8627, val_loss: 671.9464\n",
      "[Epoch: 190] Average loss: 823.1650, val_loss: 675.5997\n",
      "[Epoch: 191] Average loss: 863.8652, val_loss: 903.0288\n",
      "[Epoch: 192] Average loss: 868.9740, val_loss: 806.4900\n",
      "[Epoch: 193] Average loss: 877.8826, val_loss: 702.8298\n",
      "[Epoch: 194] Average loss: 889.7430, val_loss: 923.4138\n",
      "[Epoch: 195] Average loss: 807.1702, val_loss: 690.0449\n",
      "[Epoch: 196] Average loss: 958.8759, val_loss: 699.3711\n",
      "[Epoch: 197] Average loss: 904.7925, val_loss: 850.2493\n",
      "[Epoch: 198] Average loss: 756.0875, val_loss: 855.1974\n",
      "[Epoch: 199] Average loss: 1076.5347, val_loss: 713.9832\n",
      "[Epoch: 200] Average loss: 1030.2236, val_loss: 870.5074\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    avg_loss = 0\n",
    "\n",
    "    for X1, X2, Y in train_loader:\n",
    "        X1 = X1.to(device)\n",
    "        X2 = X2.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        model.zero_grad()  # why we use zero_grad?\n",
    "        prediction = model(X1, X2)\n",
    "        loss = torch.sqrt(criterion(prediction, Y)).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss / len(train_loader)\n",
    "    print(f'[Epoch: {epoch+1:>2}] Average loss: {avg_loss:.4f}, ', end='')\n",
    "    \n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    with torch.no_grad():\n",
    "        val_avg_loss = 0.\n",
    "        for X1_val, X2_val, Y_val in val_loader:\n",
    "            X1_val = X1_val.to(device)\n",
    "            X2_val = X2_val.to(device)\n",
    "            Y_val = Y_val.to(device)\n",
    "            val_prediction = model(X1_val, X2_val)\n",
    "            val_loss = torch.sqrt(criterion(val_prediction, Y_val)).to(device)\n",
    "            val_avg_loss += val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"val_loss: {val_avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aa9855b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:22:25.017973Z",
     "start_time": "2022-02-23T14:22:24.869007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.27%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "criterion.eval()\n",
    "ss_tot = 0\n",
    "ss_res = 0\n",
    "with torch.no_grad():\n",
    "    for X1_test, X2_test, Y_test in test_loader:\n",
    "        X1_test = X1_test.to(device)\n",
    "        X2_test = X2_test.to(device)\n",
    "        Y_test = Y_test.to(device)\n",
    "        prediction = model(X1_test, X2_test)\n",
    "        prices_mean = torch.mean(Y_test)\n",
    "        ss_tot += torch.sum((Y_test - prices_mean) ** 2)\n",
    "        ss_res += torch.sum((Y_test - prediction) ** 2)\n",
    "    \n",
    "    accuracy = 1 - ss_res/ss_tot\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a572d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python-3-9-7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
