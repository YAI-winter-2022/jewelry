{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7bf85c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T13:39:55.554407Z",
     "start_time": "2022-02-25T13:39:54.800672Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88539da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T13:39:55.570364Z",
     "start_time": "2022-02-25T13:39:55.555404Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_path = \".\"\n",
    "image_path = \"./images\"\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c5b968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T13:39:55.693984Z",
     "start_time": "2022-02-25T13:39:55.571361Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78410749",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T13:39:55.709449Z",
     "start_time": "2022-02-25T13:39:55.694974Z"
    }
   },
   "outputs": [],
   "source": [
    "class AllDataset(Dataset):\n",
    "    def __init__(self, csv_path, image_path, image_transform=transforms.Compose([transforms.ToTensor()])):\n",
    "        super(AllDataset).__init__()\n",
    "        csv = pd.read_csv(csv_path)\n",
    "        csv_np = csv.to_numpy()\n",
    "        \n",
    "        self.image_transform = image_transform\n",
    "        self.ids = list(map(str, csv_np[:,0]))\n",
    "        self.image_path = image_path\n",
    "        \n",
    "        for i in [1, 3, 4, 5, 6, 7, 8]:\n",
    "            wordset = {word: idx for idx, word in enumerate(np.unique(csv_np[:,i]))}\n",
    "            for row in range(len(csv_np)):\n",
    "                csv_np[row][i] = wordset[csv_np[row][i]]\n",
    "        self.ints = torch.from_numpy(np.array(csv_np[:,[1,3,4,5,6,7,8]], dtype=\"int\"))\n",
    "        self.floats = torch.from_numpy(np.array(csv_np[:,[2,9,10,11]], dtype=\"float\")).float()\n",
    "        self.target = torch.from_numpy(np.array(csv_np[:,[12]], dtype=\"float\")).float()\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = Image.open(self.image_path+'/'+self.ids[idx]+'.jpg')\n",
    "        image_tensor = self.image_transform(image)\n",
    "        image.close()\n",
    "        return image_tensor, self.ints[idx],self.floats[idx], self.target[idx]\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8af2023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T13:39:55.740366Z",
     "start_time": "2022-02-25T13:39:55.710448Z"
    }
   },
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([transforms.ToTensor()\n",
    "                                     ])\n",
    "\n",
    "train_dataset = AllDataset(csv_path+'/train.csv', image_path, image_transform)\n",
    "test_dataset = AllDataset(csv_path+'/test.csv', image_path, image_transform)\n",
    "val_dataset = AllDataset(csv_path+'/val.csv', image_path, image_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a46f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T13:39:55.756323Z",
     "start_time": "2022-02-25T13:39:55.741364Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.resnet18 = torchvision.models.resnet18(pretrained=False)\n",
    "        self.resnet18.fc = nn.Sequential(nn.Linear(512, 4096),\n",
    "                                         nn.BatchNorm1d(4096),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout()\n",
    "                                        )\n",
    "        self.resenet18 = self.resnet18.to(device)\n",
    "        \n",
    "        self.emb1 = torch.nn.Embedding(8, 20)\n",
    "        self.emb2 = torch.nn.Embedding(11, 20)\n",
    "        self.emb3 = torch.nn.Embedding(20, 20)\n",
    "        self.emb4 = torch.nn.Embedding(4, 20)\n",
    "        self.emb5 = torch.nn.Embedding(4, 20)\n",
    "        self.emb6 = torch.nn.Embedding(4, 20)\n",
    "        self.emb7 = torch.nn.Embedding(7, 20)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc = nn.Linear(4, 80)\n",
    "        self.csvbn = nn.BatchNorm1d(80)\n",
    "        self.csvfc1 = nn.Linear(220, 8192)\n",
    "        self.csvfc2 = nn.Linear(8192, 8192)\n",
    "        self.csvfc3 = nn.Linear(8192, 4096)\n",
    "        self.csvbn1 = nn.BatchNorm1d(8192)\n",
    "        self.csvbn2 = nn.BatchNorm1d(8192)\n",
    "        self.csvbn3 = nn.BatchNorm1d(4096)\n",
    "        \n",
    "        self.fc1 = nn.Linear(8192, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(4096)\n",
    "        self.dropout = nn.Dropout()\n",
    "    \n",
    "    def forward(self, image, x, y):\n",
    "        image = self.resnet18(image)\n",
    "        \n",
    "        x1 = self.emb1(x[:,0])\n",
    "        x2 = self.emb2(x[:,1])\n",
    "        x3 = self.emb3(x[:,2])\n",
    "        x4 = self.emb4(x[:,3])\n",
    "        x5 = self.emb5(x[:,4])\n",
    "        x6 = self.emb6(x[:,5])\n",
    "        x7 = self.emb7(x[:,6])\n",
    "        y = self.csvbn(self.fc(y))\n",
    "        x = torch.cat((x1, x2, x3, x4, x5, x6, x7, y), dim=1)\n",
    "        \n",
    "        x = self.dropout(self.act(self.csvbn1(self.csvfc1(x))))\n",
    "        x = self.dropout(self.act(self.csvbn2(self.csvfc2(x))))\n",
    "        x = self.dropout(self.act(self.csvbn3(self.csvfc3(x))))\n",
    "        x = torch.cat((x, image), dim=1)\n",
    "        \n",
    "        x = self.dropout(self.act(self.bn1(self.fc1(x))))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3749f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T13:39:56.474068Z",
     "start_time": "2022-02-25T13:39:55.757320Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad748bfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T14:14:23.663236Z",
     "start_time": "2022-02-25T13:39:56.475066Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:  1] Average loss: 4386.0732, val_loss: 4059.1494\n",
      "[Epoch:  2] Average loss: 4343.2930, val_loss: 4595.4800\n",
      "[Epoch:  3] Average loss: 4502.4038, val_loss: 4164.3027\n",
      "[Epoch:  4] Average loss: 4359.0620, val_loss: 4488.6191\n",
      "[Epoch:  5] Average loss: 4605.9663, val_loss: 4314.8706\n",
      "[Epoch:  6] Average loss: 4173.6626, val_loss: 4099.2759\n",
      "[Epoch:  7] Average loss: 5594.8481, val_loss: 4183.4932\n",
      "[Epoch:  8] Average loss: 3928.9604, val_loss: 4126.0942\n",
      "[Epoch:  9] Average loss: 4113.3047, val_loss: 4247.1777\n",
      "[Epoch: 10] Average loss: 3947.5435, val_loss: 3882.3040\n",
      "[Epoch: 11] Average loss: 3934.0725, val_loss: 3934.1631\n",
      "[Epoch: 12] Average loss: 3841.7168, val_loss: 3943.6484\n",
      "[Epoch: 13] Average loss: 3920.7812, val_loss: 3540.2773\n",
      "[Epoch: 14] Average loss: 3730.4177, val_loss: 3718.4382\n",
      "[Epoch: 15] Average loss: 3614.7852, val_loss: 3379.8533\n",
      "[Epoch: 16] Average loss: 3639.3958, val_loss: 3602.7327\n",
      "[Epoch: 17] Average loss: 3795.5361, val_loss: 3676.9663\n",
      "[Epoch: 18] Average loss: 3510.5715, val_loss: 3372.4563\n",
      "[Epoch: 19] Average loss: 3393.6211, val_loss: 3423.3125\n",
      "[Epoch: 20] Average loss: 3292.2827, val_loss: 2961.1299\n",
      "[Epoch: 21] Average loss: 3185.8682, val_loss: 3014.6602\n",
      "[Epoch: 22] Average loss: 3204.5022, val_loss: 2998.7488\n",
      "[Epoch: 23] Average loss: 3116.4319, val_loss: 2917.1895\n",
      "[Epoch: 24] Average loss: 3101.2861, val_loss: 2458.9106\n",
      "[Epoch: 25] Average loss: 3094.3723, val_loss: 3003.6101\n",
      "[Epoch: 26] Average loss: 2926.6919, val_loss: 2766.0186\n",
      "[Epoch: 27] Average loss: 2797.2854, val_loss: 2557.2598\n",
      "[Epoch: 28] Average loss: 2774.3616, val_loss: 2465.5906\n",
      "[Epoch: 29] Average loss: 2658.5662, val_loss: 2564.6680\n",
      "[Epoch: 30] Average loss: 2630.1653, val_loss: 2449.9646\n",
      "[Epoch: 31] Average loss: 4157.5884, val_loss: 2766.3208\n",
      "[Epoch: 32] Average loss: 2441.4578, val_loss: 2546.0630\n",
      "[Epoch: 33] Average loss: 2357.8923, val_loss: 2030.2678\n",
      "[Epoch: 34] Average loss: 2323.2935, val_loss: 2425.6655\n",
      "[Epoch: 35] Average loss: 2206.6062, val_loss: 1817.6284\n",
      "[Epoch: 36] Average loss: 2170.1238, val_loss: 1971.2131\n",
      "[Epoch: 37] Average loss: 2074.8694, val_loss: 1619.3259\n",
      "[Epoch: 38] Average loss: 2292.2683, val_loss: 1616.1915\n",
      "[Epoch: 39] Average loss: 1974.3621, val_loss: 1852.8661\n",
      "[Epoch: 40] Average loss: 1925.9813, val_loss: 1732.5148\n",
      "[Epoch: 41] Average loss: 1937.7931, val_loss: 1709.9142\n",
      "[Epoch: 42] Average loss: 1807.2598, val_loss: 1682.0278\n",
      "[Epoch: 43] Average loss: 1691.9292, val_loss: 1324.4536\n",
      "[Epoch: 44] Average loss: 1869.1620, val_loss: 1872.4951\n",
      "[Epoch: 45] Average loss: 1749.7618, val_loss: 1513.5549\n",
      "[Epoch: 46] Average loss: 1658.8160, val_loss: 1688.4253\n",
      "[Epoch: 47] Average loss: 1555.1827, val_loss: 1659.3717\n",
      "[Epoch: 48] Average loss: 1675.1719, val_loss: 1565.7104\n",
      "[Epoch: 49] Average loss: 1543.2474, val_loss: 1485.9113\n",
      "[Epoch: 50] Average loss: 1621.5635, val_loss: 1642.2362\n",
      "[Epoch: 51] Average loss: 1662.1237, val_loss: 1455.6948\n",
      "[Epoch: 52] Average loss: 1678.1731, val_loss: 1406.2461\n",
      "[Epoch: 53] Average loss: 1481.2637, val_loss: 1413.9700\n",
      "[Epoch: 54] Average loss: 1526.2710, val_loss: 1252.0856\n",
      "[Epoch: 55] Average loss: 1432.0813, val_loss: 1220.5864\n",
      "[Epoch: 56] Average loss: 1508.1859, val_loss: 1326.3768\n",
      "[Epoch: 57] Average loss: 1572.8304, val_loss: 1432.8960\n",
      "[Epoch: 58] Average loss: 1328.3398, val_loss: 1353.6572\n",
      "[Epoch: 59] Average loss: 1244.0521, val_loss: 1200.1318\n",
      "[Epoch: 60] Average loss: 1411.4058, val_loss: 1367.5471\n",
      "[Epoch: 61] Average loss: 1631.2880, val_loss: 1403.8496\n",
      "[Epoch: 62] Average loss: 1519.1108, val_loss: 1858.1798\n",
      "[Epoch: 63] Average loss: 1367.5901, val_loss: 1297.0016\n",
      "[Epoch: 64] Average loss: 1276.5287, val_loss: 1434.4426\n",
      "[Epoch: 65] Average loss: 1207.5942, val_loss: 1479.8279\n",
      "[Epoch: 66] Average loss: 1290.0784, val_loss: 1306.5637\n",
      "[Epoch: 67] Average loss: 1224.5375, val_loss: 1136.9669\n",
      "[Epoch: 68] Average loss: 1307.1252, val_loss: 1211.1132\n",
      "[Epoch: 69] Average loss: 1246.2776, val_loss: 1330.8075\n",
      "[Epoch: 70] Average loss: 1309.0675, val_loss: 1577.6323\n",
      "[Epoch: 71] Average loss: 1169.9658, val_loss: 1272.5342\n",
      "[Epoch: 72] Average loss: 1294.7135, val_loss: 1242.3054\n",
      "[Epoch: 73] Average loss: 1181.2207, val_loss: 1215.7773\n",
      "[Epoch: 74] Average loss: 1267.4287, val_loss: 1218.4830\n",
      "[Epoch: 75] Average loss: 1718.6216, val_loss: 1386.5731\n",
      "[Epoch: 76] Average loss: 1125.3661, val_loss: 1493.8240\n",
      "[Epoch: 77] Average loss: 1130.1453, val_loss: 1435.9116\n",
      "[Epoch: 78] Average loss: 1272.6832, val_loss: 1322.7820\n",
      "[Epoch: 79] Average loss: 1175.0226, val_loss: 1186.6191\n",
      "[Epoch: 80] Average loss: 1340.1844, val_loss: 1405.8004\n",
      "[Epoch: 81] Average loss: 1177.4596, val_loss: 1371.5093\n",
      "[Epoch: 82] Average loss: 1253.7224, val_loss: 1161.1986\n",
      "[Epoch: 83] Average loss: 1327.7240, val_loss: 1291.3333\n",
      "[Epoch: 84] Average loss: 1224.4202, val_loss: 1287.1329\n",
      "[Epoch: 85] Average loss: 1257.8961, val_loss: 1311.5850\n",
      "[Epoch: 86] Average loss: 1490.1605, val_loss: 1569.3433\n",
      "[Epoch: 87] Average loss: 1254.6469, val_loss: 1378.0496\n",
      "[Epoch: 88] Average loss: 1133.0474, val_loss: 1197.7094\n",
      "[Epoch: 89] Average loss: 1161.7407, val_loss: 1304.4193\n",
      "[Epoch: 90] Average loss: 1074.5262, val_loss: 1384.2441\n",
      "[Epoch: 91] Average loss: 1202.8296, val_loss: 1420.5635\n",
      "[Epoch: 92] Average loss: 1137.2374, val_loss: 1395.5688\n",
      "[Epoch: 93] Average loss: 1080.8064, val_loss: 1198.4535\n",
      "[Epoch: 94] Average loss: 975.6944, val_loss: 1414.9784\n",
      "[Epoch: 95] Average loss: 1214.5604, val_loss: 1682.3867\n",
      "[Epoch: 96] Average loss: 1202.4617, val_loss: 1397.8535\n",
      "[Epoch: 97] Average loss: 1349.2009, val_loss: 1545.0818\n",
      "[Epoch: 98] Average loss: 1095.7607, val_loss: 1228.6228\n",
      "[Epoch: 99] Average loss: 1334.5742, val_loss: 1329.4546\n",
      "[Epoch: 100] Average loss: 1776.7280, val_loss: 1549.3618\n",
      "[Epoch: 101] Average loss: 1138.1423, val_loss: 1424.8916\n",
      "[Epoch: 102] Average loss: 1107.8833, val_loss: 1240.8413\n",
      "[Epoch: 103] Average loss: 1078.3312, val_loss: 1465.0265\n",
      "[Epoch: 104] Average loss: 1229.1737, val_loss: 1372.6472\n",
      "[Epoch: 105] Average loss: 1131.0377, val_loss: 1519.0198\n",
      "[Epoch: 106] Average loss: 1042.3190, val_loss: 1514.5507\n",
      "[Epoch: 107] Average loss: 1055.2281, val_loss: 1497.6161\n",
      "[Epoch: 108] Average loss: 1005.0957, val_loss: 1384.1188\n",
      "[Epoch: 109] Average loss: 972.7524, val_loss: 1619.6692\n",
      "[Epoch: 110] Average loss: 999.6180, val_loss: 1329.9520\n",
      "[Epoch: 111] Average loss: 1050.7720, val_loss: 1429.2629\n",
      "[Epoch: 112] Average loss: 967.4444, val_loss: 1499.7162\n",
      "[Epoch: 113] Average loss: 1044.2432, val_loss: 1339.0292\n",
      "[Epoch: 114] Average loss: 1028.6224, val_loss: 1505.7205\n",
      "[Epoch: 115] Average loss: 1146.9690, val_loss: 1651.6210\n",
      "[Epoch: 116] Average loss: 1006.9155, val_loss: 1283.6797\n",
      "[Epoch: 117] Average loss: 1135.1434, val_loss: 1920.9623\n",
      "[Epoch: 118] Average loss: 1950.4166, val_loss: 1800.0922\n",
      "[Epoch: 119] Average loss: 1105.7716, val_loss: 1687.4088\n",
      "[Epoch: 120] Average loss: 989.6949, val_loss: 1328.9084\n",
      "[Epoch: 121] Average loss: 965.9025, val_loss: 1454.2371\n",
      "[Epoch: 122] Average loss: 1282.9303, val_loss: 1436.9766\n",
      "[Epoch: 123] Average loss: 1075.6877, val_loss: 1379.3334\n",
      "[Epoch: 124] Average loss: 1058.1033, val_loss: 1321.4407\n",
      "[Epoch: 125] Average loss: 953.0651, val_loss: 1654.3693\n",
      "[Epoch: 126] Average loss: 1100.6964, val_loss: 1459.2078\n",
      "[Epoch: 127] Average loss: 1182.7637, val_loss: 1373.5708\n",
      "[Epoch: 128] Average loss: 941.9019, val_loss: 1396.8358\n",
      "[Epoch: 129] Average loss: 1043.8574, val_loss: 1555.8823\n",
      "[Epoch: 130] Average loss: 979.7814, val_loss: 1342.9722\n",
      "[Epoch: 131] Average loss: 963.0688, val_loss: 1524.4619\n",
      "[Epoch: 132] Average loss: 783.0215, val_loss: 1500.9789\n",
      "[Epoch: 133] Average loss: 1077.3243, val_loss: 1488.3959\n",
      "[Epoch: 134] Average loss: 1055.7498, val_loss: 1340.7292\n",
      "[Epoch: 135] Average loss: 2608.9453, val_loss: 1991.9849\n",
      "[Epoch: 136] Average loss: 840.8042, val_loss: 1525.0627\n",
      "[Epoch: 137] Average loss: 897.6283, val_loss: 1582.0408\n",
      "[Epoch: 138] Average loss: 940.2932, val_loss: 1440.5027\n",
      "[Epoch: 139] Average loss: 1100.8539, val_loss: 1751.3232\n",
      "[Epoch: 140] Average loss: 932.5312, val_loss: 1540.3125\n",
      "[Epoch: 141] Average loss: 2249.3926, val_loss: 1825.9225\n",
      "[Epoch: 142] Average loss: 1037.3972, val_loss: 1474.9814\n",
      "[Epoch: 143] Average loss: 961.4753, val_loss: 1429.4495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 144] Average loss: 939.9152, val_loss: 1447.3506\n",
      "[Epoch: 145] Average loss: 1019.9977, val_loss: 1579.7068\n",
      "[Epoch: 146] Average loss: 1011.0018, val_loss: 1372.9178\n",
      "[Epoch: 147] Average loss: 983.1951, val_loss: 1555.9540\n",
      "[Epoch: 148] Average loss: 829.1470, val_loss: 1379.1600\n",
      "[Epoch: 149] Average loss: 923.9688, val_loss: 1326.6255\n",
      "[Epoch: 150] Average loss: 1004.4633, val_loss: 1646.6611\n",
      "[Epoch: 151] Average loss: 1012.2207, val_loss: 1648.0925\n",
      "[Epoch: 152] Average loss: 2553.4202, val_loss: 1939.2454\n",
      "[Epoch: 153] Average loss: 824.9622, val_loss: 1562.1403\n",
      "[Epoch: 154] Average loss: 850.0100, val_loss: 1608.1995\n",
      "[Epoch: 155] Average loss: 937.5533, val_loss: 1742.9166\n",
      "[Epoch: 156] Average loss: 996.8402, val_loss: 1399.1776\n",
      "[Epoch: 157] Average loss: 982.6718, val_loss: 1265.3888\n",
      "[Epoch: 158] Average loss: 892.2037, val_loss: 1343.4982\n",
      "[Epoch: 159] Average loss: 847.6124, val_loss: 1483.1326\n",
      "[Epoch: 160] Average loss: 1623.6033, val_loss: 1649.7344\n",
      "[Epoch: 161] Average loss: 987.8956, val_loss: 1573.6578\n",
      "[Epoch: 162] Average loss: 1187.7708, val_loss: 1582.7589\n",
      "[Epoch: 163] Average loss: 864.6984, val_loss: 1537.1157\n",
      "[Epoch: 164] Average loss: 965.3029, val_loss: 1499.1503\n",
      "[Epoch: 165] Average loss: 888.3470, val_loss: 1589.4039\n",
      "[Epoch: 166] Average loss: 865.8550, val_loss: 1297.7552\n",
      "[Epoch: 167] Average loss: 1010.0164, val_loss: 1420.9767\n",
      "[Epoch: 168] Average loss: 898.4397, val_loss: 1588.8281\n",
      "[Epoch: 169] Average loss: 964.6685, val_loss: 1543.9104\n",
      "[Epoch: 170] Average loss: 673.7234, val_loss: 1372.7578\n",
      "[Epoch: 171] Average loss: 802.4122, val_loss: 1485.0449\n",
      "[Epoch: 172] Average loss: 793.2373, val_loss: 1434.8636\n",
      "[Epoch: 173] Average loss: 770.9573, val_loss: 1516.4314\n",
      "[Epoch: 174] Average loss: 1050.1908, val_loss: 1420.9854\n",
      "[Epoch: 175] Average loss: 904.6406, val_loss: 1454.9027\n",
      "[Epoch: 176] Average loss: 796.0645, val_loss: 1384.7380\n",
      "[Epoch: 177] Average loss: 859.0800, val_loss: 1565.3623\n",
      "[Epoch: 178] Average loss: 851.0903, val_loss: 1435.3237\n",
      "[Epoch: 179] Average loss: 806.3962, val_loss: 1401.4832\n",
      "[Epoch: 180] Average loss: 917.8351, val_loss: 1375.2683\n",
      "[Epoch: 181] Average loss: 687.9725, val_loss: 1371.3212\n",
      "[Epoch: 182] Average loss: 809.4498, val_loss: 1438.1622\n",
      "[Epoch: 183] Average loss: 879.4808, val_loss: 1541.4177\n",
      "[Epoch: 184] Average loss: 867.6456, val_loss: 1692.8438\n",
      "[Epoch: 185] Average loss: 875.7784, val_loss: 1537.6265\n",
      "[Epoch: 186] Average loss: 1051.6650, val_loss: 1400.4913\n",
      "[Epoch: 187] Average loss: 841.6843, val_loss: 1481.6649\n",
      "[Epoch: 188] Average loss: 833.5859, val_loss: 1624.0903\n",
      "[Epoch: 189] Average loss: 883.7580, val_loss: 1578.7246\n",
      "[Epoch: 190] Average loss: 933.2770, val_loss: 1364.8889\n",
      "[Epoch: 191] Average loss: 938.4877, val_loss: 1510.2374\n",
      "[Epoch: 192] Average loss: 920.4952, val_loss: 1704.0312\n",
      "[Epoch: 193] Average loss: 763.6603, val_loss: 1526.0712\n",
      "[Epoch: 194] Average loss: 1057.5806, val_loss: 1439.0557\n",
      "[Epoch: 195] Average loss: 806.6204, val_loss: 1524.0059\n",
      "[Epoch: 196] Average loss: 875.6043, val_loss: 1595.7396\n",
      "[Epoch: 197] Average loss: 784.6854, val_loss: 1448.5112\n",
      "[Epoch: 198] Average loss: 830.8839, val_loss: 1650.2603\n",
      "[Epoch: 199] Average loss: 792.8636, val_loss: 1360.0227\n",
      "[Epoch: 200] Average loss: 746.2523, val_loss: 1475.1199\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    avg_loss = 0\n",
    "\n",
    "    for Img, X1, X2, Y in train_loader:\n",
    "        Img = Img.to(device)\n",
    "        X1 = X1.to(device)\n",
    "        X2 = X2.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        prediction = model(Img, X1, X2)\n",
    "        loss = torch.sqrt(criterion(prediction, Y)).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss / len(train_loader)\n",
    "    print(f'[Epoch: {epoch+1:>2}] Average loss: {avg_loss:.4f}, ', end='')\n",
    "    \n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    with torch.no_grad():\n",
    "        val_avg_loss = 0.\n",
    "        for Image_val, X1_val, X2_val, Y_val in val_loader:\n",
    "            Image_val = Image_val.to(device)\n",
    "            X1_val = X1_val.to(device)\n",
    "            X2_val = X2_val.to(device)\n",
    "            Y_val = Y_val.to(device)\n",
    "            val_prediction = model(Image_val, X1_val, X2_val)\n",
    "            val_loss = torch.sqrt(criterion(val_prediction, Y_val)).to(device)\n",
    "            val_avg_loss += val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"val_loss: {val_avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "434a531a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T14:14:26.004238Z",
     "start_time": "2022-02-25T14:14:23.664202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.98%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "criterion.eval()\n",
    "ss_tot = 0\n",
    "ss_res = 0\n",
    "with torch.no_grad():\n",
    "    for Image_test, X1_test, X2_test, Y_test in test_loader:\n",
    "        Image_test =Image_test.to(device)\n",
    "        X1_test = X1_test.to(device)\n",
    "        X2_test = X2_test.to(device)\n",
    "        Y_test = Y_test.to(device)\n",
    "        prediction = model(Image_test, X1_test, X2_test)\n",
    "        mean = torch.mean(Y_test)\n",
    "        ss_tot += torch.sum((Y_test - mean) ** 2)\n",
    "        ss_res += torch.sum((Y_test - prediction) ** 2)\n",
    "    \n",
    "    accuracy = 1 - ss_res/ss_tot\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python-3-9-7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
