{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd03e70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T13:29:23.819486Z",
     "start_time": "2022-02-23T13:29:22.696952Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab9a308",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T13:29:23.834487Z",
     "start_time": "2022-02-23T13:29:23.820484Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_path = \"final.csv\"\n",
    "image_path = \"./images\"\n",
    "batch_size = 400\n",
    "epochs = 70\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e251de1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T13:29:23.973815Z",
     "start_time": "2022-02-23T13:29:23.835486Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, image_path, csv_transform=None, image_transform=transforms.Compose([transforms.ToTensor()])):\n",
    "        super(Dataset).__init__()\n",
    "        csv = pd.read_csv(csv_path)\n",
    "        csv_np = csv.to_numpy()\n",
    "        self.images = []\n",
    "        for Id in csv['Id']:\n",
    "            Id = str(Id)\n",
    "            image = Image.open(image_path+'/'+Id+'.jpg')\n",
    "            self.images.append(image_transform(image))\n",
    "            image.close()\n",
    "        \n",
    "        for i in [1, 3, 4, 5, 6, 7, 8]:\n",
    "            wordset = {word: idx for idx, word in enumerate(np.unique(csv_np[:,i]))}\n",
    "            for row in range(len(csv_np)):\n",
    "                csv_np[row][i] = wordset[csv_np[row][i]]\n",
    "        self.ints = torch.from_numpy(np.array(csv_np[:,[1,3,4,5,6,7,8]], dtype=\"int\"))\n",
    "        self.floats = torch.from_numpy(np.array(csv_np[:,[2,9,10,11]], dtype=\"float\")).float()\n",
    "        if csv_transform is not None:\n",
    "            self.floats = torch.tensor(csv_transform(self.floats), dtype = torch.float)\n",
    "        self.target = torch.from_numpy(np.array(csv_np[:,[12]], dtype=\"float\")).float()\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.images[idx], self.ints[idx],self.floats[idx], self.target[idx]\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0274e9ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T13:29:30.835034Z",
     "start_time": "2022-02-23T13:29:23.974681Z"
    }
   },
   "outputs": [],
   "source": [
    "data_length = len(pd.read_csv(csv_path))\n",
    "train_length = int(data_length * 0.6)\n",
    "test_length = int(data_length * 0.2)\n",
    "val_length = data_length - train_length - test_length\n",
    "\n",
    "csv_transform = None\n",
    "image_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = Dataset(csv_path, image_path, csv_transform, image_transform)\n",
    "train_dataset, test_dataset = random_split(train_dataset, [train_length, test_length+val_length])\n",
    "test_dataset, val_dataset = random_split(test_dataset, [test_length, val_length])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37355947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T13:29:30.850960Z",
     "start_time": "2022-02-23T13:29:30.836000Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.resnet18 = torchvision.models.resnet18(pretrained=False)\n",
    "        self.resnet18.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet18.fc = nn.Sequential(nn.Linear(512, 4096), nn.ReLU())\n",
    "        self.resenet18 = self.resnet18.to(device)\n",
    "        \n",
    "        self.emb1 = torch.nn.Embedding(8, 20)\n",
    "        self.emb2 = torch.nn.Embedding(11, 20)\n",
    "        self.emb3 = torch.nn.Embedding(20, 20)\n",
    "        self.emb4 = torch.nn.Embedding(4, 20)\n",
    "        self.emb5 = torch.nn.Embedding(4, 20)\n",
    "        self.emb6 = torch.nn.Embedding(4, 20)\n",
    "        self.emb7 = torch.nn.Embedding(7, 20)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc = nn.Linear(4, 80)\n",
    "        self.csvfc1 = nn.Linear(220, 8192)\n",
    "        self.csvfc2 = nn.Linear(8192, 8192)\n",
    "        self.csvfc3 = nn.Linear(8192, 4096)\n",
    "        \n",
    "        self.fc1 = nn.Linear(8192, 8192)\n",
    "        self.fc2 = nn.Linear(8192, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2048)\n",
    "        self.fc4 = nn.Linear(2048, 1)\n",
    "        self.dropout = nn.Dropout()\n",
    "    \n",
    "    def forward(self, image, x, y):\n",
    "        image = self.resnet18(image)\n",
    "        \n",
    "        x1 = self.emb1(x[:,0])\n",
    "        x2 = self.emb2(x[:,1])\n",
    "        x3 = self.emb3(x[:,2])\n",
    "        x4 = self.emb4(x[:,3])\n",
    "        x5 = self.emb5(x[:,4])\n",
    "        x6 = self.emb6(x[:,5])\n",
    "        x7 = self.emb7(x[:,6])\n",
    "        y = self.fc(y)\n",
    "        x = torch.cat((x1, x2, x3, x4, x5, x6, x7, y), dim=1)\n",
    "        \n",
    "        x = self.dropout(self.act(self.csvfc1(x)))\n",
    "        x = self.dropout(self.act(self.csvfc2(x)))\n",
    "        x = self.dropout(self.act(self.csvfc3(x)))\n",
    "        x = torch.cat((x, image), dim=1)\n",
    "        \n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        x = self.act(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e751855f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T13:29:31.820017Z",
     "start_time": "2022-02-23T13:29:30.851958Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d68d9b98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T13:35:39.189566Z",
     "start_time": "2022-02-23T13:29:31.821014Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:  1] Average loss: 9250.9082, val_loss: 4809.6963\n",
      "[Epoch:  2] Average loss: 4477.8555, val_loss: 5128.0391\n",
      "[Epoch:  3] Average loss: 3833.0349, val_loss: 4807.1484\n",
      "[Epoch:  4] Average loss: 3467.8557, val_loss: 5305.4473\n",
      "[Epoch:  5] Average loss: 3586.7563, val_loss: 3557.1631\n",
      "[Epoch:  6] Average loss: 4161.3203, val_loss: 3091.5693\n",
      "[Epoch:  7] Average loss: 3370.6348, val_loss: 28112.0469\n",
      "[Epoch:  8] Average loss: 3174.0352, val_loss: 73426.5938\n",
      "[Epoch:  9] Average loss: 2884.8325, val_loss: 114073.8047\n",
      "[Epoch: 10] Average loss: 2912.8489, val_loss: 67336.7109\n",
      "[Epoch: 11] Average loss: 2615.5059, val_loss: 6740.7998\n",
      "[Epoch: 12] Average loss: 2957.8135, val_loss: 2092.3462\n",
      "[Epoch: 13] Average loss: 2160.2375, val_loss: 2752.5725\n",
      "[Epoch: 14] Average loss: 2426.1841, val_loss: 18739.5293\n",
      "[Epoch: 15] Average loss: 2492.4585, val_loss: 2576.2170\n",
      "[Epoch: 16] Average loss: 2620.5085, val_loss: 84148.4141\n",
      "[Epoch: 17] Average loss: 2746.3887, val_loss: 2078.5078\n",
      "[Epoch: 18] Average loss: 2304.1860, val_loss: 5392.1387\n",
      "[Epoch: 19] Average loss: 2558.0188, val_loss: 2750.9604\n",
      "[Epoch: 20] Average loss: 2632.9202, val_loss: 2627.9092\n",
      "[Epoch: 21] Average loss: 2072.6978, val_loss: 1534.6576\n",
      "[Epoch: 22] Average loss: 2031.9854, val_loss: 1907.4215\n",
      "[Epoch: 23] Average loss: 1920.0634, val_loss: 11316.5957\n",
      "[Epoch: 24] Average loss: 2231.9077, val_loss: 28148.3418\n",
      "[Epoch: 25] Average loss: 2557.3496, val_loss: 25180.8945\n",
      "[Epoch: 26] Average loss: 2094.1851, val_loss: 35581.0273\n",
      "[Epoch: 27] Average loss: 2224.8176, val_loss: 36757.5664\n",
      "[Epoch: 28] Average loss: 2343.6375, val_loss: 12958.9619\n",
      "[Epoch: 29] Average loss: 2197.8599, val_loss: 2358.0544\n",
      "[Epoch: 30] Average loss: 2160.2766, val_loss: 1939.6836\n",
      "[Epoch: 31] Average loss: 1710.4792, val_loss: 2261.9539\n",
      "[Epoch: 32] Average loss: 1866.7074, val_loss: 1886.3440\n",
      "[Epoch: 33] Average loss: 1718.0371, val_loss: 2093.4805\n",
      "[Epoch: 34] Average loss: 1829.9578, val_loss: 2452.4490\n",
      "[Epoch: 35] Average loss: 1974.5204, val_loss: 2344.4019\n",
      "[Epoch: 36] Average loss: 1670.5978, val_loss: 2225.8525\n",
      "[Epoch: 37] Average loss: 1738.3112, val_loss: 8410.8916\n",
      "[Epoch: 38] Average loss: 1730.2998, val_loss: 53593.2266\n",
      "[Epoch: 39] Average loss: 1989.4585, val_loss: 8023.1431\n",
      "[Epoch: 40] Average loss: 1943.9796, val_loss: 2370.9717\n",
      "[Epoch: 41] Average loss: 1872.3491, val_loss: 2392.2488\n",
      "[Epoch: 42] Average loss: 2148.9209, val_loss: 2140.8438\n",
      "[Epoch: 43] Average loss: 1682.0494, val_loss: 16390.1270\n",
      "[Epoch: 44] Average loss: 1651.7639, val_loss: 1980.7700\n",
      "[Epoch: 45] Average loss: 1740.5638, val_loss: 2515.9014\n",
      "[Epoch: 46] Average loss: 1754.7032, val_loss: 2031.9172\n",
      "[Epoch: 47] Average loss: 1597.4866, val_loss: 1677.8304\n",
      "[Epoch: 48] Average loss: 1837.0540, val_loss: 7126.0576\n",
      "[Epoch: 49] Average loss: 1636.5558, val_loss: 3939.8623\n",
      "[Epoch: 50] Average loss: 1566.1306, val_loss: 2055.3184\n",
      "[Epoch: 51] Average loss: 2434.0203, val_loss: 2015.3436\n",
      "[Epoch: 52] Average loss: 1918.6487, val_loss: 2404.2197\n",
      "[Epoch: 53] Average loss: 1622.5239, val_loss: 8006.3550\n",
      "[Epoch: 54] Average loss: 1717.4233, val_loss: 3634.8887\n",
      "[Epoch: 55] Average loss: 1265.4214, val_loss: 6339.0234\n",
      "[Epoch: 56] Average loss: 1563.2976, val_loss: 18315.9238\n",
      "[Epoch: 57] Average loss: 1973.8070, val_loss: 1678.0387\n",
      "[Epoch: 58] Average loss: 1534.4901, val_loss: 2101.0547\n",
      "[Epoch: 59] Average loss: 1608.1366, val_loss: 7316.2739\n",
      "[Epoch: 60] Average loss: 1593.4492, val_loss: 56165.9453\n",
      "[Epoch: 61] Average loss: 1190.6100, val_loss: 6108.3838\n",
      "[Epoch: 62] Average loss: 1464.7299, val_loss: 2743.9009\n",
      "[Epoch: 63] Average loss: 1755.6614, val_loss: 1678.7843\n",
      "[Epoch: 64] Average loss: 1539.8734, val_loss: 2694.2598\n",
      "[Epoch: 65] Average loss: 1258.8314, val_loss: 1962.6841\n",
      "[Epoch: 66] Average loss: 1191.8157, val_loss: 1898.0070\n",
      "[Epoch: 67] Average loss: 1572.5535, val_loss: 2428.6650\n",
      "[Epoch: 68] Average loss: 1427.9379, val_loss: 3529.5898\n",
      "[Epoch: 69] Average loss: 1565.2621, val_loss: 9963.1914\n",
      "[Epoch: 70] Average loss: 1652.3845, val_loss: 9648.3252\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    avg_loss = 0\n",
    "\n",
    "    for Image, X1, X2, Y in train_loader:\n",
    "        Image = Image.to(device)\n",
    "        X1 = X1.to(device)\n",
    "        X2 = X2.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        model.zero_grad()  # why we use zero_grad?\n",
    "        prediction = model(Image, X1, X2)\n",
    "        loss = torch.sqrt(criterion(prediction, Y)).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss / len(train_loader)\n",
    "    print(f'[Epoch: {epoch+1:>2}] Average loss: {avg_loss:.4f}, ', end='')\n",
    "    \n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    with torch.no_grad():\n",
    "        val_avg_loss = 0.\n",
    "        for Image_val, X1_val, X2_val, Y_val in val_loader:\n",
    "            Image_val = Image_val.to(device)\n",
    "            X1_val = X1_val.to(device)\n",
    "            X2_val = X2_val.to(device)\n",
    "            Y_val = Y_val.to(device)\n",
    "            val_prediction = model(Image_val, X1_val, X2_val)\n",
    "            val_loss = torch.sqrt(criterion(val_prediction, Y_val)).to(device)\n",
    "            val_avg_loss += val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"val_loss: {val_avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b699d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T13:35:39.847754Z",
     "start_time": "2022-02-23T13:35:39.190564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.67%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "criterion.eval()\n",
    "ss_tot = 0\n",
    "ss_res = 0\n",
    "with torch.no_grad():\n",
    "    for Image_test, X1_test, X2_test, Y_test in test_loader:\n",
    "        Image_test =Image_test.to(device)\n",
    "        X1_test = X1_test.to(device)\n",
    "        X2_test = X2_test.to(device)\n",
    "        Y_test = Y_test.to(device)\n",
    "        prediction = model(Image_test, X1_test, X2_test)\n",
    "        prices_mean = torch.mean(Y_test)\n",
    "        ss_tot += torch.sum((Y_test - prices_mean) ** 2)\n",
    "        ss_res += torch.sum((Y_test - prediction) ** 2)\n",
    "    \n",
    "    accuracy = 1 - ss_tot/ss_res\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3165bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python-3-9-7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
